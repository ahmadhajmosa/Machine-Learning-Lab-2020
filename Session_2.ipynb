{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadhajmosa/Machine-Learning-Lab-2020/blob/Taraneh/Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSUExzC-ZBV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgWZldyi-Zef",
        "colab_type": "text"
      },
      "source": [
        "# Lab on Machine Learning and Applications in Intelligent Vehicles\n",
        "## Session 1: Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75NLOuwKXSs",
        "colab_type": "text"
      },
      "source": [
        "#Session 2: 05.06 - 13:00 - 14:30 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUtGM-W_ehP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Intro:\n",
        "\n",
        "Tensorflow is a powerful framework for implementing and deploying large-scale deep learning models. Recently, it has been widely used in both reasearch and production. TF objective is to combine scale and flexibility.\n",
        "\n",
        "In the past session, we will learning the following:\n",
        "\n",
        "1. TF programming stack\n",
        "2. TF programming concepts including computatoin graphs, operations and sessions. \n",
        "3. Implementation of linear regression\n",
        "4. Implementation of feed-forward neural networks\n",
        "\n",
        "## TF stack:\n",
        "\n",
        "TensorFlow is a framework composed of two core building blocks — a library for defining computational graphs and a runtime for executing such graphs on a variety of different hardware\n",
        "\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/layers.png)\n",
        "\n",
        "\n",
        "Before goining into details about the stack, let us talk about computational graphs.\n",
        "\n",
        "### Computational Graphs\n",
        "\n",
        "A directed graph is a data structure consisting of nodes (vertices) and edges. It’s a set of vertices connected pairwise by directed edges.\n",
        "\n",
        "Graphs come in many shapes and sizes and are used to solve many real-life problems, such as representing networks including telephone networks, circuit networks, road networks, and even social networks. \n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*V6aYjD3AxDbEKYahkGqVQw.png)\n",
        "\n",
        "TensorFlow uses directed graphs internally to represent computations, and they call this data flow graphs (or computational graphs).\n",
        "\n",
        "The nodes in TF data flow graph mostly represents operations, variables and placeholders.\n",
        "\n",
        "Take for example the following operation:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "\n",
        "To create a computational graph out of this program, we create nodes for each of the operations in our program, along with the input variables a and b. In fact, a and b could be constants if they don’t change. If one node is used as the input to another operation we draw a directed arrow that goes from one node to another.\n",
        "\n",
        "The computational graph for this program might look like this:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*vPb9E0Yd1QUAD0oFmAgaOw.png)\n",
        "\n",
        "Operations create or manipulate data according to specific rules. In TensorFlow those rules are called Ops, short for operations. Variables on the other hand represent shared, persistent state that can be manipulated by running Ops on those variables.\n",
        "\n",
        "The questions now what are the advantages of representing operations as directed graphs: The main advantage of using directed graphs is the ability to do **parallelism** and what is called **dependency driving scheduling**. \n",
        "For example, consider again the follwoing code:\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*6E3sfit6DCeJ9mOz17g4bA.png)\n",
        "At the most fundamental level, most computer programs are mainly composed of two things — primitive operations and an order in which these operations are executed, often sequentially, line by line. This means we would first multiply a and b and only when this expression was evaluated we would take their sum. Computational graphs on the otherhand, exclusively specify the dependencies across the operations.\n",
        "If we look at our computational graph we see that we could execute the multiplication and addition in parallel. That’s because these two operations do not depend on each other.\n",
        " So we can use the topology of the graph to drive the scheduling of operations and execute them in the most efficient manner, e.g. using multiple GPUs on a single machine or even distribute the execution across multiple machines.\n",
        " Another key advantage is portability. The graph is a language-independent representation of our code. So we can build the graph in Python, save the model (TensorFlow uses protocol buffers), and restore the model in a different language, say C++, if you want to go really fast.\n",
        " \n",
        " \n",
        "\n",
        "--------------------------------\n",
        "# References:\n",
        "\n",
        "https://medium.com/@d3lm/understand-tensorflow-by-mimicking-its-api-from-scratch-faa55787170d\n",
        "\n",
        "https://www.tensorflow.org/guide/extend/architecture\n",
        "\n",
        "https://www.tensorflow.org/guide/low_level_intro\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-GFJPVDnEwx",
        "colab_type": "text"
      },
      "source": [
        "# placeholder: tensors are feeded externaly for example inputs tensors + output tensors\n",
        "\n",
        "# variables : tensors represent the parameters of the network/graph ie. nn weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmSCbhtoJBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "\n",
        "num_inputs = 3\n",
        "num_outputs = 4\n",
        "num_samples= 10\n",
        "# Training data\n",
        "x_gr = np.random.rand(num_samples,num_inputs)\n",
        "y_gr = np.random.rand(num_samples,num_outputs)\n",
        "\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "\n",
        "# weights \n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs,num_outputs ]))\n",
        "\n",
        "# model\n",
        "y_p = tf.matmul(x, w_1)\n",
        "\n",
        "\n",
        "# cost\n",
        "\n",
        "cost = tf.reduce_mean(tf.pow(y-y_p,2)) # \n",
        "\n",
        "# optimisation \n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(10):\n",
        "    \n",
        "        sess.run(optimizer, feed_dict={x: x_gr, y: y_gr}) \n",
        "\n",
        "        pr_cost = sess.run(cost, feed_dict={x: x_gr,y: y_gr})\n",
        "    \n",
        "        print('iter: ',i, 'cost: ', pr_cost)\n",
        "    \n",
        "    y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    print('predicted ', y_p_p)\n",
        "    print('real ', y_gr)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv2aqi3Fu-AJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "eabf27bc-af78-4605-b30d-27f8077196c3"
      },
      "source": [
        "sess = tf.Session() \n",
        "sess.run(init)\n",
        "    \n",
        "for i in range(10):\n",
        "    \n",
        "        sess.run(optimizer, feed_dict={x: x_gr, y: y_gr}) \n",
        "\n",
        "        pr_cost = sess.run(cost, feed_dict={x: x_gr,y: y_gr})\n",
        "    \n",
        "        print('iter: ',i, 'cost: ', pr_cost)\n",
        "    \n",
        "y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "print('predicted ', y_p_p)\n",
        "print('real ', y_gr)\n",
        "\n",
        "#sess.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter:  0 cost:  0.5914289\n",
            "iter:  1 cost:  0.590312\n",
            "iter:  2 cost:  0.5891979\n",
            "iter:  3 cost:  0.5880863\n",
            "iter:  4 cost:  0.5869776\n",
            "iter:  5 cost:  0.58587164\n",
            "iter:  6 cost:  0.58476853\n",
            "iter:  7 cost:  0.5836683\n",
            "iter:  8 cost:  0.5825709\n",
            "iter:  9 cost:  0.5814764\n",
            "predicted  [[-0.07052338 -1.4182088  -0.20726368  0.6065073 ]\n",
            " [-0.41022846  0.7640786   1.0915788   0.5919728 ]\n",
            " [-0.07066503 -0.73823565  0.10052644  0.31935224]\n",
            " [-0.2946304  -0.3036949  -0.28762203  1.1227872 ]\n",
            " [-0.57840925  0.8397043   0.8986697   1.1970941 ]\n",
            " [-0.32035732 -0.3043637  -0.03262401  1.0779576 ]\n",
            " [-0.25558242 -0.41777548  0.2828037   0.74326414]\n",
            " [-0.6702078   0.774465    0.18325244  1.8486446 ]\n",
            " [-0.3652569   0.5447639   0.8380182   0.6200657 ]\n",
            " [-0.48676854  1.0157775   1.195501    0.7295743 ]]\n",
            "real  [[0.28427788 0.58920269 0.76702838 0.54495026]\n",
            " [0.10077242 0.44421162 0.08474814 0.63117015]\n",
            " [0.01157148 0.14526119 0.81988115 0.22006669]\n",
            " [0.09844534 0.24078169 0.60496677 0.87281952]\n",
            " [0.21494239 0.5097351  0.2950044  0.82441926]\n",
            " [0.41953509 0.88851562 0.17726813 0.39356474]\n",
            " [0.10843995 0.98875919 0.14346219 0.47484879]\n",
            " [0.40487958 0.82369397 0.90377852 0.66008465]\n",
            " [0.94767349 0.42496532 0.47597419 0.79391048]\n",
            " [0.89124593 0.46764663 0.18470877 0.82758744]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE6qknOSWeKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "852bbc0c-3166-486e-976e-585e172e8e21"
      },
      "source": [
        "%tensorflow_version 1.x\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUPSS03avw5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "2759de58-f542-437c-cb8f-e8da5208463c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "\n",
        "num_inputs = 3\n",
        "num_h1_n = 4\n",
        "num_h2_n = 10\n",
        "num_outputs = 4\n",
        "#  O   O   O   O\n",
        "#  O   O   O   O\n",
        "#  O   O   O   O\n",
        "#      O   O   O\n",
        "#          O   \n",
        "#          O   \n",
        "#          O   \n",
        "#          O   \n",
        "#          O   \n",
        "#          O   \n",
        "\n",
        "\n",
        "num_samples= 10\n",
        "\n",
        "# Training data\n",
        "x_gr = np.random.rand(num_samples,num_inputs)\n",
        "y_gr = np.random.rand(num_samples,num_outputs)\n",
        "\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "\n",
        "# weights \n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs,num_h1_n ]))\n",
        "w_2 = tf.Variable(tf.random_normal([num_h1_n,num_h2_n ]))\n",
        "w_3 = tf.Variable(tf.random_normal([num_h2_n,num_outputs ]))\n",
        "\n",
        "# bias \n",
        "b_1 = tf.Variable(tf.random_normal([num_h1_n]))\n",
        "b_2 = tf.Variable(tf.random_normal([num_h2_n]))\n",
        "b_3 = tf.Variable(tf.random_normal([num_outputs]))\n",
        "\n",
        "\n",
        "\n",
        "#F(WX+b)\n",
        "# model\n",
        "\n",
        "h1 = tf.nn.sigmoid(tf.add(tf.matmul(x, w_1),b_1)) # model of hidden layer 1\n",
        "h2 = tf.nn.sigmoid(tf.add(tf.matmul(h1, w_2),b_2)) # model of hidden layer 2\n",
        "y_p = tf.add(tf.matmul(h2, w_3),b_3) # model of the output layer\n",
        "\n",
        "#placeholders/inputs:outpus --> Variables/Weights --> Model --> cost --> optimizer --> initilize all variables --> start the session\n",
        "\n",
        "# cost\n",
        "\n",
        "cost = tf.reduce_mean(tf.pow(y-y_p,2)) # \n",
        "\n",
        "# optimisation \n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(10):\n",
        "    \n",
        "        sess.run(optimizer, feed_dict={x: x_gr, y: y_gr}) \n",
        "\n",
        "        pr_cost = sess.run(cost, feed_dict={x: x_gr,y: y_gr})\n",
        "    \n",
        "        print('iter: ',i, 'cost: ', pr_cost)\n",
        "    \n",
        "    y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    print('predicted ', y_p_p)\n",
        "    print('real ', y_gr)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "iter:  0 cost:  3.7154167\n",
            "iter:  1 cost:  3.683918\n",
            "iter:  2 cost:  3.6526089\n",
            "iter:  3 cost:  3.6214912\n",
            "iter:  4 cost:  3.5905685\n",
            "iter:  5 cost:  3.5598426\n",
            "iter:  6 cost:  3.5293164\n",
            "iter:  7 cost:  3.4989905\n",
            "iter:  8 cost:  3.468869\n",
            "iter:  9 cost:  3.438953\n",
            "predicted  [[-1.6994138   3.139545   -0.4892214   1.2918464 ]\n",
            " [-1.4141936   3.3962379  -0.56025493  1.5004289 ]\n",
            " [-1.4271342   3.3675833  -0.5393368   1.5128952 ]\n",
            " [-1.6095712   3.2013707  -0.47851884  1.3919413 ]\n",
            " [-1.3633152   3.4307165  -0.57185465  1.5379093 ]\n",
            " [-1.4424294   3.3801365  -0.5667      1.4672735 ]\n",
            " [-1.7370307   3.1341696  -0.56446815  1.1919265 ]\n",
            " [-1.6812286   3.1714983  -0.5625444   1.2488736 ]\n",
            " [-1.69051     3.1477184  -0.4841122   1.3061322 ]\n",
            " [-1.7484171   3.0911536  -0.47290224  1.2563245 ]]\n",
            "real  [[0.24953134 0.73089036 0.9260432  0.02266804]\n",
            " [0.26182008 0.19663483 0.14013938 0.71980935]\n",
            " [0.97197882 0.45010515 0.21673956 0.62109635]\n",
            " [0.38568086 0.2567362  0.679027   0.98177855]\n",
            " [0.70510403 0.63541986 0.09825508 0.63960136]\n",
            " [0.58304965 0.41118293 0.01241144 0.59573531]\n",
            " [0.12318628 0.98534367 0.48893402 0.94055269]\n",
            " [0.10609206 0.15890923 0.60863427 0.22580786]\n",
            " [0.96061428 0.7335734  0.85362857 0.42405943]\n",
            " [0.15095686 0.13433172 0.071118   0.23971957]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwhCMk9VyVj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "5eacdf2a-1c06-403a-ff02-da9c9cb96625"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "\n",
        "display(mnist.train.images.shape) # 28*28 = 784\n",
        "\n",
        "image =mnist.train.images[0].reshape((28,28))\n",
        "#MNIST data input (img shape: 28*28)\n",
        "imshow(image)\n",
        "\n",
        "print(mnist.train.labels[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-b22520be68e0>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOL0lEQVR4nO3df4wc9XnH8c8H4x8BDMahcS1+xISStqRKTXKYFlBrSkOJFRXStBS3IFeiuZRAFZQIlRJFIfmjoqghSktANQXFJAGKFH5W0IY4iVAqApyRY8yPACEG7Jx9YFNhaGOf7ad/3IAOuJk9dmZ31n7eL+m0e/PszDwa3edmd2Znvo4IAdj37dd2AwD6g7ADSRB2IAnCDiRB2IEk9u/nymZ5dszRgf1cJZDKL/WadsYOT1WrFXbbZ0j6mqQZkv4tIq6oev0cHagTfVqdVQKo8GCsLq11/Tbe9gxJX5f0UUnHSVpu+7hulwegt+p8Zl8i6ZmIeDYidkq6RdKZzbQFoGl1wn64pBcm/b6xmPYmtodtj9geGdeOGqsDUEfPj8ZHxMqIGIqIoZma3evVAShRJ+ybJB056fcjimkABlCdsD8s6VjbR9ueJekcSXc10xaApnV96i0idtm+SNJ/aeLU2w0R8VhjnQFoVK3z7BFxj6R7GuoFQA/xdVkgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAErWGbLa9QdJ2Sbsl7YqIoSaaAtC8WmEvnBoRLzWwHAA9xNt4IIm6YQ9J37W9xvbwVC+wPWx7xPbIuHbUXB2AbtV9G39KRGyy/R5J99l+MiLun/yCiFgpaaUkHez5UXN9ALpUa88eEZuKxzFJt0ta0kRTAJrXddhtH2h77uvPJZ0uaX1TjQFoVp238Qsk3W779eXcFBH/2UhXABrXddgj4llJv91gLwB6iFNvQBKEHUiCsANJEHYgCcIOJNHEhTBo2ehnTyqtucN3FudsrX7By79RPf/CB3ZXL//uh6oXgL5hzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSewz59nHLiw/1yxJ//PB8cr67adf3WQ7ffWbsx7uet5fxq7K+iH7vauyPnbea5X1X/xz+Z/YVZs/Ujnv1rMPrqzvemFjZR1vxp4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JwRP8GaTnY8+NEn9b1/E9dd0Jp7cll11TOO9szu14v2nHuhqWV9Zf/osN5+A3PN9jN3uHBWK1XYpunqrFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk9qrr2a899cbSWqfz6P+49djK+tjOuV311ITb1ny4sn7U3VOeNh0IG0+r3l9cueym0tonDnqlct5vLfphZf3cm5ZW1l/+8yNKaxmvhe+4Z7d9g+0x2+snTZtv+z7bTxePh/a2TQB1Tedt/DcknfGWaZdKWh0Rx0paXfwOYIB1DHtE3C9p21smnylpVfF8laSzGu4LQMO6/cy+ICJGi+ebJS0oe6HtYUnDkjRHB3S5OgB11T4aHxNX0pReTRMRKyNiKCKGZmp23dUB6FK3Yd9ie6EkFY9jzbUEoBe6DftdklYUz1dIurOZdgD0Ssfr2W3fLGmppMMkbZH0RUl3SLpV0lGSnpN0dkS89SDe29S9nt0f/kBp7aXF1dc2v+eOn1bWd2/t2D66sN8Hywd4/9gt/10574XzXqi17l+//oLS2qIvPFBr2YOq6nr2jgfoImJ5San71ALoO74uCyRB2IEkCDuQBGEHkiDsQBJ71a2ksW/Z+snfrayPfOnaWstfs2Nnae2yo5fUWvag4lbSAAg7kAVhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgib1qyGbsfTZedlJpbc/x23u67gUzyq9n3/UH1cNk7//9NU230zr27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBPeN3wfs/75FpbVnzl9YOe8156xsuJs3WzpnvLQ2w+3ta342/mpl/dPvPaVPnTSr1n3jbd9ge8z2+knTLre9yfba4mdZkw0DaN50/rV+Q9IZU0z/akQsLn7uabYtAE3rGPaIuF/Stj70AqCH6nxousj2uuJt/qFlL7I9bHvE9si4dtRYHYA6ug37tZKOkbRY0qikr5S9MCJWRsRQRAzN1OwuVwegrq7CHhFbImJ3ROyRdJ2kfXNITGAf0lXYbU8+n/NxSevLXgtgMHS8nt32zZKWSjrM9kZJX5S01PZiSSFpg6RP9bDHfd6rf3ZiZf3FD1X/T/7yn9xSWjtn7std9dScwfze1h9+7+LK+vs10qdO+qdj2CNi+RSTr+9BLwB6aDD/7QJoHGEHkiDsQBKEHUiCsANJcCvpBvj4D1TW5109Wlm/Z9G1lfVeXgp6x2sHVdbX/98RtZb/H1cuLa3N2FF9efWKL99dWR8+5BfdtCRJmrV5Ztfz7q3YswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEpxnn6bnvlQ+9PAXzvn3ynn/cu7Wyvrzu/63sv7kztK7fkmS/vbmvy6tHTA65V2F37Dwhy9V1nc//lRlvZND9OOu53367xd0WHj1efafV9wuetGd1beS3hexZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDjPPk3zThgrrXU6j37a439cWR//l1+trL/rzocq64v0QGW9yu6u56xvz+8fX1k/a16nmxhX76u27ZlVXnzo0Q7L3vewZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDjPPk3vPr/8+udf++wFlfMec0n1efD99XxXPe3tXn7/nMr6yXPq7YuG159bWjtM9a7T3xt13Jq2j7T9A9uP237M9meK6fNt32f76eKx+g4LAFo1nX+duyR9LiKOk/Q7ki60fZykSyWtjohjJa0ufgcwoDqGPSJGI+KR4vl2SU9IOlzSmZJWFS9bJemsXjUJoL539Jnd9iJJx0t6UNKCiHh9ELPNkqa8YZjtYUnDkjRHB3TbJ4Capn0ExPZBkr4j6eKIeGVyLSJC0pSj9EXEyogYioihmZpdq1kA3ZtW2G3P1ETQvx0RtxWTt9heWNQXSiq/LAxA6zq+jbdtSddLeiIirppUukvSCklXFI939qTDAbFrdHNp7ZhLymsot/WEXbXmf2Jn9S24515zSK3l72um85n9ZEnnSXrU9tpi2mWaCPmtts+X9Jyks3vTIoAmdAx7RPxIUtlIA6c12w6AXuHrskAShB1IgrADSRB2IAnCDiTBJa7oqT9a/0pp7fZ5X+8wd8WtoCWteGxFZf3Qex/usPxc2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKcZ0dP/enB60prB+x3UOW8T42/Vlk/4Op5XfWUFXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC8+yoZezTJ1XWF8wov6b85+Plw2BL0vJ/uKSyfti91UNh483YswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEtMZn/1ISTdKWiApJK2MiK/ZvlzSJyW9WLz0soi4p1eNoh2ePbuy/om/+X5lffuenaW1ZQ9dUDnvUf/KefQmTedLNbskfS4iHrE9V9Ia2/cVta9GxD/1rj0ATZnO+OyjkkaL59ttPyHp8F43BqBZ7+gzu+1Fko6X9GAx6SLb62zfYPvQknmGbY/YHhnXjlrNAujetMNu+yBJ35F0cUS8IulaScdIWqyJPf9XppovIlZGxFBEDM1U9ec/AL0zrbDbnqmJoH87Im6TpIjYEhG7I2KPpOskLeldmwDq6hh225Z0vaQnIuKqSdMXTnrZxyWtb749AE2ZztH4kyWdJ+lR22uLaZdJWm57sSZOx22Q9KmedIh27YnK8jfvPrWyfu9PlpbWjrr1x910hC5N52j8jyR5ihLn1IG9CN+gA5Ig7EAShB1IgrADSRB2IAnCDiTBraRRKcbLL1GVpEWf5zLUvQV7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhHV1ys3ujL7RUnPTZp0mKSX+tbAOzOovQ1qXxK9davJ3t4bEb8yVaGvYX/byu2RiBhqrYEKg9rboPYl0Vu3+tUbb+OBJAg7kETbYV/Z8vqrDGpvg9qXRG/d6ktvrX5mB9A/be/ZAfQJYQeSaCXsts+w/VPbz9i+tI0eytjeYPtR22ttj7Tcyw22x2yvnzRtvu37bD9dPE45xl5LvV1ue1Ox7dbaXtZSb0fa/oHtx20/ZvszxfRWt11FX33Zbn3/zG57hqSnJH1E0kZJD0taHhGP97WRErY3SBqKiNa/gGH79yS9KunGiPitYtqVkrZFxBXFP8pDI+LvBqS3yyW92vYw3sVoRQsnDzMu6SxJf6UWt11FX2erD9utjT37EknPRMSzEbFT0i2Szmyhj4EXEfdL2vaWyWdKWlU8X6WJP5a+K+ltIETEaEQ8UjzfLun1YcZb3XYVffVFG2E/XNILk37fqMEa7z0kfdf2GtvDbTczhQURMVo83yxpQZvNTKHjMN799JZhxgdm23Uz/HldHKB7u1Mi4kOSPirpwuLt6kCKic9gg3TudFrDePfLFMOMv6HNbdft8Od1tRH2TZKOnPT7EcW0gRARm4rHMUm3a/CGot7y+gi6xeNYy/28YZCG8Z5qmHENwLZrc/jzNsL+sKRjbR9te5akcyTd1UIfb2P7wOLAiWwfKOl0Dd5Q1HdJWlE8XyHpzhZ7eZNBGca7bJhxtbztWh/+PCL6/iNpmSaOyP9M0ufb6KGkr/dJ+knx81jbvUm6WRNv68Y1cWzjfEnvlrRa0tOSvidp/gD19k1Jj0pap4lgLWypt1M08RZ9naS1xc+ytrddRV992W58XRZIggN0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DE/wN7/T2QKq1v5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXapqksBX95W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "tic = time.clock()\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaeRp0T10834",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b77c0cfa-460b-4cfa-98b6-6560e04773ab"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# training data\n",
        "X_train = mnist.train.images\n",
        "Y_train = mnist.train.labels\n",
        "\n",
        "# testing data\n",
        "X_test = mnist.test.images\n",
        "Y_test = mnist.test.labels\n",
        "\n",
        "# training data\n",
        "X_val = mnist.validation.images\n",
        "Y_val = mnist.validation.labels\n",
        "\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 2000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "\n",
        "num_inputs = 784\n",
        "num_h1_n = 100\n",
        "num_h2_n = 100\n",
        "num_outputs = 10\n",
        "\n",
        "\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "\n",
        "# weights \n",
        "w_1 = tf.Variable(tf.random_normal([num_inputs,num_h1_n ]))\n",
        "w_2 = tf.Variable(tf.random_normal([num_h1_n,num_h2_n ]))\n",
        "w_3 = tf.Variable(tf.random_normal([num_h2_n,num_outputs ]))\n",
        "\n",
        "# bias \n",
        "b_1 = tf.Variable(tf.random_normal([num_h1_n]))\n",
        "b_2 = tf.Variable(tf.random_normal([num_h2_n]))\n",
        "b_3 = tf.Variable(tf.random_normal([num_outputs]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# model\n",
        "\n",
        "h1 = tf.nn.sigmoid(tf.add(tf.matmul(x, w_1),b_1)) # model of hidden layer 1\n",
        "h2 = tf.nn.sigmoid(tf.add(tf.matmul(h1, w_2),b_2)) # model of hidden layer 2\n",
        "y_p = tf.add(tf.matmul(h2, w_3),b_3) # model of the output layer\n",
        "\n",
        "\n",
        "\n",
        "# cost\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_p, labels=y)) # cross entropy cost\n",
        "\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(y_p, 1), tf.argmax(y, 1))\n",
        "\n",
        "## 3 images, y_p=[[0.1,0.0,0,0.9],[0.9,0.1,0,0.],[0,0.9,0,0.1]] \n",
        "\n",
        "# tf.argmax(y_p, 1) [3,0,1] \n",
        "\n",
        "# 3 images, y=[[0,0.0,0,1],[0,1,0,0],[0,1,0,0]] \n",
        "\n",
        "# tf.argmax(y, 1) [3,1,1]\n",
        "\n",
        "# tf.equal [True,False,True]--[1,0,1]--- 2/3 \n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "#\n",
        "\n",
        "# optimisation \n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "tic = time.clock()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(1000):\n",
        "        \n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        \n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
        "    \n",
        "\n",
        "        train_cost, train_acc  = sess.run([cost,accuracy], feed_dict={x: batch_x,y: batch_y})\n",
        "    \n",
        "        \n",
        "        test_batch_x, test_batch_y = mnist.test.next_batch(batch_size)\n",
        "\n",
        "        test_cost, test_acc  = sess.run([cost,accuracy], feed_dict={x: test_batch_x,y: test_batch_y})\n",
        "        print('iter: ',i, 'train_cost: ', train_cost, 'train_acc: ', train_acc,'test_cost: ', test_cost, 'test_acc: ', test_acc )\n",
        "\n",
        "    \n",
        "    #y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    #print('predicted ', y_p_p)\n",
        "    #print('real ', y_gr)\n",
        "\n",
        "\n",
        "\n",
        "toc = time.clock()\n",
        "toc-tic"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-df1b11446ace>:59: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "iter:  0 train_cost:  12.1140585 train_acc:  0.0859375 test_cost:  11.795431 test_acc:  0.078125\n",
            "iter:  1 train_cost:  11.158198 train_acc:  0.1015625 test_cost:  10.622961 test_acc:  0.0859375\n",
            "iter:  2 train_cost:  9.48166 train_acc:  0.1484375 test_cost:  10.758317 test_acc:  0.0859375\n",
            "iter:  3 train_cost:  10.0866165 train_acc:  0.078125 test_cost:  10.30264 test_acc:  0.1171875\n",
            "iter:  4 train_cost:  8.962734 train_acc:  0.109375 test_cost:  9.430954 test_acc:  0.0703125\n",
            "iter:  5 train_cost:  9.232653 train_acc:  0.09375 test_cost:  9.372509 test_acc:  0.0546875\n",
            "iter:  6 train_cost:  9.555784 train_acc:  0.1015625 test_cost:  8.978596 test_acc:  0.109375\n",
            "iter:  7 train_cost:  8.785046 train_acc:  0.078125 test_cost:  9.376514 test_acc:  0.0625\n",
            "iter:  8 train_cost:  7.9027333 train_acc:  0.109375 test_cost:  8.416481 test_acc:  0.0625\n",
            "iter:  9 train_cost:  7.6231194 train_acc:  0.078125 test_cost:  8.510196 test_acc:  0.0859375\n",
            "iter:  10 train_cost:  7.681741 train_acc:  0.0390625 test_cost:  7.629182 test_acc:  0.046875\n",
            "iter:  11 train_cost:  7.095518 train_acc:  0.1171875 test_cost:  7.937524 test_acc:  0.046875\n",
            "iter:  12 train_cost:  7.231922 train_acc:  0.0859375 test_cost:  7.168652 test_acc:  0.0546875\n",
            "iter:  13 train_cost:  7.9107847 train_acc:  0.0546875 test_cost:  6.959939 test_acc:  0.09375\n",
            "iter:  14 train_cost:  6.181819 train_acc:  0.0546875 test_cost:  6.5733542 test_acc:  0.0859375\n",
            "iter:  15 train_cost:  6.3100986 train_acc:  0.0625 test_cost:  6.3423615 test_acc:  0.046875\n",
            "iter:  16 train_cost:  6.1996326 train_acc:  0.125 test_cost:  6.1082473 test_acc:  0.1015625\n",
            "iter:  17 train_cost:  5.7372227 train_acc:  0.09375 test_cost:  5.8561954 test_acc:  0.078125\n",
            "iter:  18 train_cost:  5.845117 train_acc:  0.1015625 test_cost:  5.8019714 test_acc:  0.1015625\n",
            "iter:  19 train_cost:  6.085985 train_acc:  0.0859375 test_cost:  5.775237 test_acc:  0.078125\n",
            "iter:  20 train_cost:  5.855738 train_acc:  0.1015625 test_cost:  5.191521 test_acc:  0.140625\n",
            "iter:  21 train_cost:  4.7474785 train_acc:  0.140625 test_cost:  5.0258837 test_acc:  0.0703125\n",
            "iter:  22 train_cost:  4.9156523 train_acc:  0.1640625 test_cost:  5.309524 test_acc:  0.0859375\n",
            "iter:  23 train_cost:  5.4423466 train_acc:  0.1015625 test_cost:  5.336598 test_acc:  0.0859375\n",
            "iter:  24 train_cost:  5.19483 train_acc:  0.1328125 test_cost:  5.232994 test_acc:  0.1015625\n",
            "iter:  25 train_cost:  5.247367 train_acc:  0.125 test_cost:  5.530486 test_acc:  0.1015625\n",
            "iter:  26 train_cost:  4.6862593 train_acc:  0.125 test_cost:  4.7343273 test_acc:  0.1328125\n",
            "iter:  27 train_cost:  4.7734413 train_acc:  0.125 test_cost:  4.4685807 test_acc:  0.1015625\n",
            "iter:  28 train_cost:  4.693672 train_acc:  0.1015625 test_cost:  4.3214097 test_acc:  0.1015625\n",
            "iter:  29 train_cost:  4.927109 train_acc:  0.109375 test_cost:  4.3875127 test_acc:  0.1640625\n",
            "iter:  30 train_cost:  4.6267896 train_acc:  0.1953125 test_cost:  4.308183 test_acc:  0.140625\n",
            "iter:  31 train_cost:  4.437619 train_acc:  0.109375 test_cost:  3.8983796 test_acc:  0.1640625\n",
            "iter:  32 train_cost:  4.314616 train_acc:  0.1484375 test_cost:  4.2073317 test_acc:  0.1328125\n",
            "iter:  33 train_cost:  4.1031213 train_acc:  0.2109375 test_cost:  4.5108843 test_acc:  0.09375\n",
            "iter:  34 train_cost:  4.3001356 train_acc:  0.109375 test_cost:  4.0277367 test_acc:  0.140625\n",
            "iter:  35 train_cost:  3.9732845 train_acc:  0.203125 test_cost:  3.7226589 test_acc:  0.1484375\n",
            "iter:  36 train_cost:  4.1034365 train_acc:  0.1640625 test_cost:  3.9147525 test_acc:  0.1484375\n",
            "iter:  37 train_cost:  4.063941 train_acc:  0.140625 test_cost:  4.036084 test_acc:  0.1953125\n",
            "iter:  38 train_cost:  4.1570807 train_acc:  0.1796875 test_cost:  3.9968114 test_acc:  0.1171875\n",
            "iter:  39 train_cost:  3.8722668 train_acc:  0.1796875 test_cost:  3.908455 test_acc:  0.171875\n",
            "iter:  40 train_cost:  3.548501 train_acc:  0.1796875 test_cost:  4.0466795 test_acc:  0.1328125\n",
            "iter:  41 train_cost:  3.767826 train_acc:  0.171875 test_cost:  3.6655717 test_acc:  0.1640625\n",
            "iter:  42 train_cost:  3.5929987 train_acc:  0.21875 test_cost:  3.8980768 test_acc:  0.171875\n",
            "iter:  43 train_cost:  3.5037022 train_acc:  0.21875 test_cost:  3.6668115 test_acc:  0.1875\n",
            "iter:  44 train_cost:  3.7142413 train_acc:  0.171875 test_cost:  3.7561946 test_acc:  0.1953125\n",
            "iter:  45 train_cost:  3.8978639 train_acc:  0.1484375 test_cost:  3.4738793 test_acc:  0.1953125\n",
            "iter:  46 train_cost:  3.505039 train_acc:  0.1875 test_cost:  3.4488401 test_acc:  0.1171875\n",
            "iter:  47 train_cost:  3.2418005 train_acc:  0.2265625 test_cost:  3.4075747 test_acc:  0.1875\n",
            "iter:  48 train_cost:  3.381729 train_acc:  0.234375 test_cost:  3.6486926 test_acc:  0.1484375\n",
            "iter:  49 train_cost:  3.4577093 train_acc:  0.21875 test_cost:  3.317103 test_acc:  0.1796875\n",
            "iter:  50 train_cost:  2.9064436 train_acc:  0.234375 test_cost:  3.7044213 test_acc:  0.109375\n",
            "iter:  51 train_cost:  3.5871952 train_acc:  0.140625 test_cost:  3.2820904 test_acc:  0.234375\n",
            "iter:  52 train_cost:  3.770176 train_acc:  0.109375 test_cost:  3.2351973 test_acc:  0.203125\n",
            "iter:  53 train_cost:  2.945331 train_acc:  0.265625 test_cost:  3.4459634 test_acc:  0.1640625\n",
            "iter:  54 train_cost:  3.452528 train_acc:  0.1796875 test_cost:  3.554453 test_acc:  0.1640625\n",
            "iter:  55 train_cost:  3.2032154 train_acc:  0.2265625 test_cost:  3.2596765 test_acc:  0.2265625\n",
            "iter:  56 train_cost:  3.2639937 train_acc:  0.1875 test_cost:  3.4166021 test_acc:  0.1796875\n",
            "iter:  57 train_cost:  3.0667753 train_acc:  0.1796875 test_cost:  3.2177827 test_acc:  0.2265625\n",
            "iter:  58 train_cost:  3.2302623 train_acc:  0.203125 test_cost:  2.9081302 test_acc:  0.2578125\n",
            "iter:  59 train_cost:  3.1195107 train_acc:  0.2265625 test_cost:  2.7847834 test_acc:  0.2265625\n",
            "iter:  60 train_cost:  2.9460416 train_acc:  0.265625 test_cost:  3.1673512 test_acc:  0.2265625\n",
            "iter:  61 train_cost:  2.9198308 train_acc:  0.1953125 test_cost:  3.084216 test_acc:  0.2265625\n",
            "iter:  62 train_cost:  2.643697 train_acc:  0.3203125 test_cost:  3.2501273 test_acc:  0.234375\n",
            "iter:  63 train_cost:  2.795476 train_acc:  0.2578125 test_cost:  2.741754 test_acc:  0.25\n",
            "iter:  64 train_cost:  3.0420394 train_acc:  0.2734375 test_cost:  2.810273 test_acc:  0.2890625\n",
            "iter:  65 train_cost:  3.0768247 train_acc:  0.1875 test_cost:  2.912946 test_acc:  0.2421875\n",
            "iter:  66 train_cost:  2.8312805 train_acc:  0.2734375 test_cost:  2.7450964 test_acc:  0.296875\n",
            "iter:  67 train_cost:  3.0141227 train_acc:  0.1875 test_cost:  2.8344872 test_acc:  0.265625\n",
            "iter:  68 train_cost:  2.5073564 train_acc:  0.28125 test_cost:  2.9476118 test_acc:  0.2421875\n",
            "iter:  69 train_cost:  2.6728117 train_acc:  0.2734375 test_cost:  2.9358895 test_acc:  0.1484375\n",
            "iter:  70 train_cost:  2.7594328 train_acc:  0.3125 test_cost:  2.6469038 test_acc:  0.2734375\n",
            "iter:  71 train_cost:  2.624112 train_acc:  0.3125 test_cost:  2.6459148 test_acc:  0.234375\n",
            "iter:  72 train_cost:  2.7107022 train_acc:  0.265625 test_cost:  2.7266884 test_acc:  0.2734375\n",
            "iter:  73 train_cost:  2.7658503 train_acc:  0.296875 test_cost:  2.8638935 test_acc:  0.28125\n",
            "iter:  74 train_cost:  2.9909317 train_acc:  0.21875 test_cost:  2.6570506 test_acc:  0.265625\n",
            "iter:  75 train_cost:  2.58749 train_acc:  0.2890625 test_cost:  2.5288615 test_acc:  0.2265625\n",
            "iter:  76 train_cost:  2.6938012 train_acc:  0.2890625 test_cost:  2.5553427 test_acc:  0.2734375\n",
            "iter:  77 train_cost:  2.6069713 train_acc:  0.2734375 test_cost:  2.6106644 test_acc:  0.328125\n",
            "iter:  78 train_cost:  2.5869656 train_acc:  0.265625 test_cost:  2.7752097 test_acc:  0.2734375\n",
            "iter:  79 train_cost:  2.4737196 train_acc:  0.3359375 test_cost:  2.6805277 test_acc:  0.28125\n",
            "iter:  80 train_cost:  2.5883636 train_acc:  0.3515625 test_cost:  2.6312227 test_acc:  0.296875\n",
            "iter:  81 train_cost:  2.5732412 train_acc:  0.3515625 test_cost:  2.376643 test_acc:  0.3515625\n",
            "iter:  82 train_cost:  2.8848188 train_acc:  0.2734375 test_cost:  2.403678 test_acc:  0.3359375\n",
            "iter:  83 train_cost:  2.6020427 train_acc:  0.3203125 test_cost:  2.4407048 test_acc:  0.3203125\n",
            "iter:  84 train_cost:  2.6714635 train_acc:  0.2578125 test_cost:  2.3374462 test_acc:  0.34375\n",
            "iter:  85 train_cost:  2.5480075 train_acc:  0.2734375 test_cost:  2.2249928 test_acc:  0.3203125\n",
            "iter:  86 train_cost:  2.659579 train_acc:  0.296875 test_cost:  2.580937 test_acc:  0.296875\n",
            "iter:  87 train_cost:  2.3676481 train_acc:  0.3515625 test_cost:  2.6400495 test_acc:  0.2890625\n",
            "iter:  88 train_cost:  2.379241 train_acc:  0.34375 test_cost:  2.377472 test_acc:  0.359375\n",
            "iter:  89 train_cost:  2.561478 train_acc:  0.3359375 test_cost:  1.9541078 test_acc:  0.4140625\n",
            "iter:  90 train_cost:  2.2650604 train_acc:  0.359375 test_cost:  2.2265275 test_acc:  0.34375\n",
            "iter:  91 train_cost:  2.752428 train_acc:  0.3046875 test_cost:  2.5125866 test_acc:  0.3828125\n",
            "iter:  92 train_cost:  2.5303793 train_acc:  0.3125 test_cost:  2.3509486 test_acc:  0.3359375\n",
            "iter:  93 train_cost:  2.1364267 train_acc:  0.4296875 test_cost:  1.9455066 test_acc:  0.40625\n",
            "iter:  94 train_cost:  2.6250763 train_acc:  0.3203125 test_cost:  2.4053006 test_acc:  0.359375\n",
            "iter:  95 train_cost:  2.4508 train_acc:  0.3984375 test_cost:  2.6878793 test_acc:  0.28125\n",
            "iter:  96 train_cost:  2.154067 train_acc:  0.3671875 test_cost:  2.2054563 test_acc:  0.3671875\n",
            "iter:  97 train_cost:  2.143433 train_acc:  0.4140625 test_cost:  2.2818515 test_acc:  0.3359375\n",
            "iter:  98 train_cost:  2.1891124 train_acc:  0.34375 test_cost:  2.3606625 test_acc:  0.3359375\n",
            "iter:  99 train_cost:  2.1294928 train_acc:  0.3671875 test_cost:  1.937254 test_acc:  0.4375\n",
            "iter:  100 train_cost:  2.1662986 train_acc:  0.3828125 test_cost:  2.0566888 test_acc:  0.453125\n",
            "iter:  101 train_cost:  2.4551508 train_acc:  0.296875 test_cost:  2.2056134 test_acc:  0.4140625\n",
            "iter:  102 train_cost:  2.385736 train_acc:  0.3203125 test_cost:  2.2461133 test_acc:  0.390625\n",
            "iter:  103 train_cost:  1.9075713 train_acc:  0.484375 test_cost:  2.3613186 test_acc:  0.3515625\n",
            "iter:  104 train_cost:  2.1434762 train_acc:  0.390625 test_cost:  1.9980148 test_acc:  0.3984375\n",
            "iter:  105 train_cost:  2.0632741 train_acc:  0.3515625 test_cost:  2.1252458 test_acc:  0.328125\n",
            "iter:  106 train_cost:  1.7940962 train_acc:  0.4453125 test_cost:  1.6929495 test_acc:  0.484375\n",
            "iter:  107 train_cost:  2.2425935 train_acc:  0.4296875 test_cost:  2.0934284 test_acc:  0.3984375\n",
            "iter:  108 train_cost:  2.07409 train_acc:  0.3671875 test_cost:  2.3183208 test_acc:  0.375\n",
            "iter:  109 train_cost:  1.9719226 train_acc:  0.359375 test_cost:  2.3014755 test_acc:  0.3515625\n",
            "iter:  110 train_cost:  1.9098387 train_acc:  0.4140625 test_cost:  2.0943031 test_acc:  0.375\n",
            "iter:  111 train_cost:  1.8372835 train_acc:  0.4765625 test_cost:  2.3499782 test_acc:  0.359375\n",
            "iter:  112 train_cost:  2.0306437 train_acc:  0.4375 test_cost:  2.2842512 test_acc:  0.34375\n",
            "iter:  113 train_cost:  1.9461496 train_acc:  0.4296875 test_cost:  1.7341831 test_acc:  0.4140625\n",
            "iter:  114 train_cost:  1.9305376 train_acc:  0.484375 test_cost:  2.022742 test_acc:  0.390625\n",
            "iter:  115 train_cost:  2.1854143 train_acc:  0.3515625 test_cost:  1.9490594 test_acc:  0.4140625\n",
            "iter:  116 train_cost:  1.8338978 train_acc:  0.46875 test_cost:  1.9786637 test_acc:  0.4296875\n",
            "iter:  117 train_cost:  1.8462198 train_acc:  0.4453125 test_cost:  1.9227129 test_acc:  0.40625\n",
            "iter:  118 train_cost:  2.1080427 train_acc:  0.390625 test_cost:  2.1146135 test_acc:  0.421875\n",
            "iter:  119 train_cost:  1.4738419 train_acc:  0.515625 test_cost:  1.9001511 test_acc:  0.4765625\n",
            "iter:  120 train_cost:  1.8976386 train_acc:  0.4296875 test_cost:  1.8628356 test_acc:  0.3984375\n",
            "iter:  121 train_cost:  1.8978322 train_acc:  0.4140625 test_cost:  1.820486 test_acc:  0.484375\n",
            "iter:  122 train_cost:  2.2076273 train_acc:  0.3984375 test_cost:  1.9193593 test_acc:  0.421875\n",
            "iter:  123 train_cost:  1.6332892 train_acc:  0.4609375 test_cost:  1.7570641 test_acc:  0.40625\n",
            "iter:  124 train_cost:  1.8581492 train_acc:  0.4453125 test_cost:  1.9515994 test_acc:  0.3984375\n",
            "iter:  125 train_cost:  1.627908 train_acc:  0.4296875 test_cost:  1.8777473 test_acc:  0.484375\n",
            "iter:  126 train_cost:  1.9702781 train_acc:  0.4296875 test_cost:  1.6064126 test_acc:  0.46875\n",
            "iter:  127 train_cost:  2.0346372 train_acc:  0.4140625 test_cost:  1.9527341 test_acc:  0.453125\n",
            "iter:  128 train_cost:  1.8964456 train_acc:  0.4609375 test_cost:  1.9121249 test_acc:  0.4375\n",
            "iter:  129 train_cost:  1.58728 train_acc:  0.5390625 test_cost:  1.9131213 test_acc:  0.4296875\n",
            "iter:  130 train_cost:  1.9396288 train_acc:  0.3828125 test_cost:  1.4404855 test_acc:  0.546875\n",
            "iter:  131 train_cost:  1.7697122 train_acc:  0.5234375 test_cost:  1.6242802 test_acc:  0.484375\n",
            "iter:  132 train_cost:  1.722966 train_acc:  0.5390625 test_cost:  1.8837891 test_acc:  0.515625\n",
            "iter:  133 train_cost:  1.8665781 train_acc:  0.453125 test_cost:  1.6398621 test_acc:  0.515625\n",
            "iter:  134 train_cost:  1.8470787 train_acc:  0.46875 test_cost:  2.0349147 test_acc:  0.453125\n",
            "iter:  135 train_cost:  1.621184 train_acc:  0.390625 test_cost:  2.1984015 test_acc:  0.3671875\n",
            "iter:  136 train_cost:  1.4742868 train_acc:  0.578125 test_cost:  1.6825831 test_acc:  0.5234375\n",
            "iter:  137 train_cost:  1.6655194 train_acc:  0.4765625 test_cost:  1.652833 test_acc:  0.4296875\n",
            "iter:  138 train_cost:  1.6176133 train_acc:  0.53125 test_cost:  1.7496424 test_acc:  0.453125\n",
            "iter:  139 train_cost:  1.9813898 train_acc:  0.4453125 test_cost:  1.497306 test_acc:  0.578125\n",
            "iter:  140 train_cost:  1.6427398 train_acc:  0.4921875 test_cost:  1.747732 test_acc:  0.5\n",
            "iter:  141 train_cost:  1.6395761 train_acc:  0.5 test_cost:  1.509176 test_acc:  0.5625\n",
            "iter:  142 train_cost:  1.6365278 train_acc:  0.515625 test_cost:  1.716856 test_acc:  0.5078125\n",
            "iter:  143 train_cost:  1.5851793 train_acc:  0.5078125 test_cost:  1.583425 test_acc:  0.5078125\n",
            "iter:  144 train_cost:  1.8549011 train_acc:  0.453125 test_cost:  1.7599108 test_acc:  0.484375\n",
            "iter:  145 train_cost:  1.929433 train_acc:  0.421875 test_cost:  1.5570889 test_acc:  0.5546875\n",
            "iter:  146 train_cost:  2.0099292 train_acc:  0.40625 test_cost:  1.6588124 test_acc:  0.5234375\n",
            "iter:  147 train_cost:  1.6759441 train_acc:  0.5078125 test_cost:  1.480569 test_acc:  0.5546875\n",
            "iter:  148 train_cost:  1.3387387 train_acc:  0.5625 test_cost:  1.7322792 test_acc:  0.484375\n",
            "iter:  149 train_cost:  1.9347491 train_acc:  0.421875 test_cost:  1.6447619 test_acc:  0.46875\n",
            "iter:  150 train_cost:  1.7000816 train_acc:  0.53125 test_cost:  1.6465573 test_acc:  0.4609375\n",
            "iter:  151 train_cost:  1.6307935 train_acc:  0.5625 test_cost:  1.360914 test_acc:  0.5625\n",
            "iter:  152 train_cost:  1.704287 train_acc:  0.5078125 test_cost:  1.5928693 test_acc:  0.5390625\n",
            "iter:  153 train_cost:  1.8193722 train_acc:  0.53125 test_cost:  1.5161085 test_acc:  0.5\n",
            "iter:  154 train_cost:  1.5053345 train_acc:  0.546875 test_cost:  1.5055077 test_acc:  0.5703125\n",
            "iter:  155 train_cost:  1.8779001 train_acc:  0.4921875 test_cost:  1.6733583 test_acc:  0.5\n",
            "iter:  156 train_cost:  1.4370733 train_acc:  0.53125 test_cost:  1.5636636 test_acc:  0.5234375\n",
            "iter:  157 train_cost:  1.4476438 train_acc:  0.59375 test_cost:  1.5681092 test_acc:  0.5078125\n",
            "iter:  158 train_cost:  1.5316578 train_acc:  0.5078125 test_cost:  1.4928817 test_acc:  0.5390625\n",
            "iter:  159 train_cost:  1.4829476 train_acc:  0.5703125 test_cost:  1.5412209 test_acc:  0.5078125\n",
            "iter:  160 train_cost:  1.4674599 train_acc:  0.5546875 test_cost:  1.9026434 test_acc:  0.4140625\n",
            "iter:  161 train_cost:  1.6624655 train_acc:  0.5390625 test_cost:  1.6338882 test_acc:  0.4765625\n",
            "iter:  162 train_cost:  1.5102136 train_acc:  0.5625 test_cost:  1.5424762 test_acc:  0.484375\n",
            "iter:  163 train_cost:  1.580813 train_acc:  0.5546875 test_cost:  1.4609702 test_acc:  0.5625\n",
            "iter:  164 train_cost:  1.4940059 train_acc:  0.5234375 test_cost:  1.3335752 test_acc:  0.578125\n",
            "iter:  165 train_cost:  1.333159 train_acc:  0.59375 test_cost:  1.8285873 test_acc:  0.53125\n",
            "iter:  166 train_cost:  1.398157 train_acc:  0.546875 test_cost:  1.1994774 test_acc:  0.6171875\n",
            "iter:  167 train_cost:  1.6362083 train_acc:  0.5390625 test_cost:  1.3014586 test_acc:  0.5625\n",
            "iter:  168 train_cost:  1.6699548 train_acc:  0.5625 test_cost:  1.5725021 test_acc:  0.5625\n",
            "iter:  169 train_cost:  1.3412191 train_acc:  0.59375 test_cost:  1.3418285 test_acc:  0.65625\n",
            "iter:  170 train_cost:  1.6621962 train_acc:  0.5078125 test_cost:  1.5663489 test_acc:  0.484375\n",
            "iter:  171 train_cost:  1.5045061 train_acc:  0.484375 test_cost:  1.3636153 test_acc:  0.5859375\n",
            "iter:  172 train_cost:  1.7105188 train_acc:  0.5390625 test_cost:  1.474556 test_acc:  0.5234375\n",
            "iter:  173 train_cost:  1.4327695 train_acc:  0.5625 test_cost:  1.4039137 test_acc:  0.6015625\n",
            "iter:  174 train_cost:  1.5528406 train_acc:  0.546875 test_cost:  1.2853647 test_acc:  0.609375\n",
            "iter:  175 train_cost:  1.4434319 train_acc:  0.5390625 test_cost:  1.5395136 test_acc:  0.5\n",
            "iter:  176 train_cost:  1.746335 train_acc:  0.453125 test_cost:  1.6035882 test_acc:  0.484375\n",
            "iter:  177 train_cost:  1.5315125 train_acc:  0.53125 test_cost:  1.4737232 test_acc:  0.5390625\n",
            "iter:  178 train_cost:  1.4725016 train_acc:  0.53125 test_cost:  1.3816614 test_acc:  0.5546875\n",
            "iter:  179 train_cost:  1.6212163 train_acc:  0.515625 test_cost:  1.4256282 test_acc:  0.5546875\n",
            "iter:  180 train_cost:  1.185519 train_acc:  0.6484375 test_cost:  1.3613365 test_acc:  0.6484375\n",
            "iter:  181 train_cost:  1.6822186 train_acc:  0.46875 test_cost:  1.2118883 test_acc:  0.625\n",
            "iter:  182 train_cost:  1.3548567 train_acc:  0.625 test_cost:  1.5352818 test_acc:  0.5625\n",
            "iter:  183 train_cost:  1.4603782 train_acc:  0.5390625 test_cost:  1.4646893 test_acc:  0.5625\n",
            "iter:  184 train_cost:  1.3015412 train_acc:  0.578125 test_cost:  1.2183022 test_acc:  0.625\n",
            "iter:  185 train_cost:  1.4746411 train_acc:  0.5859375 test_cost:  1.4637276 test_acc:  0.5859375\n",
            "iter:  186 train_cost:  1.1460377 train_acc:  0.671875 test_cost:  1.310739 test_acc:  0.5625\n",
            "iter:  187 train_cost:  1.372891 train_acc:  0.578125 test_cost:  1.0921059 test_acc:  0.6171875\n",
            "iter:  188 train_cost:  1.5995324 train_acc:  0.5234375 test_cost:  1.2771757 test_acc:  0.6328125\n",
            "iter:  189 train_cost:  1.6256828 train_acc:  0.4609375 test_cost:  1.5547744 test_acc:  0.5234375\n",
            "iter:  190 train_cost:  1.2471707 train_acc:  0.5859375 test_cost:  1.2481136 test_acc:  0.609375\n",
            "iter:  191 train_cost:  1.3633627 train_acc:  0.59375 test_cost:  1.4546944 test_acc:  0.5546875\n",
            "iter:  192 train_cost:  1.2679266 train_acc:  0.6328125 test_cost:  1.1996789 test_acc:  0.625\n",
            "iter:  193 train_cost:  1.3517218 train_acc:  0.59375 test_cost:  1.4544257 test_acc:  0.5390625\n",
            "iter:  194 train_cost:  1.3987777 train_acc:  0.515625 test_cost:  1.3220212 test_acc:  0.59375\n",
            "iter:  195 train_cost:  1.1942055 train_acc:  0.6015625 test_cost:  1.6984618 test_acc:  0.4921875\n",
            "iter:  196 train_cost:  1.328499 train_acc:  0.6640625 test_cost:  1.185833 test_acc:  0.6015625\n",
            "iter:  197 train_cost:  1.4296842 train_acc:  0.625 test_cost:  1.3742146 test_acc:  0.5859375\n",
            "iter:  198 train_cost:  1.2730676 train_acc:  0.578125 test_cost:  1.3195815 test_acc:  0.5859375\n",
            "iter:  199 train_cost:  1.4332501 train_acc:  0.5625 test_cost:  1.2653989 test_acc:  0.6015625\n",
            "iter:  200 train_cost:  1.6038077 train_acc:  0.515625 test_cost:  1.485673 test_acc:  0.5390625\n",
            "iter:  201 train_cost:  1.1099741 train_acc:  0.65625 test_cost:  1.2539437 test_acc:  0.6328125\n",
            "iter:  202 train_cost:  1.6055788 train_acc:  0.4921875 test_cost:  1.1771739 test_acc:  0.640625\n",
            "iter:  203 train_cost:  1.1988971 train_acc:  0.59375 test_cost:  1.0645587 test_acc:  0.640625\n",
            "iter:  204 train_cost:  1.5234585 train_acc:  0.5390625 test_cost:  1.1495026 test_acc:  0.65625\n",
            "iter:  205 train_cost:  1.3448594 train_acc:  0.5625 test_cost:  1.5222201 test_acc:  0.5859375\n",
            "iter:  206 train_cost:  1.3012316 train_acc:  0.53125 test_cost:  1.2656622 test_acc:  0.640625\n",
            "iter:  207 train_cost:  1.0210087 train_acc:  0.65625 test_cost:  1.4168304 test_acc:  0.5234375\n",
            "iter:  208 train_cost:  1.3039025 train_acc:  0.5546875 test_cost:  1.5379031 test_acc:  0.53125\n",
            "iter:  209 train_cost:  1.1557763 train_acc:  0.609375 test_cost:  1.0589747 test_acc:  0.6484375\n",
            "iter:  210 train_cost:  1.0869509 train_acc:  0.65625 test_cost:  1.3935537 test_acc:  0.5546875\n",
            "iter:  211 train_cost:  1.1613917 train_acc:  0.6171875 test_cost:  1.2061166 test_acc:  0.6484375\n",
            "iter:  212 train_cost:  1.4980757 train_acc:  0.5234375 test_cost:  1.2927058 test_acc:  0.6171875\n",
            "iter:  213 train_cost:  1.1842091 train_acc:  0.6171875 test_cost:  1.0821655 test_acc:  0.640625\n",
            "iter:  214 train_cost:  1.2050292 train_acc:  0.625 test_cost:  1.0879016 test_acc:  0.6328125\n",
            "iter:  215 train_cost:  1.1141765 train_acc:  0.6640625 test_cost:  1.265547 test_acc:  0.6015625\n",
            "iter:  216 train_cost:  1.3254964 train_acc:  0.6015625 test_cost:  1.288142 test_acc:  0.5859375\n",
            "iter:  217 train_cost:  1.4737602 train_acc:  0.5546875 test_cost:  1.4105804 test_acc:  0.5859375\n",
            "iter:  218 train_cost:  1.4320239 train_acc:  0.6328125 test_cost:  1.1015699 test_acc:  0.609375\n",
            "iter:  219 train_cost:  1.1767225 train_acc:  0.6484375 test_cost:  1.282625 test_acc:  0.625\n",
            "iter:  220 train_cost:  1.3627348 train_acc:  0.5703125 test_cost:  1.1882644 test_acc:  0.6015625\n",
            "iter:  221 train_cost:  1.449651 train_acc:  0.5390625 test_cost:  1.2524843 test_acc:  0.5703125\n",
            "iter:  222 train_cost:  1.0100263 train_acc:  0.625 test_cost:  1.3519571 test_acc:  0.578125\n",
            "iter:  223 train_cost:  1.1563816 train_acc:  0.5859375 test_cost:  1.1831851 test_acc:  0.6328125\n",
            "iter:  224 train_cost:  1.2394776 train_acc:  0.6171875 test_cost:  1.2040086 test_acc:  0.640625\n",
            "iter:  225 train_cost:  1.3815594 train_acc:  0.546875 test_cost:  1.3619624 test_acc:  0.6171875\n",
            "iter:  226 train_cost:  1.3181452 train_acc:  0.609375 test_cost:  1.2161486 test_acc:  0.6328125\n",
            "iter:  227 train_cost:  1.30481 train_acc:  0.625 test_cost:  1.3495681 test_acc:  0.546875\n",
            "iter:  228 train_cost:  1.3660561 train_acc:  0.5234375 test_cost:  1.1725621 test_acc:  0.625\n",
            "iter:  229 train_cost:  1.2305179 train_acc:  0.609375 test_cost:  1.1361265 test_acc:  0.6171875\n",
            "iter:  230 train_cost:  1.3495162 train_acc:  0.578125 test_cost:  1.2574211 test_acc:  0.6796875\n",
            "iter:  231 train_cost:  1.1620991 train_acc:  0.6171875 test_cost:  1.2241534 test_acc:  0.609375\n",
            "iter:  232 train_cost:  1.089024 train_acc:  0.640625 test_cost:  1.5962617 test_acc:  0.4921875\n",
            "iter:  233 train_cost:  1.0971713 train_acc:  0.625 test_cost:  0.98750883 test_acc:  0.6875\n",
            "iter:  234 train_cost:  1.0192201 train_acc:  0.671875 test_cost:  1.1911048 test_acc:  0.6015625\n",
            "iter:  235 train_cost:  1.176945 train_acc:  0.625 test_cost:  1.3419893 test_acc:  0.5703125\n",
            "iter:  236 train_cost:  1.1617864 train_acc:  0.6640625 test_cost:  1.1361251 test_acc:  0.6015625\n",
            "iter:  237 train_cost:  1.1742854 train_acc:  0.5703125 test_cost:  1.2040331 test_acc:  0.6484375\n",
            "iter:  238 train_cost:  1.1286671 train_acc:  0.6640625 test_cost:  1.0421057 test_acc:  0.6796875\n",
            "iter:  239 train_cost:  1.1430869 train_acc:  0.671875 test_cost:  0.9502878 test_acc:  0.671875\n",
            "iter:  240 train_cost:  1.2231874 train_acc:  0.609375 test_cost:  1.1618466 test_acc:  0.671875\n",
            "iter:  241 train_cost:  0.9840267 train_acc:  0.6640625 test_cost:  0.8762945 test_acc:  0.6953125\n",
            "iter:  242 train_cost:  1.0850512 train_acc:  0.640625 test_cost:  0.98487514 test_acc:  0.71875\n",
            "iter:  243 train_cost:  1.1393533 train_acc:  0.6484375 test_cost:  1.1418858 test_acc:  0.625\n",
            "iter:  244 train_cost:  1.4126208 train_acc:  0.5546875 test_cost:  0.79696244 test_acc:  0.7265625\n",
            "iter:  245 train_cost:  0.9976578 train_acc:  0.671875 test_cost:  0.9469205 test_acc:  0.7109375\n",
            "iter:  246 train_cost:  1.0425355 train_acc:  0.6796875 test_cost:  1.0499525 test_acc:  0.625\n",
            "iter:  247 train_cost:  1.493673 train_acc:  0.6171875 test_cost:  0.94065976 test_acc:  0.6875\n",
            "iter:  248 train_cost:  1.3287168 train_acc:  0.59375 test_cost:  1.1635709 test_acc:  0.6015625\n",
            "iter:  249 train_cost:  1.19645 train_acc:  0.609375 test_cost:  1.182947 test_acc:  0.640625\n",
            "iter:  250 train_cost:  0.8041652 train_acc:  0.75 test_cost:  1.1010101 test_acc:  0.6640625\n",
            "iter:  251 train_cost:  1.2649078 train_acc:  0.5859375 test_cost:  0.9349537 test_acc:  0.6640625\n",
            "iter:  252 train_cost:  1.2253926 train_acc:  0.6328125 test_cost:  1.376267 test_acc:  0.5703125\n",
            "iter:  253 train_cost:  0.9163685 train_acc:  0.671875 test_cost:  1.4290669 test_acc:  0.578125\n",
            "iter:  254 train_cost:  1.1442449 train_acc:  0.6328125 test_cost:  0.79993606 test_acc:  0.7265625\n",
            "iter:  255 train_cost:  1.164027 train_acc:  0.6171875 test_cost:  1.278729 test_acc:  0.6328125\n",
            "iter:  256 train_cost:  1.291937 train_acc:  0.609375 test_cost:  0.9940516 test_acc:  0.6640625\n",
            "iter:  257 train_cost:  1.0385506 train_acc:  0.65625 test_cost:  1.2042998 test_acc:  0.671875\n",
            "iter:  258 train_cost:  1.059277 train_acc:  0.6640625 test_cost:  0.85708904 test_acc:  0.7265625\n",
            "iter:  259 train_cost:  0.9823964 train_acc:  0.6171875 test_cost:  0.93064535 test_acc:  0.7578125\n",
            "iter:  260 train_cost:  1.2780824 train_acc:  0.59375 test_cost:  1.1797913 test_acc:  0.65625\n",
            "iter:  261 train_cost:  0.8409655 train_acc:  0.703125 test_cost:  1.1538008 test_acc:  0.640625\n",
            "iter:  262 train_cost:  1.1748788 train_acc:  0.6015625 test_cost:  1.059212 test_acc:  0.6484375\n",
            "iter:  263 train_cost:  1.0460567 train_acc:  0.625 test_cost:  0.83317727 test_acc:  0.71875\n",
            "iter:  264 train_cost:  0.9854964 train_acc:  0.671875 test_cost:  1.1153538 test_acc:  0.625\n",
            "iter:  265 train_cost:  1.1516438 train_acc:  0.625 test_cost:  1.0587188 test_acc:  0.671875\n",
            "iter:  266 train_cost:  1.1569992 train_acc:  0.6328125 test_cost:  1.0645995 test_acc:  0.6796875\n",
            "iter:  267 train_cost:  0.9469329 train_acc:  0.703125 test_cost:  1.3005314 test_acc:  0.5546875\n",
            "iter:  268 train_cost:  0.97367465 train_acc:  0.734375 test_cost:  1.1523685 test_acc:  0.640625\n",
            "iter:  269 train_cost:  1.0783398 train_acc:  0.703125 test_cost:  1.0519644 test_acc:  0.6484375\n",
            "iter:  270 train_cost:  0.9351734 train_acc:  0.6796875 test_cost:  1.0438368 test_acc:  0.609375\n",
            "iter:  271 train_cost:  1.0095209 train_acc:  0.6875 test_cost:  1.0744555 test_acc:  0.6484375\n",
            "iter:  272 train_cost:  1.0209272 train_acc:  0.6328125 test_cost:  1.071749 test_acc:  0.671875\n",
            "iter:  273 train_cost:  0.98964894 train_acc:  0.6796875 test_cost:  1.0805821 test_acc:  0.6875\n",
            "iter:  274 train_cost:  1.0130138 train_acc:  0.6328125 test_cost:  1.0320748 test_acc:  0.703125\n",
            "iter:  275 train_cost:  0.9512564 train_acc:  0.6796875 test_cost:  1.3256795 test_acc:  0.640625\n",
            "iter:  276 train_cost:  1.042933 train_acc:  0.6875 test_cost:  1.0159637 test_acc:  0.6875\n",
            "iter:  277 train_cost:  1.1020525 train_acc:  0.671875 test_cost:  1.0693281 test_acc:  0.6484375\n",
            "iter:  278 train_cost:  0.9546771 train_acc:  0.6953125 test_cost:  1.1249022 test_acc:  0.65625\n",
            "iter:  279 train_cost:  1.0414023 train_acc:  0.6875 test_cost:  1.1641986 test_acc:  0.625\n",
            "iter:  280 train_cost:  0.7990728 train_acc:  0.75 test_cost:  0.96944654 test_acc:  0.6875\n",
            "iter:  281 train_cost:  0.97352666 train_acc:  0.6953125 test_cost:  0.9267688 test_acc:  0.6796875\n",
            "iter:  282 train_cost:  0.99707997 train_acc:  0.7109375 test_cost:  0.8835145 test_acc:  0.71875\n",
            "iter:  283 train_cost:  1.1169074 train_acc:  0.6328125 test_cost:  1.0617542 test_acc:  0.59375\n",
            "iter:  284 train_cost:  1.1202221 train_acc:  0.65625 test_cost:  1.2239466 test_acc:  0.6015625\n",
            "iter:  285 train_cost:  1.2050261 train_acc:  0.6328125 test_cost:  0.8866543 test_acc:  0.7265625\n",
            "iter:  286 train_cost:  0.96789193 train_acc:  0.671875 test_cost:  1.030435 test_acc:  0.6953125\n",
            "iter:  287 train_cost:  1.1432924 train_acc:  0.640625 test_cost:  1.1432089 test_acc:  0.65625\n",
            "iter:  288 train_cost:  1.2172682 train_acc:  0.65625 test_cost:  1.1368057 test_acc:  0.640625\n",
            "iter:  289 train_cost:  0.86723727 train_acc:  0.7109375 test_cost:  1.0709255 test_acc:  0.703125\n",
            "iter:  290 train_cost:  1.1336435 train_acc:  0.640625 test_cost:  0.8722224 test_acc:  0.75\n",
            "iter:  291 train_cost:  1.0543561 train_acc:  0.640625 test_cost:  0.9627173 test_acc:  0.671875\n",
            "iter:  292 train_cost:  0.97547364 train_acc:  0.71875 test_cost:  0.93582845 test_acc:  0.6328125\n",
            "iter:  293 train_cost:  1.1915009 train_acc:  0.6328125 test_cost:  0.7964673 test_acc:  0.7265625\n",
            "iter:  294 train_cost:  0.8918135 train_acc:  0.6640625 test_cost:  0.9348595 test_acc:  0.671875\n",
            "iter:  295 train_cost:  0.9997513 train_acc:  0.65625 test_cost:  0.8846804 test_acc:  0.7109375\n",
            "iter:  296 train_cost:  0.8726935 train_acc:  0.703125 test_cost:  1.1703374 test_acc:  0.609375\n",
            "iter:  297 train_cost:  1.1110702 train_acc:  0.65625 test_cost:  1.1535622 test_acc:  0.671875\n",
            "iter:  298 train_cost:  1.2037926 train_acc:  0.6484375 test_cost:  1.2370265 test_acc:  0.6640625\n",
            "iter:  299 train_cost:  1.0158176 train_acc:  0.6875 test_cost:  0.97846335 test_acc:  0.703125\n",
            "iter:  300 train_cost:  1.1444845 train_acc:  0.65625 test_cost:  1.4312096 test_acc:  0.5546875\n",
            "iter:  301 train_cost:  0.8976404 train_acc:  0.7265625 test_cost:  0.80534846 test_acc:  0.75\n",
            "iter:  302 train_cost:  1.12925 train_acc:  0.625 test_cost:  0.8896972 test_acc:  0.703125\n",
            "iter:  303 train_cost:  0.8506717 train_acc:  0.71875 test_cost:  0.9858796 test_acc:  0.6953125\n",
            "iter:  304 train_cost:  0.7206571 train_acc:  0.7109375 test_cost:  1.2026263 test_acc:  0.6484375\n",
            "iter:  305 train_cost:  0.77674145 train_acc:  0.7578125 test_cost:  0.86123633 test_acc:  0.7265625\n",
            "iter:  306 train_cost:  0.7679162 train_acc:  0.71875 test_cost:  1.0885788 test_acc:  0.625\n",
            "iter:  307 train_cost:  1.1752939 train_acc:  0.6640625 test_cost:  0.8974811 test_acc:  0.7421875\n",
            "iter:  308 train_cost:  1.0364698 train_acc:  0.6640625 test_cost:  1.0621037 test_acc:  0.6484375\n",
            "iter:  309 train_cost:  0.9481271 train_acc:  0.7109375 test_cost:  0.98718214 test_acc:  0.734375\n",
            "iter:  310 train_cost:  0.7734421 train_acc:  0.7734375 test_cost:  1.1911999 test_acc:  0.6953125\n",
            "iter:  311 train_cost:  1.141756 train_acc:  0.640625 test_cost:  1.004771 test_acc:  0.6796875\n",
            "iter:  312 train_cost:  1.077493 train_acc:  0.65625 test_cost:  0.9272107 test_acc:  0.7109375\n",
            "iter:  313 train_cost:  0.8654263 train_acc:  0.71875 test_cost:  1.2444768 test_acc:  0.6640625\n",
            "iter:  314 train_cost:  0.86745965 train_acc:  0.734375 test_cost:  0.9721549 test_acc:  0.71875\n",
            "iter:  315 train_cost:  0.9494685 train_acc:  0.6953125 test_cost:  0.99236286 test_acc:  0.6875\n",
            "iter:  316 train_cost:  0.99754333 train_acc:  0.7265625 test_cost:  1.1670157 test_acc:  0.640625\n",
            "iter:  317 train_cost:  0.8742335 train_acc:  0.7265625 test_cost:  0.9729588 test_acc:  0.6484375\n",
            "iter:  318 train_cost:  1.0792581 train_acc:  0.6640625 test_cost:  0.91790926 test_acc:  0.71875\n",
            "iter:  319 train_cost:  0.9003469 train_acc:  0.71875 test_cost:  0.82070297 test_acc:  0.765625\n",
            "iter:  320 train_cost:  0.9054417 train_acc:  0.671875 test_cost:  0.97625524 test_acc:  0.703125\n",
            "iter:  321 train_cost:  1.1972773 train_acc:  0.65625 test_cost:  0.7078229 test_acc:  0.7890625\n",
            "iter:  322 train_cost:  1.0113969 train_acc:  0.7265625 test_cost:  0.8381394 test_acc:  0.7421875\n",
            "iter:  323 train_cost:  1.0134652 train_acc:  0.671875 test_cost:  1.1035757 test_acc:  0.6640625\n",
            "iter:  324 train_cost:  0.9058869 train_acc:  0.671875 test_cost:  0.6888134 test_acc:  0.7734375\n",
            "iter:  325 train_cost:  0.95517784 train_acc:  0.7109375 test_cost:  0.9871837 test_acc:  0.6953125\n",
            "iter:  326 train_cost:  1.1953244 train_acc:  0.640625 test_cost:  0.7746702 test_acc:  0.734375\n",
            "iter:  327 train_cost:  1.0079073 train_acc:  0.6640625 test_cost:  0.8015319 test_acc:  0.703125\n",
            "iter:  328 train_cost:  0.8918494 train_acc:  0.703125 test_cost:  0.74278283 test_acc:  0.7421875\n",
            "iter:  329 train_cost:  1.3383127 train_acc:  0.640625 test_cost:  0.831401 test_acc:  0.71875\n",
            "iter:  330 train_cost:  1.0365366 train_acc:  0.7109375 test_cost:  0.9706845 test_acc:  0.671875\n",
            "iter:  331 train_cost:  0.78300434 train_acc:  0.71875 test_cost:  0.96001 test_acc:  0.6875\n",
            "iter:  332 train_cost:  1.1310031 train_acc:  0.6875 test_cost:  0.9206955 test_acc:  0.6953125\n",
            "iter:  333 train_cost:  1.211372 train_acc:  0.6484375 test_cost:  1.037925 test_acc:  0.734375\n",
            "iter:  334 train_cost:  0.7360174 train_acc:  0.7734375 test_cost:  0.7696782 test_acc:  0.78125\n",
            "iter:  335 train_cost:  0.92339873 train_acc:  0.6796875 test_cost:  0.77426684 test_acc:  0.75\n",
            "iter:  336 train_cost:  1.0258033 train_acc:  0.7265625 test_cost:  0.93410206 test_acc:  0.6875\n",
            "iter:  337 train_cost:  0.94696724 train_acc:  0.71875 test_cost:  1.0788598 test_acc:  0.71875\n",
            "iter:  338 train_cost:  1.0278558 train_acc:  0.6875 test_cost:  0.8812529 test_acc:  0.734375\n",
            "iter:  339 train_cost:  0.99963725 train_acc:  0.703125 test_cost:  0.8924277 test_acc:  0.734375\n",
            "iter:  340 train_cost:  1.1787791 train_acc:  0.6328125 test_cost:  1.0620061 test_acc:  0.6640625\n",
            "iter:  341 train_cost:  0.78953385 train_acc:  0.75 test_cost:  0.7821783 test_acc:  0.71875\n",
            "iter:  342 train_cost:  0.82154405 train_acc:  0.75 test_cost:  1.0035007 test_acc:  0.6875\n",
            "iter:  343 train_cost:  1.029275 train_acc:  0.7421875 test_cost:  0.9045777 test_acc:  0.71875\n",
            "iter:  344 train_cost:  0.7768092 train_acc:  0.7734375 test_cost:  0.9017353 test_acc:  0.7265625\n",
            "iter:  345 train_cost:  0.9781512 train_acc:  0.6953125 test_cost:  0.91248596 test_acc:  0.703125\n",
            "iter:  346 train_cost:  0.7908954 train_acc:  0.7578125 test_cost:  0.8601912 test_acc:  0.7109375\n",
            "iter:  347 train_cost:  0.9232129 train_acc:  0.7265625 test_cost:  1.036244 test_acc:  0.6796875\n",
            "iter:  348 train_cost:  0.900671 train_acc:  0.71875 test_cost:  0.8627366 test_acc:  0.7734375\n",
            "iter:  349 train_cost:  0.916523 train_acc:  0.7109375 test_cost:  0.8352407 test_acc:  0.7421875\n",
            "iter:  350 train_cost:  0.81828654 train_acc:  0.734375 test_cost:  0.81709003 test_acc:  0.7421875\n",
            "iter:  351 train_cost:  1.000997 train_acc:  0.703125 test_cost:  0.817216 test_acc:  0.71875\n",
            "iter:  352 train_cost:  0.8194319 train_acc:  0.765625 test_cost:  0.8731227 test_acc:  0.75\n",
            "iter:  353 train_cost:  0.85486555 train_acc:  0.71875 test_cost:  0.98241705 test_acc:  0.6640625\n",
            "iter:  354 train_cost:  0.817644 train_acc:  0.7734375 test_cost:  0.9567885 test_acc:  0.6875\n",
            "iter:  355 train_cost:  0.88833535 train_acc:  0.75 test_cost:  0.6586244 test_acc:  0.796875\n",
            "iter:  356 train_cost:  0.7263069 train_acc:  0.78125 test_cost:  1.19517 test_acc:  0.6328125\n",
            "iter:  357 train_cost:  0.7436831 train_acc:  0.75 test_cost:  0.7412739 test_acc:  0.734375\n",
            "iter:  358 train_cost:  0.924091 train_acc:  0.6484375 test_cost:  0.86217034 test_acc:  0.703125\n",
            "iter:  359 train_cost:  0.87969476 train_acc:  0.734375 test_cost:  0.6991384 test_acc:  0.7734375\n",
            "iter:  360 train_cost:  1.0434754 train_acc:  0.71875 test_cost:  1.0355582 test_acc:  0.59375\n",
            "iter:  361 train_cost:  1.0143001 train_acc:  0.7265625 test_cost:  0.88537705 test_acc:  0.7109375\n",
            "iter:  362 train_cost:  0.7832713 train_acc:  0.75 test_cost:  0.87202096 test_acc:  0.7421875\n",
            "iter:  363 train_cost:  0.9177663 train_acc:  0.71875 test_cost:  0.9042144 test_acc:  0.6640625\n",
            "iter:  364 train_cost:  0.8028544 train_acc:  0.7421875 test_cost:  0.9033302 test_acc:  0.65625\n",
            "iter:  365 train_cost:  1.0399492 train_acc:  0.671875 test_cost:  1.0474265 test_acc:  0.7265625\n",
            "iter:  366 train_cost:  0.92868006 train_acc:  0.734375 test_cost:  1.0041476 test_acc:  0.640625\n",
            "iter:  367 train_cost:  1.04845 train_acc:  0.6875 test_cost:  0.79151225 test_acc:  0.7578125\n",
            "iter:  368 train_cost:  0.7041453 train_acc:  0.78125 test_cost:  0.77979255 test_acc:  0.75\n",
            "iter:  369 train_cost:  0.7232423 train_acc:  0.703125 test_cost:  0.948133 test_acc:  0.7109375\n",
            "iter:  370 train_cost:  0.91936255 train_acc:  0.6953125 test_cost:  0.82793146 test_acc:  0.7734375\n",
            "iter:  371 train_cost:  0.8294766 train_acc:  0.75 test_cost:  0.8356967 test_acc:  0.75\n",
            "iter:  372 train_cost:  1.1943829 train_acc:  0.671875 test_cost:  0.8746176 test_acc:  0.6953125\n",
            "iter:  373 train_cost:  0.6685827 train_acc:  0.78125 test_cost:  1.0017443 test_acc:  0.734375\n",
            "iter:  374 train_cost:  0.61006606 train_acc:  0.8046875 test_cost:  0.94930106 test_acc:  0.6953125\n",
            "iter:  375 train_cost:  0.7742117 train_acc:  0.734375 test_cost:  0.6921282 test_acc:  0.78125\n",
            "iter:  376 train_cost:  0.9267945 train_acc:  0.7265625 test_cost:  0.8823894 test_acc:  0.734375\n",
            "iter:  377 train_cost:  0.84680456 train_acc:  0.75 test_cost:  0.8936633 test_acc:  0.6875\n",
            "iter:  378 train_cost:  0.7441 train_acc:  0.7421875 test_cost:  0.86241215 test_acc:  0.7578125\n",
            "iter:  379 train_cost:  0.87020034 train_acc:  0.75 test_cost:  0.6866355 test_acc:  0.765625\n",
            "iter:  380 train_cost:  0.7733979 train_acc:  0.7890625 test_cost:  0.810814 test_acc:  0.7265625\n",
            "iter:  381 train_cost:  0.87518656 train_acc:  0.7421875 test_cost:  1.0252403 test_acc:  0.671875\n",
            "iter:  382 train_cost:  0.9245234 train_acc:  0.703125 test_cost:  1.1378655 test_acc:  0.6875\n",
            "iter:  383 train_cost:  0.82574284 train_acc:  0.7421875 test_cost:  0.7624072 test_acc:  0.734375\n",
            "iter:  384 train_cost:  0.86130476 train_acc:  0.7578125 test_cost:  1.0592492 test_acc:  0.6328125\n",
            "iter:  385 train_cost:  1.0337906 train_acc:  0.71875 test_cost:  0.8452836 test_acc:  0.7578125\n",
            "iter:  386 train_cost:  0.67681944 train_acc:  0.7734375 test_cost:  0.8493792 test_acc:  0.6953125\n",
            "iter:  387 train_cost:  0.6155106 train_acc:  0.8046875 test_cost:  0.97018117 test_acc:  0.71875\n",
            "iter:  388 train_cost:  0.79535115 train_acc:  0.7578125 test_cost:  0.81603515 test_acc:  0.71875\n",
            "iter:  389 train_cost:  0.841737 train_acc:  0.71875 test_cost:  0.7033427 test_acc:  0.7890625\n",
            "iter:  390 train_cost:  0.8341905 train_acc:  0.75 test_cost:  0.9396124 test_acc:  0.71875\n",
            "iter:  391 train_cost:  0.8846532 train_acc:  0.7265625 test_cost:  0.7403418 test_acc:  0.7109375\n",
            "iter:  392 train_cost:  0.86590254 train_acc:  0.765625 test_cost:  0.85443234 test_acc:  0.7421875\n",
            "iter:  393 train_cost:  0.7713824 train_acc:  0.7890625 test_cost:  0.84626085 test_acc:  0.7421875\n",
            "iter:  394 train_cost:  0.75954235 train_acc:  0.7734375 test_cost:  0.85138166 test_acc:  0.765625\n",
            "iter:  395 train_cost:  0.5672918 train_acc:  0.828125 test_cost:  0.5482786 test_acc:  0.8046875\n",
            "iter:  396 train_cost:  0.6163566 train_acc:  0.7890625 test_cost:  0.64911175 test_acc:  0.796875\n",
            "iter:  397 train_cost:  0.88152677 train_acc:  0.71875 test_cost:  0.79296476 test_acc:  0.7109375\n",
            "iter:  398 train_cost:  0.7706563 train_acc:  0.7421875 test_cost:  0.84385157 test_acc:  0.7578125\n",
            "iter:  399 train_cost:  0.8575525 train_acc:  0.7421875 test_cost:  0.9751557 test_acc:  0.71875\n",
            "iter:  400 train_cost:  0.95788527 train_acc:  0.6953125 test_cost:  0.9323652 test_acc:  0.71875\n",
            "iter:  401 train_cost:  0.6312947 train_acc:  0.8046875 test_cost:  0.9320481 test_acc:  0.7265625\n",
            "iter:  402 train_cost:  0.8039959 train_acc:  0.765625 test_cost:  0.81832266 test_acc:  0.7578125\n",
            "iter:  403 train_cost:  0.77295506 train_acc:  0.71875 test_cost:  0.7507135 test_acc:  0.765625\n",
            "iter:  404 train_cost:  0.86269414 train_acc:  0.6640625 test_cost:  0.7865143 test_acc:  0.7265625\n",
            "iter:  405 train_cost:  0.76484835 train_acc:  0.7421875 test_cost:  0.7734369 test_acc:  0.7890625\n",
            "iter:  406 train_cost:  0.8542044 train_acc:  0.6953125 test_cost:  0.7701409 test_acc:  0.7265625\n",
            "iter:  407 train_cost:  0.89990366 train_acc:  0.7421875 test_cost:  0.7095833 test_acc:  0.7890625\n",
            "iter:  408 train_cost:  1.0375152 train_acc:  0.640625 test_cost:  0.87645054 test_acc:  0.703125\n",
            "iter:  409 train_cost:  0.7705649 train_acc:  0.7578125 test_cost:  0.9512044 test_acc:  0.6953125\n",
            "iter:  410 train_cost:  0.7197875 train_acc:  0.78125 test_cost:  0.80078053 test_acc:  0.71875\n",
            "iter:  411 train_cost:  0.7832699 train_acc:  0.7734375 test_cost:  0.7970013 test_acc:  0.7265625\n",
            "iter:  412 train_cost:  0.74391484 train_acc:  0.7578125 test_cost:  0.8798824 test_acc:  0.765625\n",
            "iter:  413 train_cost:  0.9560976 train_acc:  0.71875 test_cost:  0.8347018 test_acc:  0.765625\n",
            "iter:  414 train_cost:  0.7354821 train_acc:  0.7734375 test_cost:  0.73143363 test_acc:  0.7578125\n",
            "iter:  415 train_cost:  1.0955746 train_acc:  0.703125 test_cost:  0.88037604 test_acc:  0.7265625\n",
            "iter:  416 train_cost:  0.77392185 train_acc:  0.7578125 test_cost:  0.84204257 test_acc:  0.671875\n",
            "iter:  417 train_cost:  0.8195063 train_acc:  0.7265625 test_cost:  0.8258903 test_acc:  0.75\n",
            "iter:  418 train_cost:  0.91002196 train_acc:  0.7421875 test_cost:  0.75027514 test_acc:  0.7890625\n",
            "iter:  419 train_cost:  0.79327995 train_acc:  0.7734375 test_cost:  0.6099609 test_acc:  0.8046875\n",
            "iter:  420 train_cost:  0.8324052 train_acc:  0.765625 test_cost:  0.82731986 test_acc:  0.71875\n",
            "iter:  421 train_cost:  0.98375976 train_acc:  0.7109375 test_cost:  0.7827387 test_acc:  0.78125\n",
            "iter:  422 train_cost:  0.70304114 train_acc:  0.7890625 test_cost:  0.734359 test_acc:  0.78125\n",
            "iter:  423 train_cost:  0.9152008 train_acc:  0.71875 test_cost:  0.8300735 test_acc:  0.75\n",
            "iter:  424 train_cost:  0.9473617 train_acc:  0.6953125 test_cost:  0.78742915 test_acc:  0.78125\n",
            "iter:  425 train_cost:  0.7570865 train_acc:  0.7734375 test_cost:  0.8334013 test_acc:  0.7265625\n",
            "iter:  426 train_cost:  0.99471015 train_acc:  0.6796875 test_cost:  0.6473825 test_acc:  0.78125\n",
            "iter:  427 train_cost:  0.6667841 train_acc:  0.8203125 test_cost:  0.80925536 test_acc:  0.7890625\n",
            "iter:  428 train_cost:  0.6435586 train_acc:  0.796875 test_cost:  0.92099875 test_acc:  0.7109375\n",
            "iter:  429 train_cost:  0.728746 train_acc:  0.7734375 test_cost:  0.7758148 test_acc:  0.7421875\n",
            "iter:  430 train_cost:  1.1182425 train_acc:  0.7109375 test_cost:  0.8479827 test_acc:  0.7265625\n",
            "iter:  431 train_cost:  0.89036983 train_acc:  0.71875 test_cost:  0.7048365 test_acc:  0.7734375\n",
            "iter:  432 train_cost:  0.6175963 train_acc:  0.8046875 test_cost:  0.77542657 test_acc:  0.7421875\n",
            "iter:  433 train_cost:  0.66094923 train_acc:  0.7734375 test_cost:  0.7896986 test_acc:  0.7265625\n",
            "iter:  434 train_cost:  0.6015763 train_acc:  0.765625 test_cost:  0.59116054 test_acc:  0.8046875\n",
            "iter:  435 train_cost:  0.6507976 train_acc:  0.75 test_cost:  0.5991699 test_acc:  0.796875\n",
            "iter:  436 train_cost:  0.8611816 train_acc:  0.7421875 test_cost:  0.8755743 test_acc:  0.75\n",
            "iter:  437 train_cost:  0.7437953 train_acc:  0.7578125 test_cost:  0.7030207 test_acc:  0.796875\n",
            "iter:  438 train_cost:  0.82479775 train_acc:  0.7265625 test_cost:  0.86876464 test_acc:  0.71875\n",
            "iter:  439 train_cost:  0.7081857 train_acc:  0.796875 test_cost:  1.0551703 test_acc:  0.7109375\n",
            "iter:  440 train_cost:  0.89459896 train_acc:  0.7578125 test_cost:  0.7864679 test_acc:  0.8046875\n",
            "iter:  441 train_cost:  0.52196026 train_acc:  0.796875 test_cost:  0.98036325 test_acc:  0.6875\n",
            "iter:  442 train_cost:  0.831702 train_acc:  0.765625 test_cost:  0.83450294 test_acc:  0.7578125\n",
            "iter:  443 train_cost:  0.6611551 train_acc:  0.7734375 test_cost:  0.73435616 test_acc:  0.765625\n",
            "iter:  444 train_cost:  0.85671294 train_acc:  0.7109375 test_cost:  0.9915569 test_acc:  0.671875\n",
            "iter:  445 train_cost:  0.66343796 train_acc:  0.78125 test_cost:  0.9056921 test_acc:  0.7109375\n",
            "iter:  446 train_cost:  0.73288053 train_acc:  0.7578125 test_cost:  0.73157346 test_acc:  0.71875\n",
            "iter:  447 train_cost:  0.76697254 train_acc:  0.7734375 test_cost:  0.6804003 test_acc:  0.78125\n",
            "iter:  448 train_cost:  0.79567486 train_acc:  0.7890625 test_cost:  0.7297864 test_acc:  0.75\n",
            "iter:  449 train_cost:  0.9354555 train_acc:  0.6875 test_cost:  0.81832004 test_acc:  0.7578125\n",
            "iter:  450 train_cost:  0.87309843 train_acc:  0.75 test_cost:  0.90412396 test_acc:  0.7109375\n",
            "iter:  451 train_cost:  0.663482 train_acc:  0.7890625 test_cost:  0.7657593 test_acc:  0.7265625\n",
            "iter:  452 train_cost:  0.69850767 train_acc:  0.7578125 test_cost:  0.838836 test_acc:  0.7890625\n",
            "iter:  453 train_cost:  0.7577472 train_acc:  0.7578125 test_cost:  0.7935822 test_acc:  0.7109375\n",
            "iter:  454 train_cost:  0.6358739 train_acc:  0.8359375 test_cost:  0.84396815 test_acc:  0.7265625\n",
            "iter:  455 train_cost:  0.77587247 train_acc:  0.796875 test_cost:  0.6839457 test_acc:  0.7421875\n",
            "iter:  456 train_cost:  0.7220583 train_acc:  0.7890625 test_cost:  0.71534425 test_acc:  0.78125\n",
            "iter:  457 train_cost:  0.7604999 train_acc:  0.78125 test_cost:  0.7656045 test_acc:  0.7578125\n",
            "iter:  458 train_cost:  0.6524816 train_acc:  0.7890625 test_cost:  0.7552371 test_acc:  0.7734375\n",
            "iter:  459 train_cost:  0.8746241 train_acc:  0.6953125 test_cost:  0.8518964 test_acc:  0.734375\n",
            "iter:  460 train_cost:  0.84828544 train_acc:  0.7265625 test_cost:  0.74452394 test_acc:  0.734375\n",
            "iter:  461 train_cost:  0.6574626 train_acc:  0.828125 test_cost:  0.5779875 test_acc:  0.8203125\n",
            "iter:  462 train_cost:  0.59126115 train_acc:  0.828125 test_cost:  0.81866336 test_acc:  0.765625\n",
            "iter:  463 train_cost:  0.7815807 train_acc:  0.765625 test_cost:  0.8245599 test_acc:  0.71875\n",
            "iter:  464 train_cost:  0.6786033 train_acc:  0.8203125 test_cost:  0.76118827 test_acc:  0.7890625\n",
            "iter:  465 train_cost:  0.6244149 train_acc:  0.796875 test_cost:  0.773429 test_acc:  0.7421875\n",
            "iter:  466 train_cost:  0.65386766 train_acc:  0.7265625 test_cost:  0.66371727 test_acc:  0.78125\n",
            "iter:  467 train_cost:  0.7932111 train_acc:  0.7578125 test_cost:  0.71639866 test_acc:  0.78125\n",
            "iter:  468 train_cost:  0.72572076 train_acc:  0.7421875 test_cost:  0.880721 test_acc:  0.7265625\n",
            "iter:  469 train_cost:  0.812913 train_acc:  0.734375 test_cost:  0.64552975 test_acc:  0.796875\n",
            "iter:  470 train_cost:  0.67518055 train_acc:  0.7578125 test_cost:  0.7356372 test_acc:  0.734375\n",
            "iter:  471 train_cost:  0.7122997 train_acc:  0.7734375 test_cost:  0.6865394 test_acc:  0.7578125\n",
            "iter:  472 train_cost:  0.7089596 train_acc:  0.796875 test_cost:  0.97580004 test_acc:  0.71875\n",
            "iter:  473 train_cost:  0.82306296 train_acc:  0.6953125 test_cost:  0.95292056 test_acc:  0.7265625\n",
            "iter:  474 train_cost:  0.76119983 train_acc:  0.7578125 test_cost:  0.77270365 test_acc:  0.7578125\n",
            "iter:  475 train_cost:  0.7625644 train_acc:  0.734375 test_cost:  0.8642106 test_acc:  0.71875\n",
            "iter:  476 train_cost:  0.7126641 train_acc:  0.7578125 test_cost:  0.8160817 test_acc:  0.78125\n",
            "iter:  477 train_cost:  0.8475069 train_acc:  0.75 test_cost:  0.47917828 test_acc:  0.8515625\n",
            "iter:  478 train_cost:  0.7603989 train_acc:  0.734375 test_cost:  0.7525891 test_acc:  0.7734375\n",
            "iter:  479 train_cost:  0.85818386 train_acc:  0.75 test_cost:  0.56932104 test_acc:  0.8046875\n",
            "iter:  480 train_cost:  0.7365771 train_acc:  0.7734375 test_cost:  0.6673626 test_acc:  0.8046875\n",
            "iter:  481 train_cost:  0.56563044 train_acc:  0.828125 test_cost:  0.7576647 test_acc:  0.7421875\n",
            "iter:  482 train_cost:  0.5589806 train_acc:  0.8203125 test_cost:  0.8151293 test_acc:  0.7265625\n",
            "iter:  483 train_cost:  0.7629626 train_acc:  0.7578125 test_cost:  0.76479733 test_acc:  0.7265625\n",
            "iter:  484 train_cost:  0.59426564 train_acc:  0.8203125 test_cost:  0.817123 test_acc:  0.734375\n",
            "iter:  485 train_cost:  0.58313084 train_acc:  0.8203125 test_cost:  0.5745733 test_acc:  0.8359375\n",
            "iter:  486 train_cost:  0.6003194 train_acc:  0.828125 test_cost:  0.7370915 test_acc:  0.7421875\n",
            "iter:  487 train_cost:  0.67696 train_acc:  0.78125 test_cost:  0.6070135 test_acc:  0.828125\n",
            "iter:  488 train_cost:  0.42001897 train_acc:  0.8671875 test_cost:  0.87896526 test_acc:  0.671875\n",
            "iter:  489 train_cost:  0.85525835 train_acc:  0.703125 test_cost:  0.7045293 test_acc:  0.796875\n",
            "iter:  490 train_cost:  0.5920311 train_acc:  0.8046875 test_cost:  0.7732269 test_acc:  0.7578125\n",
            "iter:  491 train_cost:  0.7039616 train_acc:  0.8046875 test_cost:  0.6206742 test_acc:  0.8046875\n",
            "iter:  492 train_cost:  0.7426139 train_acc:  0.75 test_cost:  0.85163355 test_acc:  0.7421875\n",
            "iter:  493 train_cost:  0.8245985 train_acc:  0.7109375 test_cost:  0.6306383 test_acc:  0.796875\n",
            "iter:  494 train_cost:  0.6189965 train_acc:  0.796875 test_cost:  0.74927753 test_acc:  0.7890625\n",
            "iter:  495 train_cost:  0.77130705 train_acc:  0.7265625 test_cost:  0.8370944 test_acc:  0.71875\n",
            "iter:  496 train_cost:  0.86629206 train_acc:  0.765625 test_cost:  0.90596914 test_acc:  0.796875\n",
            "iter:  497 train_cost:  0.65777606 train_acc:  0.8046875 test_cost:  0.7558741 test_acc:  0.7578125\n",
            "iter:  498 train_cost:  0.59063005 train_acc:  0.78125 test_cost:  0.79981863 test_acc:  0.7421875\n",
            "iter:  499 train_cost:  0.7580118 train_acc:  0.7421875 test_cost:  0.5917578 test_acc:  0.78125\n",
            "iter:  500 train_cost:  0.878336 train_acc:  0.7109375 test_cost:  0.65862423 test_acc:  0.78125\n",
            "iter:  501 train_cost:  0.7710599 train_acc:  0.7421875 test_cost:  0.5801368 test_acc:  0.8203125\n",
            "iter:  502 train_cost:  0.76245993 train_acc:  0.7734375 test_cost:  0.8587404 test_acc:  0.7265625\n",
            "iter:  503 train_cost:  0.78811264 train_acc:  0.7421875 test_cost:  0.7313342 test_acc:  0.7578125\n",
            "iter:  504 train_cost:  0.7934816 train_acc:  0.7890625 test_cost:  0.7487259 test_acc:  0.796875\n",
            "iter:  505 train_cost:  0.8237099 train_acc:  0.78125 test_cost:  0.66769546 test_acc:  0.78125\n",
            "iter:  506 train_cost:  0.77924097 train_acc:  0.75 test_cost:  0.71411973 test_acc:  0.8046875\n",
            "iter:  507 train_cost:  0.8267808 train_acc:  0.7421875 test_cost:  0.8675314 test_acc:  0.78125\n",
            "iter:  508 train_cost:  0.606804 train_acc:  0.875 test_cost:  0.89657724 test_acc:  0.7421875\n",
            "iter:  509 train_cost:  0.7892606 train_acc:  0.7421875 test_cost:  0.8211016 test_acc:  0.765625\n",
            "iter:  510 train_cost:  0.81043327 train_acc:  0.7421875 test_cost:  0.71621716 test_acc:  0.7421875\n",
            "iter:  511 train_cost:  0.6240091 train_acc:  0.828125 test_cost:  0.6430247 test_acc:  0.8125\n",
            "iter:  512 train_cost:  0.87181675 train_acc:  0.7109375 test_cost:  0.9123244 test_acc:  0.7265625\n",
            "iter:  513 train_cost:  0.6249229 train_acc:  0.8125 test_cost:  0.7045807 test_acc:  0.78125\n",
            "iter:  514 train_cost:  0.64497495 train_acc:  0.796875 test_cost:  0.5891524 test_acc:  0.8046875\n",
            "iter:  515 train_cost:  0.68430376 train_acc:  0.7890625 test_cost:  0.7905087 test_acc:  0.7890625\n",
            "iter:  516 train_cost:  0.807004 train_acc:  0.7578125 test_cost:  0.70643306 test_acc:  0.7578125\n",
            "iter:  517 train_cost:  0.5420169 train_acc:  0.796875 test_cost:  0.6850909 test_acc:  0.78125\n",
            "iter:  518 train_cost:  0.9025234 train_acc:  0.7578125 test_cost:  0.63339806 test_acc:  0.8125\n",
            "iter:  519 train_cost:  0.638786 train_acc:  0.8125 test_cost:  0.66066253 test_acc:  0.7890625\n",
            "iter:  520 train_cost:  0.71933055 train_acc:  0.78125 test_cost:  0.530112 test_acc:  0.796875\n",
            "iter:  521 train_cost:  0.7423852 train_acc:  0.7734375 test_cost:  0.5231837 test_acc:  0.8671875\n",
            "iter:  522 train_cost:  0.5732372 train_acc:  0.8125 test_cost:  0.701441 test_acc:  0.796875\n",
            "iter:  523 train_cost:  0.7055981 train_acc:  0.7890625 test_cost:  0.75836885 test_acc:  0.78125\n",
            "iter:  524 train_cost:  0.66749114 train_acc:  0.828125 test_cost:  0.79029274 test_acc:  0.734375\n",
            "iter:  525 train_cost:  0.60865474 train_acc:  0.796875 test_cost:  0.6091906 test_acc:  0.8046875\n",
            "iter:  526 train_cost:  0.74045074 train_acc:  0.8125 test_cost:  0.7848912 test_acc:  0.7265625\n",
            "iter:  527 train_cost:  0.736181 train_acc:  0.78125 test_cost:  0.718307 test_acc:  0.75\n",
            "iter:  528 train_cost:  0.5681454 train_acc:  0.796875 test_cost:  0.7223202 test_acc:  0.7734375\n",
            "iter:  529 train_cost:  0.7695991 train_acc:  0.7421875 test_cost:  0.67674357 test_acc:  0.734375\n",
            "iter:  530 train_cost:  0.6381502 train_acc:  0.828125 test_cost:  0.59278154 test_acc:  0.7890625\n",
            "iter:  531 train_cost:  0.63160646 train_acc:  0.8203125 test_cost:  0.50164354 test_acc:  0.859375\n",
            "iter:  532 train_cost:  0.598369 train_acc:  0.8203125 test_cost:  0.68699163 test_acc:  0.7578125\n",
            "iter:  533 train_cost:  0.8911689 train_acc:  0.7109375 test_cost:  0.5915509 test_acc:  0.828125\n",
            "iter:  534 train_cost:  0.46163476 train_acc:  0.84375 test_cost:  0.7798367 test_acc:  0.78125\n",
            "iter:  535 train_cost:  0.7082373 train_acc:  0.765625 test_cost:  0.7585046 test_acc:  0.7734375\n",
            "iter:  536 train_cost:  0.55363554 train_acc:  0.8125 test_cost:  0.6413077 test_acc:  0.7890625\n",
            "iter:  537 train_cost:  0.7664056 train_acc:  0.7734375 test_cost:  0.56016266 test_acc:  0.8203125\n",
            "iter:  538 train_cost:  0.6508266 train_acc:  0.8203125 test_cost:  0.7947016 test_acc:  0.6953125\n",
            "iter:  539 train_cost:  0.6010838 train_acc:  0.8046875 test_cost:  0.8169466 test_acc:  0.75\n",
            "iter:  540 train_cost:  0.7439962 train_acc:  0.7578125 test_cost:  0.81779623 test_acc:  0.7890625\n",
            "iter:  541 train_cost:  0.6508619 train_acc:  0.796875 test_cost:  0.6468113 test_acc:  0.8125\n",
            "iter:  542 train_cost:  0.77599907 train_acc:  0.75 test_cost:  0.65630144 test_acc:  0.8359375\n",
            "iter:  543 train_cost:  0.57426155 train_acc:  0.828125 test_cost:  0.8394204 test_acc:  0.734375\n",
            "iter:  544 train_cost:  0.6042973 train_acc:  0.765625 test_cost:  0.650993 test_acc:  0.7890625\n",
            "iter:  545 train_cost:  0.54277384 train_acc:  0.8125 test_cost:  0.70435894 test_acc:  0.75\n",
            "iter:  546 train_cost:  0.5077029 train_acc:  0.8515625 test_cost:  0.5846874 test_acc:  0.8046875\n",
            "iter:  547 train_cost:  0.7166716 train_acc:  0.7890625 test_cost:  0.54547197 test_acc:  0.8203125\n",
            "iter:  548 train_cost:  0.6623966 train_acc:  0.7734375 test_cost:  0.67378414 test_acc:  0.828125\n",
            "iter:  549 train_cost:  0.672485 train_acc:  0.7734375 test_cost:  0.6022185 test_acc:  0.8046875\n",
            "iter:  550 train_cost:  0.69478786 train_acc:  0.796875 test_cost:  0.5215031 test_acc:  0.84375\n",
            "iter:  551 train_cost:  0.6653198 train_acc:  0.7890625 test_cost:  0.694023 test_acc:  0.7578125\n",
            "iter:  552 train_cost:  0.47352695 train_acc:  0.7890625 test_cost:  0.74770194 test_acc:  0.78125\n",
            "iter:  553 train_cost:  0.68490547 train_acc:  0.765625 test_cost:  0.6478882 test_acc:  0.75\n",
            "iter:  554 train_cost:  0.73416173 train_acc:  0.7734375 test_cost:  0.4871294 test_acc:  0.828125\n",
            "iter:  555 train_cost:  0.7522963 train_acc:  0.7890625 test_cost:  0.9352354 test_acc:  0.734375\n",
            "iter:  556 train_cost:  0.655353 train_acc:  0.8125 test_cost:  0.61874115 test_acc:  0.7734375\n",
            "iter:  557 train_cost:  0.633723 train_acc:  0.7578125 test_cost:  0.58437574 test_acc:  0.7890625\n",
            "iter:  558 train_cost:  0.7961705 train_acc:  0.8046875 test_cost:  0.6722482 test_acc:  0.75\n",
            "iter:  559 train_cost:  0.60169125 train_acc:  0.7890625 test_cost:  0.7372303 test_acc:  0.7578125\n",
            "iter:  560 train_cost:  0.7709549 train_acc:  0.7109375 test_cost:  0.60062504 test_acc:  0.7578125\n",
            "iter:  561 train_cost:  0.6239219 train_acc:  0.7890625 test_cost:  0.45554817 test_acc:  0.84375\n",
            "iter:  562 train_cost:  0.7676819 train_acc:  0.78125 test_cost:  0.7731064 test_acc:  0.8046875\n",
            "iter:  563 train_cost:  0.5652571 train_acc:  0.8203125 test_cost:  0.5720358 test_acc:  0.78125\n",
            "iter:  564 train_cost:  0.5140458 train_acc:  0.8046875 test_cost:  0.611297 test_acc:  0.796875\n",
            "iter:  565 train_cost:  0.7046678 train_acc:  0.75 test_cost:  0.67134416 test_acc:  0.78125\n",
            "iter:  566 train_cost:  0.8508909 train_acc:  0.7734375 test_cost:  0.71913016 test_acc:  0.7734375\n",
            "iter:  567 train_cost:  0.44476146 train_acc:  0.8359375 test_cost:  0.5788172 test_acc:  0.8125\n",
            "iter:  568 train_cost:  0.5479511 train_acc:  0.84375 test_cost:  0.56499374 test_acc:  0.78125\n",
            "iter:  569 train_cost:  0.8113527 train_acc:  0.765625 test_cost:  0.6825721 test_acc:  0.8046875\n",
            "iter:  570 train_cost:  0.6175283 train_acc:  0.8046875 test_cost:  0.74352896 test_acc:  0.765625\n",
            "iter:  571 train_cost:  0.70006704 train_acc:  0.75 test_cost:  0.5742959 test_acc:  0.8359375\n",
            "iter:  572 train_cost:  0.849475 train_acc:  0.7265625 test_cost:  0.60480696 test_acc:  0.8203125\n",
            "iter:  573 train_cost:  0.64018965 train_acc:  0.859375 test_cost:  0.5727742 test_acc:  0.8046875\n",
            "iter:  574 train_cost:  0.70698327 train_acc:  0.7578125 test_cost:  0.71678853 test_acc:  0.734375\n",
            "iter:  575 train_cost:  0.44913673 train_acc:  0.8203125 test_cost:  0.5462049 test_acc:  0.7734375\n",
            "iter:  576 train_cost:  0.6458288 train_acc:  0.7890625 test_cost:  0.70373034 test_acc:  0.8046875\n",
            "iter:  577 train_cost:  0.69061816 train_acc:  0.8203125 test_cost:  0.8238257 test_acc:  0.75\n",
            "iter:  578 train_cost:  0.75501454 train_acc:  0.71875 test_cost:  0.7393133 test_acc:  0.78125\n",
            "iter:  579 train_cost:  0.62005484 train_acc:  0.8046875 test_cost:  0.6893672 test_acc:  0.7890625\n",
            "iter:  580 train_cost:  0.5746447 train_acc:  0.84375 test_cost:  0.72533804 test_acc:  0.7421875\n",
            "iter:  581 train_cost:  0.49854073 train_acc:  0.859375 test_cost:  0.6489908 test_acc:  0.8046875\n",
            "iter:  582 train_cost:  0.6452537 train_acc:  0.7890625 test_cost:  0.65725124 test_acc:  0.7890625\n",
            "iter:  583 train_cost:  0.5838789 train_acc:  0.796875 test_cost:  0.63447654 test_acc:  0.8203125\n",
            "iter:  584 train_cost:  0.6936055 train_acc:  0.75 test_cost:  0.6167596 test_acc:  0.828125\n",
            "iter:  585 train_cost:  0.632413 train_acc:  0.7890625 test_cost:  0.78827274 test_acc:  0.75\n",
            "iter:  586 train_cost:  0.7360891 train_acc:  0.75 test_cost:  0.5260587 test_acc:  0.8046875\n",
            "iter:  587 train_cost:  0.7212719 train_acc:  0.7578125 test_cost:  0.77906716 test_acc:  0.7890625\n",
            "iter:  588 train_cost:  0.62711596 train_acc:  0.796875 test_cost:  0.7128012 test_acc:  0.765625\n",
            "iter:  589 train_cost:  0.7621944 train_acc:  0.78125 test_cost:  0.5692973 test_acc:  0.8359375\n",
            "iter:  590 train_cost:  0.42049834 train_acc:  0.8671875 test_cost:  0.8927705 test_acc:  0.765625\n",
            "iter:  591 train_cost:  0.7342007 train_acc:  0.734375 test_cost:  0.6010047 test_acc:  0.765625\n",
            "iter:  592 train_cost:  0.66005635 train_acc:  0.7734375 test_cost:  0.6425884 test_acc:  0.78125\n",
            "iter:  593 train_cost:  0.728204 train_acc:  0.7734375 test_cost:  0.63579404 test_acc:  0.8125\n",
            "iter:  594 train_cost:  0.61238444 train_acc:  0.8125 test_cost:  0.6702143 test_acc:  0.765625\n",
            "iter:  595 train_cost:  0.5489765 train_acc:  0.8359375 test_cost:  0.66242844 test_acc:  0.8046875\n",
            "iter:  596 train_cost:  0.56405646 train_acc:  0.828125 test_cost:  0.7793233 test_acc:  0.7734375\n",
            "iter:  597 train_cost:  0.7928231 train_acc:  0.78125 test_cost:  0.7221249 test_acc:  0.8046875\n",
            "iter:  598 train_cost:  0.66901517 train_acc:  0.7734375 test_cost:  0.8258176 test_acc:  0.734375\n",
            "iter:  599 train_cost:  0.56925464 train_acc:  0.8359375 test_cost:  0.52232826 test_acc:  0.859375\n",
            "iter:  600 train_cost:  0.71212924 train_acc:  0.796875 test_cost:  0.70773625 test_acc:  0.7734375\n",
            "iter:  601 train_cost:  0.6815399 train_acc:  0.7890625 test_cost:  0.75163406 test_acc:  0.8046875\n",
            "iter:  602 train_cost:  0.40074795 train_acc:  0.890625 test_cost:  0.6669842 test_acc:  0.8203125\n",
            "iter:  603 train_cost:  0.59947693 train_acc:  0.828125 test_cost:  0.6451498 test_acc:  0.8046875\n",
            "iter:  604 train_cost:  0.6139917 train_acc:  0.8046875 test_cost:  0.6461587 test_acc:  0.78125\n",
            "iter:  605 train_cost:  0.6890511 train_acc:  0.7890625 test_cost:  0.7088698 test_acc:  0.7421875\n",
            "iter:  606 train_cost:  0.6528826 train_acc:  0.8125 test_cost:  0.7206378 test_acc:  0.796875\n",
            "iter:  607 train_cost:  0.56510234 train_acc:  0.859375 test_cost:  0.51843786 test_acc:  0.8359375\n",
            "iter:  608 train_cost:  0.778625 train_acc:  0.75 test_cost:  0.75781685 test_acc:  0.7734375\n",
            "iter:  609 train_cost:  0.8180115 train_acc:  0.78125 test_cost:  0.6858833 test_acc:  0.78125\n",
            "iter:  610 train_cost:  0.5516909 train_acc:  0.796875 test_cost:  0.6567694 test_acc:  0.78125\n",
            "iter:  611 train_cost:  0.7638648 train_acc:  0.703125 test_cost:  0.61771274 test_acc:  0.828125\n",
            "iter:  612 train_cost:  0.5400779 train_acc:  0.828125 test_cost:  0.49000663 test_acc:  0.8671875\n",
            "iter:  613 train_cost:  0.6797537 train_acc:  0.75 test_cost:  0.81269 test_acc:  0.7421875\n",
            "iter:  614 train_cost:  0.6982374 train_acc:  0.734375 test_cost:  0.49943203 test_acc:  0.84375\n",
            "iter:  615 train_cost:  0.5425235 train_acc:  0.828125 test_cost:  0.5398698 test_acc:  0.8203125\n",
            "iter:  616 train_cost:  0.7549584 train_acc:  0.78125 test_cost:  0.62494135 test_acc:  0.8203125\n",
            "iter:  617 train_cost:  0.6787801 train_acc:  0.78125 test_cost:  0.4824275 test_acc:  0.8515625\n",
            "iter:  618 train_cost:  0.5708593 train_acc:  0.7890625 test_cost:  0.63709044 test_acc:  0.8359375\n",
            "iter:  619 train_cost:  0.51230645 train_acc:  0.8359375 test_cost:  0.64994776 test_acc:  0.7890625\n",
            "iter:  620 train_cost:  0.5790994 train_acc:  0.8359375 test_cost:  0.5631148 test_acc:  0.8359375\n",
            "iter:  621 train_cost:  0.65138185 train_acc:  0.8125 test_cost:  0.7841903 test_acc:  0.7265625\n",
            "iter:  622 train_cost:  0.57836217 train_acc:  0.828125 test_cost:  0.6962789 test_acc:  0.765625\n",
            "iter:  623 train_cost:  0.42312557 train_acc:  0.8671875 test_cost:  0.78824633 test_acc:  0.7890625\n",
            "iter:  624 train_cost:  0.46177852 train_acc:  0.84375 test_cost:  0.5934397 test_acc:  0.8125\n",
            "iter:  625 train_cost:  0.62575424 train_acc:  0.78125 test_cost:  0.7920829 test_acc:  0.7421875\n",
            "iter:  626 train_cost:  0.5916544 train_acc:  0.8046875 test_cost:  0.63976216 test_acc:  0.765625\n",
            "iter:  627 train_cost:  0.65753883 train_acc:  0.8125 test_cost:  0.49819675 test_acc:  0.828125\n",
            "iter:  628 train_cost:  0.5232481 train_acc:  0.8359375 test_cost:  0.61655474 test_acc:  0.78125\n",
            "iter:  629 train_cost:  0.60584444 train_acc:  0.8515625 test_cost:  0.5883413 test_acc:  0.8203125\n",
            "iter:  630 train_cost:  0.40214986 train_acc:  0.828125 test_cost:  0.57924426 test_acc:  0.8359375\n",
            "iter:  631 train_cost:  0.65835774 train_acc:  0.7890625 test_cost:  0.600806 test_acc:  0.84375\n",
            "iter:  632 train_cost:  0.5704992 train_acc:  0.8125 test_cost:  0.5764832 test_acc:  0.8046875\n",
            "iter:  633 train_cost:  0.7483231 train_acc:  0.7734375 test_cost:  0.69451505 test_acc:  0.796875\n",
            "iter:  634 train_cost:  0.68474394 train_acc:  0.796875 test_cost:  0.48965326 test_acc:  0.8125\n",
            "iter:  635 train_cost:  0.48081574 train_acc:  0.8515625 test_cost:  0.51503325 test_acc:  0.828125\n",
            "iter:  636 train_cost:  0.5344776 train_acc:  0.8671875 test_cost:  0.7055836 test_acc:  0.7578125\n",
            "iter:  637 train_cost:  0.6971475 train_acc:  0.765625 test_cost:  0.7181684 test_acc:  0.7890625\n",
            "iter:  638 train_cost:  0.6025696 train_acc:  0.8125 test_cost:  0.58228385 test_acc:  0.8046875\n",
            "iter:  639 train_cost:  0.5939728 train_acc:  0.8203125 test_cost:  0.8264315 test_acc:  0.75\n",
            "iter:  640 train_cost:  0.64011383 train_acc:  0.7734375 test_cost:  0.5187249 test_acc:  0.84375\n",
            "iter:  641 train_cost:  0.7434494 train_acc:  0.765625 test_cost:  0.5975726 test_acc:  0.8046875\n",
            "iter:  642 train_cost:  0.58285564 train_acc:  0.8515625 test_cost:  0.66683817 test_acc:  0.8046875\n",
            "iter:  643 train_cost:  0.5568225 train_acc:  0.8046875 test_cost:  0.6712774 test_acc:  0.8359375\n",
            "iter:  644 train_cost:  0.7000905 train_acc:  0.78125 test_cost:  0.5276791 test_acc:  0.8203125\n",
            "iter:  645 train_cost:  0.6687199 train_acc:  0.7734375 test_cost:  0.62748253 test_acc:  0.8125\n",
            "iter:  646 train_cost:  0.6341431 train_acc:  0.796875 test_cost:  0.6234036 test_acc:  0.8125\n",
            "iter:  647 train_cost:  0.77882063 train_acc:  0.78125 test_cost:  0.7541007 test_acc:  0.7421875\n",
            "iter:  648 train_cost:  0.47544673 train_acc:  0.828125 test_cost:  0.7758024 test_acc:  0.75\n",
            "iter:  649 train_cost:  0.44493607 train_acc:  0.859375 test_cost:  0.7835127 test_acc:  0.7890625\n",
            "iter:  650 train_cost:  0.48389214 train_acc:  0.859375 test_cost:  0.5417416 test_acc:  0.84375\n",
            "iter:  651 train_cost:  0.61489207 train_acc:  0.7890625 test_cost:  0.6174046 test_acc:  0.8203125\n",
            "iter:  652 train_cost:  0.80022955 train_acc:  0.7734375 test_cost:  0.59962857 test_acc:  0.796875\n",
            "iter:  653 train_cost:  0.6478111 train_acc:  0.8203125 test_cost:  0.6401367 test_acc:  0.796875\n",
            "iter:  654 train_cost:  0.6236336 train_acc:  0.8125 test_cost:  0.5213065 test_acc:  0.828125\n",
            "iter:  655 train_cost:  0.5407841 train_acc:  0.8125 test_cost:  0.6697817 test_acc:  0.8203125\n",
            "iter:  656 train_cost:  0.57484525 train_acc:  0.8515625 test_cost:  0.6808996 test_acc:  0.796875\n",
            "iter:  657 train_cost:  0.6645965 train_acc:  0.8125 test_cost:  0.61755085 test_acc:  0.8046875\n",
            "iter:  658 train_cost:  0.60949683 train_acc:  0.796875 test_cost:  0.69094634 test_acc:  0.7734375\n",
            "iter:  659 train_cost:  0.67982864 train_acc:  0.78125 test_cost:  0.7716881 test_acc:  0.7578125\n",
            "iter:  660 train_cost:  0.5594773 train_acc:  0.828125 test_cost:  0.41520417 test_acc:  0.875\n",
            "iter:  661 train_cost:  0.50590855 train_acc:  0.84375 test_cost:  0.6438179 test_acc:  0.7734375\n",
            "iter:  662 train_cost:  0.9886416 train_acc:  0.7265625 test_cost:  0.72948563 test_acc:  0.78125\n",
            "iter:  663 train_cost:  0.62162614 train_acc:  0.78125 test_cost:  0.35463202 test_acc:  0.8828125\n",
            "iter:  664 train_cost:  0.7704253 train_acc:  0.75 test_cost:  0.5501589 test_acc:  0.84375\n",
            "iter:  665 train_cost:  0.627488 train_acc:  0.8125 test_cost:  0.85976404 test_acc:  0.734375\n",
            "iter:  666 train_cost:  0.60042584 train_acc:  0.8203125 test_cost:  0.65544903 test_acc:  0.8125\n",
            "iter:  667 train_cost:  0.6413658 train_acc:  0.7734375 test_cost:  0.69616544 test_acc:  0.8046875\n",
            "iter:  668 train_cost:  0.6768707 train_acc:  0.7734375 test_cost:  0.54949814 test_acc:  0.8125\n",
            "iter:  669 train_cost:  0.5723571 train_acc:  0.8046875 test_cost:  0.5263133 test_acc:  0.8359375\n",
            "iter:  670 train_cost:  0.58661383 train_acc:  0.8515625 test_cost:  0.68374777 test_acc:  0.8125\n",
            "iter:  671 train_cost:  0.7268595 train_acc:  0.7890625 test_cost:  0.74611104 test_acc:  0.7890625\n",
            "iter:  672 train_cost:  0.6223644 train_acc:  0.84375 test_cost:  0.4030397 test_acc:  0.8359375\n",
            "iter:  673 train_cost:  0.60218143 train_acc:  0.8125 test_cost:  0.5983173 test_acc:  0.8125\n",
            "iter:  674 train_cost:  0.5063813 train_acc:  0.84375 test_cost:  0.5761211 test_acc:  0.8359375\n",
            "iter:  675 train_cost:  0.4800958 train_acc:  0.84375 test_cost:  0.44033855 test_acc:  0.8515625\n",
            "iter:  676 train_cost:  0.5277854 train_acc:  0.8203125 test_cost:  0.61898685 test_acc:  0.8046875\n",
            "iter:  677 train_cost:  0.56775355 train_acc:  0.8125 test_cost:  0.6252079 test_acc:  0.828125\n",
            "iter:  678 train_cost:  0.47973794 train_acc:  0.8515625 test_cost:  0.55028117 test_acc:  0.859375\n",
            "iter:  679 train_cost:  0.9577898 train_acc:  0.734375 test_cost:  0.5323088 test_acc:  0.8359375\n",
            "iter:  680 train_cost:  0.69364136 train_acc:  0.8359375 test_cost:  0.50555086 test_acc:  0.84375\n",
            "iter:  681 train_cost:  0.82152426 train_acc:  0.7734375 test_cost:  0.6696718 test_acc:  0.8125\n",
            "iter:  682 train_cost:  0.64037204 train_acc:  0.8046875 test_cost:  0.70687044 test_acc:  0.8125\n",
            "iter:  683 train_cost:  0.702358 train_acc:  0.7734375 test_cost:  0.7968472 test_acc:  0.765625\n",
            "iter:  684 train_cost:  0.7089542 train_acc:  0.7890625 test_cost:  0.55335796 test_acc:  0.8203125\n",
            "iter:  685 train_cost:  0.5205537 train_acc:  0.8125 test_cost:  0.6052279 test_acc:  0.796875\n",
            "iter:  686 train_cost:  0.7006173 train_acc:  0.765625 test_cost:  0.7185057 test_acc:  0.78125\n",
            "iter:  687 train_cost:  0.6735164 train_acc:  0.796875 test_cost:  0.726061 test_acc:  0.765625\n",
            "iter:  688 train_cost:  0.58788633 train_acc:  0.8203125 test_cost:  0.36209548 test_acc:  0.859375\n",
            "iter:  689 train_cost:  0.70526475 train_acc:  0.78125 test_cost:  0.62927437 test_acc:  0.765625\n",
            "iter:  690 train_cost:  0.71763086 train_acc:  0.7734375 test_cost:  0.33566892 test_acc:  0.8984375\n",
            "iter:  691 train_cost:  0.42691535 train_acc:  0.84375 test_cost:  0.56668806 test_acc:  0.8515625\n",
            "iter:  692 train_cost:  0.80075383 train_acc:  0.796875 test_cost:  0.6739618 test_acc:  0.78125\n",
            "iter:  693 train_cost:  0.6956123 train_acc:  0.8125 test_cost:  0.5459224 test_acc:  0.8125\n",
            "iter:  694 train_cost:  0.74247694 train_acc:  0.7421875 test_cost:  0.78034604 test_acc:  0.7890625\n",
            "iter:  695 train_cost:  0.5384643 train_acc:  0.8203125 test_cost:  0.420043 test_acc:  0.8515625\n",
            "iter:  696 train_cost:  0.58397746 train_acc:  0.8046875 test_cost:  0.6257527 test_acc:  0.8203125\n",
            "iter:  697 train_cost:  0.68200195 train_acc:  0.7734375 test_cost:  0.45476276 test_acc:  0.8515625\n",
            "iter:  698 train_cost:  0.55842185 train_acc:  0.828125 test_cost:  0.6031359 test_acc:  0.8203125\n",
            "iter:  699 train_cost:  0.55651146 train_acc:  0.8125 test_cost:  0.79829454 test_acc:  0.75\n",
            "iter:  700 train_cost:  0.7138758 train_acc:  0.78125 test_cost:  0.6397302 test_acc:  0.796875\n",
            "iter:  701 train_cost:  0.5845175 train_acc:  0.796875 test_cost:  0.5277038 test_acc:  0.8046875\n",
            "iter:  702 train_cost:  0.5601939 train_acc:  0.796875 test_cost:  0.59512883 test_acc:  0.859375\n",
            "iter:  703 train_cost:  0.321746 train_acc:  0.8984375 test_cost:  0.6348783 test_acc:  0.828125\n",
            "iter:  704 train_cost:  0.5615819 train_acc:  0.8203125 test_cost:  0.47437334 test_acc:  0.8671875\n",
            "iter:  705 train_cost:  0.45658225 train_acc:  0.8359375 test_cost:  0.543552 test_acc:  0.796875\n",
            "iter:  706 train_cost:  0.51797074 train_acc:  0.8359375 test_cost:  0.58273053 test_acc:  0.8359375\n",
            "iter:  707 train_cost:  0.5299586 train_acc:  0.8671875 test_cost:  0.7408054 test_acc:  0.7890625\n",
            "iter:  708 train_cost:  0.46037006 train_acc:  0.875 test_cost:  0.7871096 test_acc:  0.7421875\n",
            "iter:  709 train_cost:  0.49814725 train_acc:  0.796875 test_cost:  0.70798236 test_acc:  0.8125\n",
            "iter:  710 train_cost:  0.56379366 train_acc:  0.84375 test_cost:  0.56309617 test_acc:  0.8359375\n",
            "iter:  711 train_cost:  0.6141233 train_acc:  0.8203125 test_cost:  0.39487988 test_acc:  0.875\n",
            "iter:  712 train_cost:  0.69484466 train_acc:  0.8046875 test_cost:  0.71658206 test_acc:  0.7890625\n",
            "iter:  713 train_cost:  0.61974716 train_acc:  0.828125 test_cost:  0.43946427 test_acc:  0.8671875\n",
            "iter:  714 train_cost:  0.59310377 train_acc:  0.8125 test_cost:  0.60879254 test_acc:  0.8203125\n",
            "iter:  715 train_cost:  0.67162895 train_acc:  0.7734375 test_cost:  0.5493971 test_acc:  0.8359375\n",
            "iter:  716 train_cost:  0.6360136 train_acc:  0.8125 test_cost:  0.56058294 test_acc:  0.796875\n",
            "iter:  717 train_cost:  0.52746105 train_acc:  0.828125 test_cost:  0.41724008 test_acc:  0.859375\n",
            "iter:  718 train_cost:  0.43280366 train_acc:  0.84375 test_cost:  0.5668044 test_acc:  0.8046875\n",
            "iter:  719 train_cost:  0.57974637 train_acc:  0.7890625 test_cost:  0.30092615 test_acc:  0.8828125\n",
            "iter:  720 train_cost:  0.55957663 train_acc:  0.84375 test_cost:  0.63677514 test_acc:  0.796875\n",
            "iter:  721 train_cost:  0.4896367 train_acc:  0.8359375 test_cost:  0.7572229 test_acc:  0.78125\n",
            "iter:  722 train_cost:  0.4429783 train_acc:  0.84375 test_cost:  0.62848413 test_acc:  0.8203125\n",
            "iter:  723 train_cost:  0.6600996 train_acc:  0.7578125 test_cost:  0.61771697 test_acc:  0.8125\n",
            "iter:  724 train_cost:  0.5594174 train_acc:  0.84375 test_cost:  0.58990014 test_acc:  0.796875\n",
            "iter:  725 train_cost:  0.42424273 train_acc:  0.8515625 test_cost:  0.62972414 test_acc:  0.8125\n",
            "iter:  726 train_cost:  0.66596663 train_acc:  0.765625 test_cost:  0.56202567 test_acc:  0.84375\n",
            "iter:  727 train_cost:  0.53739095 train_acc:  0.8359375 test_cost:  0.36533767 test_acc:  0.8515625\n",
            "iter:  728 train_cost:  0.6148193 train_acc:  0.8046875 test_cost:  0.55563134 test_acc:  0.8359375\n",
            "iter:  729 train_cost:  0.7099674 train_acc:  0.7890625 test_cost:  0.5885987 test_acc:  0.8203125\n",
            "iter:  730 train_cost:  0.4916122 train_acc:  0.8359375 test_cost:  0.5884042 test_acc:  0.7890625\n",
            "iter:  731 train_cost:  0.4697895 train_acc:  0.859375 test_cost:  0.68736243 test_acc:  0.796875\n",
            "iter:  732 train_cost:  0.6419736 train_acc:  0.7578125 test_cost:  0.5498208 test_acc:  0.8359375\n",
            "iter:  733 train_cost:  0.5841963 train_acc:  0.84375 test_cost:  0.40288582 test_acc:  0.875\n",
            "iter:  734 train_cost:  0.43943572 train_acc:  0.8671875 test_cost:  0.5632824 test_acc:  0.8359375\n",
            "iter:  735 train_cost:  0.40892735 train_acc:  0.8671875 test_cost:  0.68513656 test_acc:  0.765625\n",
            "iter:  736 train_cost:  0.7130029 train_acc:  0.796875 test_cost:  0.6834779 test_acc:  0.828125\n",
            "iter:  737 train_cost:  0.6279553 train_acc:  0.7578125 test_cost:  0.46887946 test_acc:  0.8671875\n",
            "iter:  738 train_cost:  0.52781296 train_acc:  0.7890625 test_cost:  0.56115615 test_acc:  0.796875\n",
            "iter:  739 train_cost:  0.47811902 train_acc:  0.890625 test_cost:  0.53409106 test_acc:  0.8984375\n",
            "iter:  740 train_cost:  0.5243394 train_acc:  0.8359375 test_cost:  0.48875698 test_acc:  0.859375\n",
            "iter:  741 train_cost:  0.38830304 train_acc:  0.890625 test_cost:  0.53758955 test_acc:  0.859375\n",
            "iter:  742 train_cost:  0.8997443 train_acc:  0.7890625 test_cost:  0.47940946 test_acc:  0.8515625\n",
            "iter:  743 train_cost:  0.6422982 train_acc:  0.8359375 test_cost:  0.64250857 test_acc:  0.8046875\n",
            "iter:  744 train_cost:  0.53915715 train_acc:  0.828125 test_cost:  0.41315037 test_acc:  0.8515625\n",
            "iter:  745 train_cost:  0.7205031 train_acc:  0.75 test_cost:  0.53757906 test_acc:  0.828125\n",
            "iter:  746 train_cost:  0.626239 train_acc:  0.8203125 test_cost:  0.46719655 test_acc:  0.8671875\n",
            "iter:  747 train_cost:  0.6010567 train_acc:  0.8203125 test_cost:  0.56003594 test_acc:  0.8203125\n",
            "iter:  748 train_cost:  0.530512 train_acc:  0.8046875 test_cost:  0.5805857 test_acc:  0.796875\n",
            "iter:  749 train_cost:  0.55222917 train_acc:  0.8046875 test_cost:  0.6588651 test_acc:  0.8125\n",
            "iter:  750 train_cost:  0.63865054 train_acc:  0.8203125 test_cost:  0.47853833 test_acc:  0.84375\n",
            "iter:  751 train_cost:  0.51275337 train_acc:  0.8203125 test_cost:  0.537573 test_acc:  0.828125\n",
            "iter:  752 train_cost:  0.68308806 train_acc:  0.78125 test_cost:  0.65574926 test_acc:  0.796875\n",
            "iter:  753 train_cost:  0.722821 train_acc:  0.796875 test_cost:  0.5944593 test_acc:  0.8046875\n",
            "iter:  754 train_cost:  0.49789107 train_acc:  0.859375 test_cost:  0.85230374 test_acc:  0.703125\n",
            "iter:  755 train_cost:  0.571638 train_acc:  0.78125 test_cost:  0.5320487 test_acc:  0.8203125\n",
            "iter:  756 train_cost:  0.6130349 train_acc:  0.78125 test_cost:  0.617143 test_acc:  0.8046875\n",
            "iter:  757 train_cost:  0.68952775 train_acc:  0.734375 test_cost:  0.6358992 test_acc:  0.765625\n",
            "iter:  758 train_cost:  0.53818023 train_acc:  0.84375 test_cost:  0.5279132 test_acc:  0.859375\n",
            "iter:  759 train_cost:  0.619921 train_acc:  0.765625 test_cost:  0.6270587 test_acc:  0.796875\n",
            "iter:  760 train_cost:  0.47956306 train_acc:  0.84375 test_cost:  0.49974355 test_acc:  0.8203125\n",
            "iter:  761 train_cost:  0.5291761 train_acc:  0.8203125 test_cost:  0.5739095 test_acc:  0.8125\n",
            "iter:  762 train_cost:  0.5170428 train_acc:  0.890625 test_cost:  0.52002054 test_acc:  0.8203125\n",
            "iter:  763 train_cost:  0.5014958 train_acc:  0.8515625 test_cost:  0.4903056 test_acc:  0.8515625\n",
            "iter:  764 train_cost:  0.52533114 train_acc:  0.828125 test_cost:  0.6323234 test_acc:  0.8359375\n",
            "iter:  765 train_cost:  0.40695316 train_acc:  0.8515625 test_cost:  0.64086497 test_acc:  0.8125\n",
            "iter:  766 train_cost:  0.46685776 train_acc:  0.84375 test_cost:  0.7915834 test_acc:  0.734375\n",
            "iter:  767 train_cost:  0.4614487 train_acc:  0.828125 test_cost:  0.6501876 test_acc:  0.7734375\n",
            "iter:  768 train_cost:  0.63459074 train_acc:  0.796875 test_cost:  0.52802074 test_acc:  0.8359375\n",
            "iter:  769 train_cost:  0.76217127 train_acc:  0.7421875 test_cost:  0.4341773 test_acc:  0.875\n",
            "iter:  770 train_cost:  0.5450878 train_acc:  0.78125 test_cost:  0.66889846 test_acc:  0.828125\n",
            "iter:  771 train_cost:  0.47384048 train_acc:  0.8671875 test_cost:  0.6149214 test_acc:  0.7890625\n",
            "iter:  772 train_cost:  0.533122 train_acc:  0.8125 test_cost:  0.549845 test_acc:  0.8515625\n",
            "iter:  773 train_cost:  0.39251804 train_acc:  0.8828125 test_cost:  0.7021016 test_acc:  0.7890625\n",
            "iter:  774 train_cost:  0.5668867 train_acc:  0.8203125 test_cost:  0.4795695 test_acc:  0.8203125\n",
            "iter:  775 train_cost:  0.5484885 train_acc:  0.8203125 test_cost:  0.5903649 test_acc:  0.7890625\n",
            "iter:  776 train_cost:  0.60915565 train_acc:  0.7890625 test_cost:  0.67743254 test_acc:  0.8203125\n",
            "iter:  777 train_cost:  0.6419679 train_acc:  0.78125 test_cost:  0.60941255 test_acc:  0.8125\n",
            "iter:  778 train_cost:  0.56230175 train_acc:  0.8359375 test_cost:  0.631776 test_acc:  0.8125\n",
            "iter:  779 train_cost:  0.8197551 train_acc:  0.765625 test_cost:  0.47470173 test_acc:  0.8515625\n",
            "iter:  780 train_cost:  0.50620425 train_acc:  0.828125 test_cost:  0.588817 test_acc:  0.8125\n",
            "iter:  781 train_cost:  0.5911255 train_acc:  0.828125 test_cost:  0.6690676 test_acc:  0.765625\n",
            "iter:  782 train_cost:  0.49756932 train_acc:  0.8671875 test_cost:  0.511606 test_acc:  0.84375\n",
            "iter:  783 train_cost:  0.40148306 train_acc:  0.8671875 test_cost:  0.47422588 test_acc:  0.8515625\n",
            "iter:  784 train_cost:  0.54964983 train_acc:  0.84375 test_cost:  0.51268744 test_acc:  0.828125\n",
            "iter:  785 train_cost:  0.5520034 train_acc:  0.796875 test_cost:  0.44087958 test_acc:  0.890625\n",
            "iter:  786 train_cost:  0.470834 train_acc:  0.8203125 test_cost:  0.6012162 test_acc:  0.8359375\n",
            "iter:  787 train_cost:  0.6678144 train_acc:  0.7421875 test_cost:  0.46508268 test_acc:  0.84375\n",
            "iter:  788 train_cost:  0.5251247 train_acc:  0.8515625 test_cost:  0.5813025 test_acc:  0.8203125\n",
            "iter:  789 train_cost:  0.5397266 train_acc:  0.8203125 test_cost:  0.37056047 test_acc:  0.859375\n",
            "iter:  790 train_cost:  0.3785187 train_acc:  0.8984375 test_cost:  0.6180484 test_acc:  0.8203125\n",
            "iter:  791 train_cost:  0.5565295 train_acc:  0.8125 test_cost:  0.64695346 test_acc:  0.78125\n",
            "iter:  792 train_cost:  0.4404207 train_acc:  0.875 test_cost:  0.534487 test_acc:  0.8203125\n",
            "iter:  793 train_cost:  0.6136483 train_acc:  0.8046875 test_cost:  0.6947601 test_acc:  0.7578125\n",
            "iter:  794 train_cost:  0.65341055 train_acc:  0.8515625 test_cost:  0.42865974 test_acc:  0.8515625\n",
            "iter:  795 train_cost:  0.5465333 train_acc:  0.8203125 test_cost:  0.47424597 test_acc:  0.8984375\n",
            "iter:  796 train_cost:  0.8475765 train_acc:  0.765625 test_cost:  0.5411899 test_acc:  0.8203125\n",
            "iter:  797 train_cost:  0.49002928 train_acc:  0.84375 test_cost:  0.5717002 test_acc:  0.8203125\n",
            "iter:  798 train_cost:  0.30019388 train_acc:  0.8984375 test_cost:  0.5055605 test_acc:  0.8515625\n",
            "iter:  799 train_cost:  0.5395126 train_acc:  0.84375 test_cost:  0.5394515 test_acc:  0.8203125\n",
            "iter:  800 train_cost:  0.3656158 train_acc:  0.859375 test_cost:  0.43237454 test_acc:  0.8671875\n",
            "iter:  801 train_cost:  0.843537 train_acc:  0.7734375 test_cost:  0.5774871 test_acc:  0.8046875\n",
            "iter:  802 train_cost:  0.45721015 train_acc:  0.8125 test_cost:  0.5748694 test_acc:  0.8125\n",
            "iter:  803 train_cost:  0.659896 train_acc:  0.78125 test_cost:  0.576904 test_acc:  0.8515625\n",
            "iter:  804 train_cost:  0.56614393 train_acc:  0.8359375 test_cost:  0.6789106 test_acc:  0.8125\n",
            "iter:  805 train_cost:  0.5587885 train_acc:  0.828125 test_cost:  0.4287606 test_acc:  0.859375\n",
            "iter:  806 train_cost:  0.41827092 train_acc:  0.84375 test_cost:  0.62843 test_acc:  0.796875\n",
            "iter:  807 train_cost:  0.3704056 train_acc:  0.921875 test_cost:  0.63843596 test_acc:  0.828125\n",
            "iter:  808 train_cost:  0.441118 train_acc:  0.875 test_cost:  0.5974051 test_acc:  0.796875\n",
            "iter:  809 train_cost:  0.48496598 train_acc:  0.875 test_cost:  0.6375462 test_acc:  0.8125\n",
            "iter:  810 train_cost:  0.34722948 train_acc:  0.8984375 test_cost:  0.52275324 test_acc:  0.8046875\n",
            "iter:  811 train_cost:  0.41673976 train_acc:  0.859375 test_cost:  0.4709797 test_acc:  0.84375\n",
            "iter:  812 train_cost:  0.5278625 train_acc:  0.8125 test_cost:  0.3706965 test_acc:  0.890625\n",
            "iter:  813 train_cost:  0.6034988 train_acc:  0.8125 test_cost:  0.5734248 test_acc:  0.796875\n",
            "iter:  814 train_cost:  0.5856502 train_acc:  0.796875 test_cost:  0.5567105 test_acc:  0.8046875\n",
            "iter:  815 train_cost:  0.43700308 train_acc:  0.8671875 test_cost:  0.7037133 test_acc:  0.796875\n",
            "iter:  816 train_cost:  0.53025293 train_acc:  0.84375 test_cost:  0.45727602 test_acc:  0.8359375\n",
            "iter:  817 train_cost:  0.57811296 train_acc:  0.8046875 test_cost:  0.6006447 test_acc:  0.84375\n",
            "iter:  818 train_cost:  0.43196717 train_acc:  0.8359375 test_cost:  0.64549756 test_acc:  0.8203125\n",
            "iter:  819 train_cost:  0.78562105 train_acc:  0.78125 test_cost:  0.5575896 test_acc:  0.8203125\n",
            "iter:  820 train_cost:  0.53975546 train_acc:  0.8125 test_cost:  0.58086556 test_acc:  0.8046875\n",
            "iter:  821 train_cost:  0.5077307 train_acc:  0.8359375 test_cost:  0.52299964 test_acc:  0.8671875\n",
            "iter:  822 train_cost:  0.45153916 train_acc:  0.8671875 test_cost:  0.40434468 test_acc:  0.828125\n",
            "iter:  823 train_cost:  0.6095589 train_acc:  0.828125 test_cost:  0.61500967 test_acc:  0.8046875\n",
            "iter:  824 train_cost:  0.4948816 train_acc:  0.8203125 test_cost:  0.6453483 test_acc:  0.796875\n",
            "iter:  825 train_cost:  0.5509398 train_acc:  0.8359375 test_cost:  0.5644119 test_acc:  0.796875\n",
            "iter:  826 train_cost:  0.34445414 train_acc:  0.8828125 test_cost:  0.51313806 test_acc:  0.8359375\n",
            "iter:  827 train_cost:  0.60329044 train_acc:  0.796875 test_cost:  0.97983736 test_acc:  0.734375\n",
            "iter:  828 train_cost:  0.58159345 train_acc:  0.8359375 test_cost:  0.41659135 test_acc:  0.8359375\n",
            "iter:  829 train_cost:  0.6483243 train_acc:  0.7890625 test_cost:  0.54790604 test_acc:  0.859375\n",
            "iter:  830 train_cost:  0.63213146 train_acc:  0.8046875 test_cost:  0.5677427 test_acc:  0.8203125\n",
            "iter:  831 train_cost:  0.5178617 train_acc:  0.84375 test_cost:  0.641855 test_acc:  0.78125\n",
            "iter:  832 train_cost:  0.57829344 train_acc:  0.8125 test_cost:  0.64709437 test_acc:  0.78125\n",
            "iter:  833 train_cost:  0.55182576 train_acc:  0.8359375 test_cost:  0.48711115 test_acc:  0.8515625\n",
            "iter:  834 train_cost:  0.5019692 train_acc:  0.8203125 test_cost:  0.5131357 test_acc:  0.8515625\n",
            "iter:  835 train_cost:  0.60023344 train_acc:  0.828125 test_cost:  0.4413807 test_acc:  0.8359375\n",
            "iter:  836 train_cost:  0.6534195 train_acc:  0.8125 test_cost:  0.5467181 test_acc:  0.8203125\n",
            "iter:  837 train_cost:  0.6696379 train_acc:  0.8046875 test_cost:  0.48965526 test_acc:  0.875\n",
            "iter:  838 train_cost:  0.5875023 train_acc:  0.8203125 test_cost:  0.3951009 test_acc:  0.8671875\n",
            "iter:  839 train_cost:  0.45336765 train_acc:  0.8671875 test_cost:  0.531618 test_acc:  0.859375\n",
            "iter:  840 train_cost:  0.65064 train_acc:  0.8125 test_cost:  0.73699856 test_acc:  0.78125\n",
            "iter:  841 train_cost:  0.47378445 train_acc:  0.859375 test_cost:  0.31716508 test_acc:  0.90625\n",
            "iter:  842 train_cost:  0.41415524 train_acc:  0.875 test_cost:  0.5333765 test_acc:  0.84375\n",
            "iter:  843 train_cost:  0.56725854 train_acc:  0.8046875 test_cost:  0.58743846 test_acc:  0.8203125\n",
            "iter:  844 train_cost:  0.48191762 train_acc:  0.8515625 test_cost:  0.43266484 test_acc:  0.8359375\n",
            "iter:  845 train_cost:  0.50634253 train_acc:  0.859375 test_cost:  0.74328023 test_acc:  0.7734375\n",
            "iter:  846 train_cost:  0.3535129 train_acc:  0.875 test_cost:  0.53634167 test_acc:  0.8046875\n",
            "iter:  847 train_cost:  0.5536963 train_acc:  0.8203125 test_cost:  0.47156852 test_acc:  0.859375\n",
            "iter:  848 train_cost:  0.672297 train_acc:  0.8203125 test_cost:  0.66778946 test_acc:  0.828125\n",
            "iter:  849 train_cost:  0.46771866 train_acc:  0.828125 test_cost:  0.5391409 test_acc:  0.828125\n",
            "iter:  850 train_cost:  0.3540993 train_acc:  0.8515625 test_cost:  0.581426 test_acc:  0.8046875\n",
            "iter:  851 train_cost:  0.53159696 train_acc:  0.859375 test_cost:  0.5745761 test_acc:  0.84375\n",
            "iter:  852 train_cost:  0.6515576 train_acc:  0.796875 test_cost:  0.56052715 test_acc:  0.828125\n",
            "iter:  853 train_cost:  0.42066905 train_acc:  0.84375 test_cost:  0.57901585 test_acc:  0.8046875\n",
            "iter:  854 train_cost:  0.47249946 train_acc:  0.8515625 test_cost:  0.40000436 test_acc:  0.8671875\n",
            "iter:  855 train_cost:  0.57145107 train_acc:  0.796875 test_cost:  0.46230137 test_acc:  0.875\n",
            "iter:  856 train_cost:  0.6166431 train_acc:  0.84375 test_cost:  0.34617886 test_acc:  0.90625\n",
            "iter:  857 train_cost:  0.5385647 train_acc:  0.8359375 test_cost:  0.5439409 test_acc:  0.8359375\n",
            "iter:  858 train_cost:  0.4998111 train_acc:  0.8515625 test_cost:  0.5726982 test_acc:  0.8359375\n",
            "iter:  859 train_cost:  0.42375538 train_acc:  0.8671875 test_cost:  0.61237526 test_acc:  0.8046875\n",
            "iter:  860 train_cost:  0.4110276 train_acc:  0.859375 test_cost:  0.49196586 test_acc:  0.8125\n",
            "iter:  861 train_cost:  0.555473 train_acc:  0.859375 test_cost:  0.47718936 test_acc:  0.8515625\n",
            "iter:  862 train_cost:  0.5085023 train_acc:  0.84375 test_cost:  0.5571873 test_acc:  0.8046875\n",
            "iter:  863 train_cost:  0.6266572 train_acc:  0.8125 test_cost:  0.55341864 test_acc:  0.8515625\n",
            "iter:  864 train_cost:  0.49000645 train_acc:  0.8359375 test_cost:  0.49750003 test_acc:  0.828125\n",
            "iter:  865 train_cost:  0.5628829 train_acc:  0.84375 test_cost:  0.5552624 test_acc:  0.8359375\n",
            "iter:  866 train_cost:  0.38329718 train_acc:  0.875 test_cost:  0.57025623 test_acc:  0.859375\n",
            "iter:  867 train_cost:  0.38385555 train_acc:  0.8828125 test_cost:  0.618773 test_acc:  0.828125\n",
            "iter:  868 train_cost:  0.42982158 train_acc:  0.84375 test_cost:  0.46282244 test_acc:  0.859375\n",
            "iter:  869 train_cost:  0.29789215 train_acc:  0.9140625 test_cost:  0.62102383 test_acc:  0.7890625\n",
            "iter:  870 train_cost:  0.550623 train_acc:  0.8125 test_cost:  0.5057708 test_acc:  0.8046875\n",
            "iter:  871 train_cost:  0.57760894 train_acc:  0.828125 test_cost:  0.48574352 test_acc:  0.8359375\n",
            "iter:  872 train_cost:  0.43432304 train_acc:  0.8359375 test_cost:  0.50741965 test_acc:  0.84375\n",
            "iter:  873 train_cost:  0.45353457 train_acc:  0.859375 test_cost:  0.44951546 test_acc:  0.875\n",
            "iter:  874 train_cost:  0.3647964 train_acc:  0.890625 test_cost:  0.4803338 test_acc:  0.859375\n",
            "iter:  875 train_cost:  0.49941492 train_acc:  0.859375 test_cost:  0.5476343 test_acc:  0.8359375\n",
            "iter:  876 train_cost:  0.52228355 train_acc:  0.859375 test_cost:  0.41955313 test_acc:  0.890625\n",
            "iter:  877 train_cost:  0.54034525 train_acc:  0.84375 test_cost:  0.43277216 test_acc:  0.8671875\n",
            "iter:  878 train_cost:  0.6309157 train_acc:  0.8203125 test_cost:  0.38611495 test_acc:  0.8828125\n",
            "iter:  879 train_cost:  0.38922536 train_acc:  0.859375 test_cost:  0.46298033 test_acc:  0.859375\n",
            "iter:  880 train_cost:  0.59384143 train_acc:  0.8046875 test_cost:  0.40726066 test_acc:  0.8828125\n",
            "iter:  881 train_cost:  0.6581169 train_acc:  0.796875 test_cost:  0.5215639 test_acc:  0.8515625\n",
            "iter:  882 train_cost:  0.6679177 train_acc:  0.84375 test_cost:  0.534179 test_acc:  0.796875\n",
            "iter:  883 train_cost:  0.3855303 train_acc:  0.875 test_cost:  0.61479473 test_acc:  0.8046875\n",
            "iter:  884 train_cost:  0.42409772 train_acc:  0.859375 test_cost:  0.40332904 test_acc:  0.8671875\n",
            "iter:  885 train_cost:  0.5232291 train_acc:  0.84375 test_cost:  0.69110966 test_acc:  0.7734375\n",
            "iter:  886 train_cost:  0.4392373 train_acc:  0.8671875 test_cost:  0.60592985 test_acc:  0.8359375\n",
            "iter:  887 train_cost:  0.44344074 train_acc:  0.875 test_cost:  0.7439736 test_acc:  0.7890625\n",
            "iter:  888 train_cost:  0.58479357 train_acc:  0.8203125 test_cost:  0.44861722 test_acc:  0.8046875\n",
            "iter:  889 train_cost:  0.42664468 train_acc:  0.875 test_cost:  0.40535378 test_acc:  0.8828125\n",
            "iter:  890 train_cost:  0.60700166 train_acc:  0.8046875 test_cost:  0.46992725 test_acc:  0.828125\n",
            "iter:  891 train_cost:  0.4137504 train_acc:  0.859375 test_cost:  0.55298334 test_acc:  0.8671875\n",
            "iter:  892 train_cost:  0.45629388 train_acc:  0.875 test_cost:  0.49370444 test_acc:  0.875\n",
            "iter:  893 train_cost:  0.50722635 train_acc:  0.8046875 test_cost:  0.52410114 test_acc:  0.8515625\n",
            "iter:  894 train_cost:  0.49559218 train_acc:  0.8203125 test_cost:  0.42490035 test_acc:  0.859375\n",
            "iter:  895 train_cost:  0.8075708 train_acc:  0.75 test_cost:  0.45863348 test_acc:  0.84375\n",
            "iter:  896 train_cost:  0.38790944 train_acc:  0.875 test_cost:  0.48703766 test_acc:  0.8671875\n",
            "iter:  897 train_cost:  0.6068693 train_acc:  0.796875 test_cost:  0.47480416 test_acc:  0.8515625\n",
            "iter:  898 train_cost:  0.43459636 train_acc:  0.8828125 test_cost:  0.6233129 test_acc:  0.8125\n",
            "iter:  899 train_cost:  0.44175476 train_acc:  0.828125 test_cost:  0.5254441 test_acc:  0.8515625\n",
            "iter:  900 train_cost:  0.5838585 train_acc:  0.828125 test_cost:  0.61744213 test_acc:  0.8359375\n",
            "iter:  901 train_cost:  0.4742812 train_acc:  0.859375 test_cost:  0.44623184 test_acc:  0.828125\n",
            "iter:  902 train_cost:  0.45727897 train_acc:  0.875 test_cost:  0.519945 test_acc:  0.890625\n",
            "iter:  903 train_cost:  0.3424626 train_acc:  0.8828125 test_cost:  0.36486316 test_acc:  0.8828125\n",
            "iter:  904 train_cost:  0.51046205 train_acc:  0.84375 test_cost:  0.4586934 test_acc:  0.859375\n",
            "iter:  905 train_cost:  0.5013764 train_acc:  0.8125 test_cost:  0.42723367 test_acc:  0.8515625\n",
            "iter:  906 train_cost:  0.5365155 train_acc:  0.8203125 test_cost:  0.6135769 test_acc:  0.796875\n",
            "iter:  907 train_cost:  0.37129188 train_acc:  0.859375 test_cost:  0.45014048 test_acc:  0.8671875\n",
            "iter:  908 train_cost:  0.515893 train_acc:  0.8515625 test_cost:  0.37578547 test_acc:  0.875\n",
            "iter:  909 train_cost:  0.48491463 train_acc:  0.8515625 test_cost:  0.60478586 test_acc:  0.796875\n",
            "iter:  910 train_cost:  0.3468489 train_acc:  0.890625 test_cost:  0.47406402 test_acc:  0.8671875\n",
            "iter:  911 train_cost:  0.519709 train_acc:  0.8828125 test_cost:  0.54358137 test_acc:  0.8515625\n",
            "iter:  912 train_cost:  0.37229314 train_acc:  0.8515625 test_cost:  0.4608511 test_acc:  0.875\n",
            "iter:  913 train_cost:  0.28222543 train_acc:  0.90625 test_cost:  0.73744774 test_acc:  0.828125\n",
            "iter:  914 train_cost:  0.44183055 train_acc:  0.8359375 test_cost:  0.66292363 test_acc:  0.796875\n",
            "iter:  915 train_cost:  0.44651496 train_acc:  0.8671875 test_cost:  0.32912576 test_acc:  0.8984375\n",
            "iter:  916 train_cost:  0.649841 train_acc:  0.78125 test_cost:  0.60934126 test_acc:  0.8046875\n",
            "iter:  917 train_cost:  0.42159864 train_acc:  0.8828125 test_cost:  0.61528504 test_acc:  0.78125\n",
            "iter:  918 train_cost:  0.58287317 train_acc:  0.84375 test_cost:  0.5159209 test_acc:  0.859375\n",
            "iter:  919 train_cost:  0.619151 train_acc:  0.8125 test_cost:  0.4789999 test_acc:  0.8671875\n",
            "iter:  920 train_cost:  0.37878382 train_acc:  0.8671875 test_cost:  0.48172054 test_acc:  0.84375\n",
            "iter:  921 train_cost:  0.48561388 train_acc:  0.84375 test_cost:  0.6042734 test_acc:  0.8359375\n",
            "iter:  922 train_cost:  0.69966865 train_acc:  0.796875 test_cost:  0.5297291 test_acc:  0.828125\n",
            "iter:  923 train_cost:  0.50836045 train_acc:  0.859375 test_cost:  0.45886412 test_acc:  0.8671875\n",
            "iter:  924 train_cost:  0.5058712 train_acc:  0.859375 test_cost:  0.50623643 test_acc:  0.796875\n",
            "iter:  925 train_cost:  0.39655426 train_acc:  0.859375 test_cost:  0.31948456 test_acc:  0.890625\n",
            "iter:  926 train_cost:  0.48600855 train_acc:  0.8359375 test_cost:  0.5671835 test_acc:  0.7890625\n",
            "iter:  927 train_cost:  0.34513068 train_acc:  0.8671875 test_cost:  0.49679503 test_acc:  0.8359375\n",
            "iter:  928 train_cost:  0.5166224 train_acc:  0.84375 test_cost:  0.7783103 test_acc:  0.78125\n",
            "iter:  929 train_cost:  0.5401199 train_acc:  0.84375 test_cost:  0.48874772 test_acc:  0.8828125\n",
            "iter:  930 train_cost:  0.48983788 train_acc:  0.8203125 test_cost:  0.42509562 test_acc:  0.875\n",
            "iter:  931 train_cost:  0.3719574 train_acc:  0.890625 test_cost:  0.58759284 test_acc:  0.84375\n",
            "iter:  932 train_cost:  0.691754 train_acc:  0.8125 test_cost:  0.497003 test_acc:  0.8359375\n",
            "iter:  933 train_cost:  0.5691585 train_acc:  0.828125 test_cost:  0.47800094 test_acc:  0.8203125\n",
            "iter:  934 train_cost:  0.58610165 train_acc:  0.8359375 test_cost:  0.52554756 test_acc:  0.8671875\n",
            "iter:  935 train_cost:  0.66731584 train_acc:  0.7734375 test_cost:  0.64666015 test_acc:  0.7734375\n",
            "iter:  936 train_cost:  0.38687235 train_acc:  0.875 test_cost:  0.75506324 test_acc:  0.765625\n",
            "iter:  937 train_cost:  0.65411764 train_acc:  0.796875 test_cost:  0.61313987 test_acc:  0.8671875\n",
            "iter:  938 train_cost:  0.4156413 train_acc:  0.8671875 test_cost:  0.4841035 test_acc:  0.84375\n",
            "iter:  939 train_cost:  0.5241512 train_acc:  0.8671875 test_cost:  0.7011771 test_acc:  0.8046875\n",
            "iter:  940 train_cost:  0.41203338 train_acc:  0.8828125 test_cost:  0.54915583 test_acc:  0.78125\n",
            "iter:  941 train_cost:  0.28250942 train_acc:  0.921875 test_cost:  0.5140233 test_acc:  0.8515625\n",
            "iter:  942 train_cost:  0.56502104 train_acc:  0.859375 test_cost:  0.5532862 test_acc:  0.8359375\n",
            "iter:  943 train_cost:  0.45055228 train_acc:  0.84375 test_cost:  0.41721863 test_acc:  0.8984375\n",
            "iter:  944 train_cost:  0.5694078 train_acc:  0.8046875 test_cost:  0.6999795 test_acc:  0.765625\n",
            "iter:  945 train_cost:  0.49870837 train_acc:  0.8359375 test_cost:  0.42000273 test_acc:  0.859375\n",
            "iter:  946 train_cost:  0.36310863 train_acc:  0.8984375 test_cost:  0.3474028 test_acc:  0.8828125\n",
            "iter:  947 train_cost:  0.45210016 train_acc:  0.8671875 test_cost:  0.59391356 test_acc:  0.84375\n",
            "iter:  948 train_cost:  0.38614598 train_acc:  0.890625 test_cost:  0.3820346 test_acc:  0.8828125\n",
            "iter:  949 train_cost:  0.31871238 train_acc:  0.9140625 test_cost:  0.52742684 test_acc:  0.8046875\n",
            "iter:  950 train_cost:  0.38448662 train_acc:  0.8515625 test_cost:  0.631079 test_acc:  0.7578125\n",
            "iter:  951 train_cost:  0.43700093 train_acc:  0.8984375 test_cost:  0.65886265 test_acc:  0.828125\n",
            "iter:  952 train_cost:  0.38822526 train_acc:  0.8671875 test_cost:  0.5177457 test_acc:  0.7890625\n",
            "iter:  953 train_cost:  0.36704186 train_acc:  0.890625 test_cost:  0.49724555 test_acc:  0.8515625\n",
            "iter:  954 train_cost:  0.5173038 train_acc:  0.8515625 test_cost:  0.52794456 test_acc:  0.8203125\n",
            "iter:  955 train_cost:  0.5481676 train_acc:  0.828125 test_cost:  0.4286062 test_acc:  0.859375\n",
            "iter:  956 train_cost:  0.2621843 train_acc:  0.9140625 test_cost:  0.52813077 test_acc:  0.859375\n",
            "iter:  957 train_cost:  0.53662646 train_acc:  0.859375 test_cost:  0.34709084 test_acc:  0.8671875\n",
            "iter:  958 train_cost:  0.44048712 train_acc:  0.875 test_cost:  0.516654 test_acc:  0.8046875\n",
            "iter:  959 train_cost:  0.44196853 train_acc:  0.8515625 test_cost:  0.4396453 test_acc:  0.828125\n",
            "iter:  960 train_cost:  0.478726 train_acc:  0.8515625 test_cost:  0.37082618 test_acc:  0.8984375\n",
            "iter:  961 train_cost:  0.49918914 train_acc:  0.828125 test_cost:  0.75417626 test_acc:  0.8203125\n",
            "iter:  962 train_cost:  0.40972146 train_acc:  0.890625 test_cost:  0.4265498 test_acc:  0.8671875\n",
            "iter:  963 train_cost:  0.39052787 train_acc:  0.875 test_cost:  0.38407254 test_acc:  0.8984375\n",
            "iter:  964 train_cost:  0.4368078 train_acc:  0.875 test_cost:  0.40853637 test_acc:  0.8515625\n",
            "iter:  965 train_cost:  0.37877184 train_acc:  0.859375 test_cost:  0.4556594 test_acc:  0.8671875\n",
            "iter:  966 train_cost:  0.5587594 train_acc:  0.8359375 test_cost:  0.42285252 test_acc:  0.859375\n",
            "iter:  967 train_cost:  0.5727366 train_acc:  0.828125 test_cost:  0.5407752 test_acc:  0.8515625\n",
            "iter:  968 train_cost:  0.5118761 train_acc:  0.84375 test_cost:  0.54845536 test_acc:  0.8359375\n",
            "iter:  969 train_cost:  0.39038375 train_acc:  0.875 test_cost:  0.554827 test_acc:  0.8203125\n",
            "iter:  970 train_cost:  0.42428008 train_acc:  0.90625 test_cost:  0.34742567 test_acc:  0.8984375\n",
            "iter:  971 train_cost:  0.48086154 train_acc:  0.84375 test_cost:  0.28039446 test_acc:  0.9140625\n",
            "iter:  972 train_cost:  0.6087111 train_acc:  0.8046875 test_cost:  0.57130194 test_acc:  0.8046875\n",
            "iter:  973 train_cost:  0.30731505 train_acc:  0.90625 test_cost:  0.637497 test_acc:  0.78125\n",
            "iter:  974 train_cost:  0.4588654 train_acc:  0.875 test_cost:  0.41387093 test_acc:  0.875\n",
            "iter:  975 train_cost:  0.6695944 train_acc:  0.765625 test_cost:  0.5332403 test_acc:  0.8515625\n",
            "iter:  976 train_cost:  0.55115813 train_acc:  0.828125 test_cost:  0.48560596 test_acc:  0.8515625\n",
            "iter:  977 train_cost:  0.40136564 train_acc:  0.875 test_cost:  0.4171219 test_acc:  0.890625\n",
            "iter:  978 train_cost:  0.33442098 train_acc:  0.890625 test_cost:  0.47184157 test_acc:  0.859375\n",
            "iter:  979 train_cost:  0.44735327 train_acc:  0.890625 test_cost:  0.4790277 test_acc:  0.859375\n",
            "iter:  980 train_cost:  0.5147878 train_acc:  0.828125 test_cost:  0.54548675 test_acc:  0.828125\n",
            "iter:  981 train_cost:  0.4897382 train_acc:  0.859375 test_cost:  0.48835072 test_acc:  0.8671875\n",
            "iter:  982 train_cost:  0.4802115 train_acc:  0.84375 test_cost:  0.3738592 test_acc:  0.859375\n",
            "iter:  983 train_cost:  0.6497842 train_acc:  0.796875 test_cost:  0.5686782 test_acc:  0.8203125\n",
            "iter:  984 train_cost:  0.4194784 train_acc:  0.8515625 test_cost:  0.71147424 test_acc:  0.8203125\n",
            "iter:  985 train_cost:  0.51698893 train_acc:  0.8359375 test_cost:  0.52969515 test_acc:  0.84375\n",
            "iter:  986 train_cost:  0.24696745 train_acc:  0.9296875 test_cost:  0.35640103 test_acc:  0.8984375\n",
            "iter:  987 train_cost:  0.4503411 train_acc:  0.84375 test_cost:  0.5967833 test_acc:  0.8203125\n",
            "iter:  988 train_cost:  0.5380938 train_acc:  0.8359375 test_cost:  0.33632243 test_acc:  0.8984375\n",
            "iter:  989 train_cost:  0.5356262 train_acc:  0.828125 test_cost:  0.48252732 test_acc:  0.84375\n",
            "iter:  990 train_cost:  0.39050096 train_acc:  0.8515625 test_cost:  0.44707274 test_acc:  0.859375\n",
            "iter:  991 train_cost:  0.45188394 train_acc:  0.8515625 test_cost:  0.44106826 test_acc:  0.8828125\n",
            "iter:  992 train_cost:  0.39981458 train_acc:  0.890625 test_cost:  0.5220581 test_acc:  0.859375\n",
            "iter:  993 train_cost:  0.4049543 train_acc:  0.890625 test_cost:  0.47659135 test_acc:  0.8671875\n",
            "iter:  994 train_cost:  0.4166362 train_acc:  0.8828125 test_cost:  0.47449732 test_acc:  0.8359375\n",
            "iter:  995 train_cost:  0.48604742 train_acc:  0.8359375 test_cost:  0.4819045 test_acc:  0.8515625\n",
            "iter:  996 train_cost:  0.5628443 train_acc:  0.8359375 test_cost:  0.50337976 test_acc:  0.8046875\n",
            "iter:  997 train_cost:  0.41092896 train_acc:  0.875 test_cost:  0.43617666 test_acc:  0.859375\n",
            "iter:  998 train_cost:  0.56679046 train_acc:  0.828125 test_cost:  0.5075347 test_acc:  0.890625\n",
            "iter:  999 train_cost:  0.49852276 train_acc:  0.8359375 test_cost:  0.43968046 test_acc:  0.8515625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.232889999999998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDkPoIsB90MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10.579477999999998 TPU\n",
        "# 10.682025999999999 CPU\n",
        "# 8.640348 GPU \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXZtWbWQ92P_",
        "colab_type": "text"
      },
      "source": [
        "# CNN using Tensorflow\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6k9YPZQ95z5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77e8daf0-a0a2-4f39-8719-19d60198fb39"
      },
      "source": [
        "import tensorflow as tf\n",
        "import time \n",
        "\n",
        "n_classes=10\n",
        "# Create some wrappers for simplicity\n",
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID') #padding='SAME' padding='VALID'\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "    # MaxPool2D wrapper\n",
        "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
        "                          padding='SAME')\n",
        "\n",
        "\n",
        "# Create model\n",
        "def conv_net(x, weights, biases):\n",
        "    # Reshape input picture\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    print('con1_before max',conv1.get_shape().as_list())\n",
        "\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv1 = maxpool2d(conv1, k=1)\n",
        "    print('con1_after max',conv1.get_shape().as_list())\n",
        "\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    print('con2_before max',conv2.get_shape().as_list())\n",
        "\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv2 = maxpool2d(conv2, k=1)\n",
        "    print('con2_after max', conv2.get_shape().as_list())\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    #wd1 numx3x3  wd1.get_shape() -> numx9 \n",
        "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    # Apply Dropout\n",
        "    #fc1 = tf.nn.dropout(fc1, dropout)\n",
        "\n",
        "    # Output, class prediction\n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return out\n",
        "\n",
        "\n",
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    # 5x5 conv, 1 input, 32 outputs\n",
        "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32]), name=\"wc1\"),\n",
        "    # 5x5 conv, 32 inputs, 64 outputs\n",
        "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
        "    # fully connected, 28*28*64 inputs, 1024 outputs when padding same, with padding valid use 20*20*64\n",
        "    'wd1': tf.Variable(tf.random_normal([20*20*64, 1024])),\n",
        "    # 1024 inputs, 10 outputs (class prediction)\n",
        "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.random_normal([32])),\n",
        "    'bc2': tf.Variable(tf.random_normal([64])),\n",
        "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}\n",
        "\n",
        "num_inputs = 784\n",
        "num_outputs = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "\n",
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, num_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, num_outputs])\n",
        "\n",
        "\n",
        "y_p = conv_net(x, weights, biases)\n",
        "\n",
        "#crossentropy cost\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_p, labels=y)) # cross entropy cost\n",
        "\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(y_p, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "#\n",
        "\n",
        "# optimisation \n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# initalizing the graph and the weights\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "tic = time.clock()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(1000):\n",
        "        \n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        \n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
        "    \n",
        "\n",
        "        train_cost, train_acc  = sess.run([cost,accuracy], feed_dict={x: batch_x,y: batch_y})\n",
        "    \n",
        "        \n",
        "        test_batch_x, test_batch_y = mnist.test.next_batch(batch_size)\n",
        "\n",
        "        test_cost, test_acc  = sess.run([cost,accuracy], feed_dict={x: test_batch_x,y: test_batch_y})\n",
        "        print('iter: ',i, 'train_cost: ', train_cost, 'train_acc: ', train_acc,'test_cost: ', test_cost, 'test_acc: ', test_acc )\n",
        "\n",
        "    \n",
        "    #y_p_p = sess.run(y_p, feed_dict={x: x_gr, y: y_gr})\n",
        "    \n",
        "    #print('predicted ', y_p_p)\n",
        "    #print('real ', y_gr)\n",
        "\n",
        "toc = time.clock()\n",
        "toc-tic"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "con1_before max [None, 24, 24, 32]\n",
            "con1_after max [None, 24, 24, 32]\n",
            "con2_before max [None, 20, 20, 64]\n",
            "con2_after max [None, 20, 20, 64]\n",
            "WARNING:tensorflow:From <ipython-input-3-e00fde220bbf>:89: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "iter:  0 train_cost:  131693.72 train_acc:  0.15625 test_cost:  141505.89 test_acc:  0.1328125\n",
            "iter:  1 train_cost:  126852.22 train_acc:  0.09375 test_cost:  119884.125 test_acc:  0.078125\n",
            "iter:  2 train_cost:  101349.74 train_acc:  0.1640625 test_cost:  130875.33 test_acc:  0.1328125\n",
            "iter:  3 train_cost:  94684.34 train_acc:  0.234375 test_cost:  82604.59 test_acc:  0.2421875\n",
            "iter:  4 train_cost:  99183.23 train_acc:  0.25 test_cost:  89858.41 test_acc:  0.265625\n",
            "iter:  5 train_cost:  70825.97 train_acc:  0.3515625 test_cost:  82060.26 test_acc:  0.3125\n",
            "iter:  6 train_cost:  55294.773 train_acc:  0.3359375 test_cost:  66866.31 test_acc:  0.375\n",
            "iter:  7 train_cost:  59364.375 train_acc:  0.3515625 test_cost:  58215.23 test_acc:  0.3984375\n",
            "iter:  8 train_cost:  51486.332 train_acc:  0.390625 test_cost:  56948.96 test_acc:  0.3359375\n",
            "iter:  9 train_cost:  33661.438 train_acc:  0.515625 test_cost:  26262.535 test_acc:  0.5625\n",
            "iter:  10 train_cost:  25147.111 train_acc:  0.5078125 test_cost:  26124.654 test_acc:  0.5390625\n",
            "iter:  11 train_cost:  33914.797 train_acc:  0.484375 test_cost:  32489.176 test_acc:  0.5703125\n",
            "iter:  12 train_cost:  15409.303 train_acc:  0.6171875 test_cost:  32426.408 test_acc:  0.5546875\n",
            "iter:  13 train_cost:  24888.531 train_acc:  0.53125 test_cost:  30576.404 test_acc:  0.5859375\n",
            "iter:  14 train_cost:  19632.61 train_acc:  0.59375 test_cost:  29587.604 test_acc:  0.5859375\n",
            "iter:  15 train_cost:  21183.508 train_acc:  0.65625 test_cost:  20198.727 test_acc:  0.6640625\n",
            "iter:  16 train_cost:  20624.0 train_acc:  0.6171875 test_cost:  17179.824 test_acc:  0.7265625\n",
            "iter:  17 train_cost:  18553.88 train_acc:  0.6953125 test_cost:  18756.518 test_acc:  0.6796875\n",
            "iter:  18 train_cost:  21390.875 train_acc:  0.6640625 test_cost:  15366.429 test_acc:  0.7265625\n",
            "iter:  19 train_cost:  13817.959 train_acc:  0.7265625 test_cost:  19271.516 test_acc:  0.6640625\n",
            "iter:  20 train_cost:  16837.602 train_acc:  0.7578125 test_cost:  17563.45 test_acc:  0.6640625\n",
            "iter:  21 train_cost:  20815.947 train_acc:  0.703125 test_cost:  13422.924 test_acc:  0.7734375\n",
            "iter:  22 train_cost:  14411.867 train_acc:  0.75 test_cost:  17129.518 test_acc:  0.6875\n",
            "iter:  23 train_cost:  15276.428 train_acc:  0.71875 test_cost:  13828.929 test_acc:  0.75\n",
            "iter:  24 train_cost:  12660.341 train_acc:  0.7734375 test_cost:  11693.883 test_acc:  0.8125\n",
            "iter:  25 train_cost:  10618.7705 train_acc:  0.7578125 test_cost:  18200.48 test_acc:  0.703125\n",
            "iter:  26 train_cost:  12683.934 train_acc:  0.765625 test_cost:  10063.245 test_acc:  0.8046875\n",
            "iter:  27 train_cost:  9153.57 train_acc:  0.828125 test_cost:  7838.404 test_acc:  0.828125\n",
            "iter:  28 train_cost:  11628.117 train_acc:  0.7734375 test_cost:  10961.008 test_acc:  0.84375\n",
            "iter:  29 train_cost:  9060.881 train_acc:  0.8359375 test_cost:  10298.359 test_acc:  0.796875\n",
            "iter:  30 train_cost:  10415.109 train_acc:  0.8046875 test_cost:  6959.6562 test_acc:  0.84375\n",
            "iter:  31 train_cost:  15239.586 train_acc:  0.7734375 test_cost:  10133.182 test_acc:  0.8203125\n",
            "iter:  32 train_cost:  8939.166 train_acc:  0.8203125 test_cost:  11520.257 test_acc:  0.8359375\n",
            "iter:  33 train_cost:  13976.486 train_acc:  0.7734375 test_cost:  9191.631 test_acc:  0.765625\n",
            "iter:  34 train_cost:  9114.883 train_acc:  0.828125 test_cost:  12674.205 test_acc:  0.8203125\n",
            "iter:  35 train_cost:  13314.37 train_acc:  0.796875 test_cost:  11538.927 test_acc:  0.8125\n",
            "iter:  36 train_cost:  12940.827 train_acc:  0.8125 test_cost:  12213.657 test_acc:  0.78125\n",
            "iter:  37 train_cost:  6087.479 train_acc:  0.859375 test_cost:  11358.304 test_acc:  0.78125\n",
            "iter:  38 train_cost:  9415.986 train_acc:  0.84375 test_cost:  8002.8447 test_acc:  0.8359375\n",
            "iter:  39 train_cost:  10716.719 train_acc:  0.8203125 test_cost:  11110.244 test_acc:  0.8515625\n",
            "iter:  40 train_cost:  9649.123 train_acc:  0.8359375 test_cost:  6805.7754 test_acc:  0.8515625\n",
            "iter:  41 train_cost:  11066.391 train_acc:  0.8671875 test_cost:  6378.8926 test_acc:  0.8515625\n",
            "iter:  42 train_cost:  7848.6953 train_acc:  0.8203125 test_cost:  8998.087 test_acc:  0.8046875\n",
            "iter:  43 train_cost:  6870.292 train_acc:  0.859375 test_cost:  8763.757 test_acc:  0.828125\n",
            "iter:  44 train_cost:  8658.893 train_acc:  0.7734375 test_cost:  8280.003 test_acc:  0.8515625\n",
            "iter:  45 train_cost:  3382.5125 train_acc:  0.875 test_cost:  8130.6885 test_acc:  0.84375\n",
            "iter:  46 train_cost:  10681.893 train_acc:  0.8125 test_cost:  9935.418 test_acc:  0.8671875\n",
            "iter:  47 train_cost:  9943.488 train_acc:  0.78125 test_cost:  6827.297 test_acc:  0.84375\n",
            "iter:  48 train_cost:  4131.891 train_acc:  0.875 test_cost:  5218.1504 test_acc:  0.859375\n",
            "iter:  49 train_cost:  7132.203 train_acc:  0.8359375 test_cost:  6324.677 test_acc:  0.859375\n",
            "iter:  50 train_cost:  9695.836 train_acc:  0.7734375 test_cost:  8020.0474 test_acc:  0.875\n",
            "iter:  51 train_cost:  4293.165 train_acc:  0.8828125 test_cost:  3233.4072 test_acc:  0.890625\n",
            "iter:  52 train_cost:  5989.0186 train_acc:  0.8359375 test_cost:  7305.614 test_acc:  0.859375\n",
            "iter:  53 train_cost:  4927.365 train_acc:  0.8671875 test_cost:  7839.8604 test_acc:  0.84375\n",
            "iter:  54 train_cost:  7226.4443 train_acc:  0.8515625 test_cost:  10183.779 test_acc:  0.7734375\n",
            "iter:  55 train_cost:  4408.6533 train_acc:  0.8828125 test_cost:  6488.765 test_acc:  0.828125\n",
            "iter:  56 train_cost:  7490.2256 train_acc:  0.8359375 test_cost:  8458.32 test_acc:  0.84375\n",
            "iter:  57 train_cost:  6201.5146 train_acc:  0.84375 test_cost:  8382.139 test_acc:  0.8515625\n",
            "iter:  58 train_cost:  7144.8354 train_acc:  0.8671875 test_cost:  8936.2 test_acc:  0.828125\n",
            "iter:  59 train_cost:  7137.784 train_acc:  0.84375 test_cost:  10499.872 test_acc:  0.828125\n",
            "iter:  60 train_cost:  8589.195 train_acc:  0.875 test_cost:  6209.7725 test_acc:  0.8828125\n",
            "iter:  61 train_cost:  5886.4907 train_acc:  0.8515625 test_cost:  12445.981 test_acc:  0.796875\n",
            "iter:  62 train_cost:  9793.722 train_acc:  0.828125 test_cost:  9426.4 test_acc:  0.828125\n",
            "iter:  63 train_cost:  6873.9683 train_acc:  0.828125 test_cost:  7864.074 test_acc:  0.84375\n",
            "iter:  64 train_cost:  13020.871 train_acc:  0.8359375 test_cost:  4878.5103 test_acc:  0.859375\n",
            "iter:  65 train_cost:  5157.005 train_acc:  0.8359375 test_cost:  10789.426 test_acc:  0.78125\n",
            "iter:  66 train_cost:  6376.7563 train_acc:  0.8515625 test_cost:  5785.744 test_acc:  0.875\n",
            "iter:  67 train_cost:  6085.4106 train_acc:  0.90625 test_cost:  10129.158 test_acc:  0.8984375\n",
            "iter:  68 train_cost:  5144.3076 train_acc:  0.8515625 test_cost:  7403.4287 test_acc:  0.8359375\n",
            "iter:  69 train_cost:  5971.94 train_acc:  0.8359375 test_cost:  6678.545 test_acc:  0.8671875\n",
            "iter:  70 train_cost:  4798.5776 train_acc:  0.8984375 test_cost:  8385.751 test_acc:  0.8359375\n",
            "iter:  71 train_cost:  4095.9487 train_acc:  0.84375 test_cost:  7911.5576 test_acc:  0.90625\n",
            "iter:  72 train_cost:  5847.734 train_acc:  0.890625 test_cost:  10619.947 test_acc:  0.8359375\n",
            "iter:  73 train_cost:  8027.947 train_acc:  0.8515625 test_cost:  9243.818 test_acc:  0.84375\n",
            "iter:  74 train_cost:  1943.97 train_acc:  0.921875 test_cost:  7143.6846 test_acc:  0.8515625\n",
            "iter:  75 train_cost:  2431.2236 train_acc:  0.890625 test_cost:  5233.987 test_acc:  0.8828125\n",
            "iter:  76 train_cost:  4708.761 train_acc:  0.875 test_cost:  8685.303 test_acc:  0.8046875\n",
            "iter:  77 train_cost:  5896.785 train_acc:  0.8671875 test_cost:  5909.1807 test_acc:  0.8671875\n",
            "iter:  78 train_cost:  4413.7983 train_acc:  0.8671875 test_cost:  7241.343 test_acc:  0.8515625\n",
            "iter:  79 train_cost:  6634.409 train_acc:  0.859375 test_cost:  7448.514 test_acc:  0.8515625\n",
            "iter:  80 train_cost:  2059.079 train_acc:  0.921875 test_cost:  4937.8315 test_acc:  0.8828125\n",
            "iter:  81 train_cost:  1547.2119 train_acc:  0.9296875 test_cost:  9667.01 test_acc:  0.875\n",
            "iter:  82 train_cost:  7795.845 train_acc:  0.8515625 test_cost:  8727.912 test_acc:  0.84375\n",
            "iter:  83 train_cost:  4370.667 train_acc:  0.875 test_cost:  4617.1836 test_acc:  0.8359375\n",
            "iter:  84 train_cost:  10390.451 train_acc:  0.8046875 test_cost:  5542.304 test_acc:  0.859375\n",
            "iter:  85 train_cost:  6139.796 train_acc:  0.8671875 test_cost:  6418.4443 test_acc:  0.90625\n",
            "iter:  86 train_cost:  4749.675 train_acc:  0.8984375 test_cost:  3191.1294 test_acc:  0.90625\n",
            "iter:  87 train_cost:  4078.4775 train_acc:  0.8984375 test_cost:  2151.5017 test_acc:  0.9375\n",
            "iter:  88 train_cost:  7138.04 train_acc:  0.8671875 test_cost:  5891.468 test_acc:  0.875\n",
            "iter:  89 train_cost:  5027.7075 train_acc:  0.9140625 test_cost:  1179.0376 test_acc:  0.9296875\n",
            "iter:  90 train_cost:  6541.032 train_acc:  0.8828125 test_cost:  4664.7725 test_acc:  0.90625\n",
            "iter:  91 train_cost:  4960.349 train_acc:  0.8984375 test_cost:  6104.6636 test_acc:  0.921875\n",
            "iter:  92 train_cost:  4869.7725 train_acc:  0.859375 test_cost:  7987.6484 test_acc:  0.84375\n",
            "iter:  93 train_cost:  7347.8555 train_acc:  0.890625 test_cost:  5818.3086 test_acc:  0.8828125\n",
            "iter:  94 train_cost:  1628.3057 train_acc:  0.921875 test_cost:  6365.955 test_acc:  0.8828125\n",
            "iter:  95 train_cost:  4550.756 train_acc:  0.8515625 test_cost:  5022.1084 test_acc:  0.859375\n",
            "iter:  96 train_cost:  5374.269 train_acc:  0.875 test_cost:  6934.721 test_acc:  0.8359375\n",
            "iter:  97 train_cost:  5708.622 train_acc:  0.875 test_cost:  4489.9785 test_acc:  0.875\n",
            "iter:  98 train_cost:  1923.8745 train_acc:  0.90625 test_cost:  4510.9453 test_acc:  0.8984375\n",
            "iter:  99 train_cost:  2839.189 train_acc:  0.9140625 test_cost:  4092.5835 test_acc:  0.921875\n",
            "iter:  100 train_cost:  4359.9546 train_acc:  0.90625 test_cost:  8320.856 test_acc:  0.8828125\n",
            "iter:  101 train_cost:  5548.589 train_acc:  0.8828125 test_cost:  2273.4849 test_acc:  0.90625\n",
            "iter:  102 train_cost:  6503.741 train_acc:  0.84375 test_cost:  3024.874 test_acc:  0.890625\n",
            "iter:  103 train_cost:  4799.867 train_acc:  0.9140625 test_cost:  3287.064 test_acc:  0.9296875\n",
            "iter:  104 train_cost:  2128.6277 train_acc:  0.9453125 test_cost:  6887.248 test_acc:  0.859375\n",
            "iter:  105 train_cost:  3444.9067 train_acc:  0.875 test_cost:  2760.2856 test_acc:  0.921875\n",
            "iter:  106 train_cost:  3742.4006 train_acc:  0.921875 test_cost:  3303.0415 test_acc:  0.9140625\n",
            "iter:  107 train_cost:  7008.162 train_acc:  0.8515625 test_cost:  3705.6323 test_acc:  0.875\n",
            "iter:  108 train_cost:  4572.047 train_acc:  0.8828125 test_cost:  4518.8076 test_acc:  0.9140625\n",
            "iter:  109 train_cost:  4309.634 train_acc:  0.921875 test_cost:  8408.805 test_acc:  0.8671875\n",
            "iter:  110 train_cost:  5219.004 train_acc:  0.8984375 test_cost:  3942.3977 test_acc:  0.90625\n",
            "iter:  111 train_cost:  1741.353 train_acc:  0.9296875 test_cost:  6386.5225 test_acc:  0.859375\n",
            "iter:  112 train_cost:  4922.44 train_acc:  0.9140625 test_cost:  4099.2085 test_acc:  0.921875\n",
            "iter:  113 train_cost:  2122.73 train_acc:  0.921875 test_cost:  3458.0107 test_acc:  0.921875\n",
            "iter:  114 train_cost:  5166.022 train_acc:  0.8828125 test_cost:  3117.0178 test_acc:  0.875\n",
            "iter:  115 train_cost:  1806.2014 train_acc:  0.953125 test_cost:  5568.3843 test_acc:  0.90625\n",
            "iter:  116 train_cost:  4253.2793 train_acc:  0.90625 test_cost:  6519.763 test_acc:  0.8828125\n",
            "iter:  117 train_cost:  6972.5215 train_acc:  0.859375 test_cost:  6365.491 test_acc:  0.859375\n",
            "iter:  118 train_cost:  6475.2266 train_acc:  0.8828125 test_cost:  3553.3281 test_acc:  0.890625\n",
            "iter:  119 train_cost:  6654.0615 train_acc:  0.8515625 test_cost:  4054.4912 test_acc:  0.90625\n",
            "iter:  120 train_cost:  3570.4707 train_acc:  0.875 test_cost:  8509.668 test_acc:  0.84375\n",
            "iter:  121 train_cost:  757.33466 train_acc:  0.9375 test_cost:  5305.3027 test_acc:  0.8828125\n",
            "iter:  122 train_cost:  4577.6772 train_acc:  0.8828125 test_cost:  6911.281 test_acc:  0.8984375\n",
            "iter:  123 train_cost:  1942.6626 train_acc:  0.90625 test_cost:  3993.146 test_acc:  0.8828125\n",
            "iter:  124 train_cost:  5959.793 train_acc:  0.859375 test_cost:  6504.199 test_acc:  0.875\n",
            "iter:  125 train_cost:  2754.769 train_acc:  0.8828125 test_cost:  5832.702 test_acc:  0.828125\n",
            "iter:  126 train_cost:  6821.5693 train_acc:  0.8828125 test_cost:  1593.8479 test_acc:  0.9375\n",
            "iter:  127 train_cost:  1903.9255 train_acc:  0.9296875 test_cost:  3699.192 test_acc:  0.8828125\n",
            "iter:  128 train_cost:  3808.4663 train_acc:  0.9140625 test_cost:  6316.088 test_acc:  0.875\n",
            "iter:  129 train_cost:  2247.05 train_acc:  0.9296875 test_cost:  6312.6123 test_acc:  0.90625\n",
            "iter:  130 train_cost:  1465.1213 train_acc:  0.921875 test_cost:  6747.39 test_acc:  0.890625\n",
            "iter:  131 train_cost:  5962.697 train_acc:  0.8984375 test_cost:  2465.071 test_acc:  0.9375\n",
            "iter:  132 train_cost:  6332.9907 train_acc:  0.9140625 test_cost:  4156.184 test_acc:  0.9140625\n",
            "iter:  133 train_cost:  6524.9893 train_acc:  0.921875 test_cost:  2494.8806 test_acc:  0.9375\n",
            "iter:  134 train_cost:  6777.3154 train_acc:  0.890625 test_cost:  1492.3643 test_acc:  0.9296875\n",
            "iter:  135 train_cost:  5062.0034 train_acc:  0.8984375 test_cost:  5354.9473 test_acc:  0.890625\n",
            "iter:  136 train_cost:  1275.8201 train_acc:  0.9375 test_cost:  7559.2153 test_acc:  0.875\n",
            "iter:  137 train_cost:  5245.6733 train_acc:  0.921875 test_cost:  1758.2681 test_acc:  0.953125\n",
            "iter:  138 train_cost:  3467.3965 train_acc:  0.8828125 test_cost:  2904.351 test_acc:  0.921875\n",
            "iter:  139 train_cost:  3191.3418 train_acc:  0.921875 test_cost:  3150.235 test_acc:  0.921875\n",
            "iter:  140 train_cost:  3404.2944 train_acc:  0.875 test_cost:  2390.3262 test_acc:  0.9140625\n",
            "iter:  141 train_cost:  5075.494 train_acc:  0.8671875 test_cost:  6151.4795 test_acc:  0.921875\n",
            "iter:  142 train_cost:  3851.1924 train_acc:  0.921875 test_cost:  4145.6606 test_acc:  0.9453125\n",
            "iter:  143 train_cost:  959.8752 train_acc:  0.9453125 test_cost:  4884.349 test_acc:  0.8828125\n",
            "iter:  144 train_cost:  4476.5713 train_acc:  0.8828125 test_cost:  5154.252 test_acc:  0.859375\n",
            "iter:  145 train_cost:  2375.06 train_acc:  0.921875 test_cost:  6304.3296 test_acc:  0.8671875\n",
            "iter:  146 train_cost:  1606.4031 train_acc:  0.9375 test_cost:  5038.99 test_acc:  0.875\n",
            "iter:  147 train_cost:  7100.727 train_acc:  0.84375 test_cost:  3744.7405 test_acc:  0.8984375\n",
            "iter:  148 train_cost:  3875.852 train_acc:  0.8828125 test_cost:  3707.8193 test_acc:  0.8828125\n",
            "iter:  149 train_cost:  4618.7363 train_acc:  0.90625 test_cost:  4782.961 test_acc:  0.890625\n",
            "iter:  150 train_cost:  6708.973 train_acc:  0.828125 test_cost:  3170.0115 test_acc:  0.8984375\n",
            "iter:  151 train_cost:  3946.5063 train_acc:  0.875 test_cost:  4720.004 test_acc:  0.8828125\n",
            "iter:  152 train_cost:  3003.195 train_acc:  0.9453125 test_cost:  4170.053 test_acc:  0.9296875\n",
            "iter:  153 train_cost:  3936.722 train_acc:  0.890625 test_cost:  3574.175 test_acc:  0.90625\n",
            "iter:  154 train_cost:  6263.9927 train_acc:  0.875 test_cost:  3596.9292 test_acc:  0.9375\n",
            "iter:  155 train_cost:  4993.053 train_acc:  0.890625 test_cost:  3556.5916 test_acc:  0.921875\n",
            "iter:  156 train_cost:  5159.4443 train_acc:  0.8828125 test_cost:  1860.164 test_acc:  0.9453125\n",
            "iter:  157 train_cost:  2866.186 train_acc:  0.8984375 test_cost:  4780.7334 test_acc:  0.84375\n",
            "iter:  158 train_cost:  3808.5486 train_acc:  0.8984375 test_cost:  3234.617 test_acc:  0.9140625\n",
            "iter:  159 train_cost:  3208.3896 train_acc:  0.9296875 test_cost:  3482.3179 test_acc:  0.90625\n",
            "iter:  160 train_cost:  6925.9863 train_acc:  0.8984375 test_cost:  2284.8955 test_acc:  0.90625\n",
            "iter:  161 train_cost:  2166.1636 train_acc:  0.90625 test_cost:  4601.0396 test_acc:  0.8828125\n",
            "iter:  162 train_cost:  4404.6143 train_acc:  0.9453125 test_cost:  4966.435 test_acc:  0.9140625\n",
            "iter:  163 train_cost:  3609.003 train_acc:  0.921875 test_cost:  6806.3115 test_acc:  0.8984375\n",
            "iter:  164 train_cost:  6106.726 train_acc:  0.875 test_cost:  6610.0767 test_acc:  0.8984375\n",
            "iter:  165 train_cost:  3060.0757 train_acc:  0.8984375 test_cost:  3126.9988 test_acc:  0.890625\n",
            "iter:  166 train_cost:  2620.1824 train_acc:  0.90625 test_cost:  2295.9663 test_acc:  0.921875\n",
            "iter:  167 train_cost:  3020.9438 train_acc:  0.8984375 test_cost:  4535.5977 test_acc:  0.8828125\n",
            "iter:  168 train_cost:  1397.5862 train_acc:  0.9453125 test_cost:  2591.504 test_acc:  0.8984375\n",
            "iter:  169 train_cost:  2370.8406 train_acc:  0.9296875 test_cost:  2752.1526 test_acc:  0.9140625\n",
            "iter:  170 train_cost:  4261.1445 train_acc:  0.875 test_cost:  2797.8218 test_acc:  0.90625\n",
            "iter:  171 train_cost:  1666.293 train_acc:  0.9453125 test_cost:  4416.4043 test_acc:  0.8828125\n",
            "iter:  172 train_cost:  3951.3115 train_acc:  0.8671875 test_cost:  2912.8857 test_acc:  0.9140625\n",
            "iter:  173 train_cost:  2154.9224 train_acc:  0.90625 test_cost:  6732.7705 test_acc:  0.875\n",
            "iter:  174 train_cost:  2803.2358 train_acc:  0.9375 test_cost:  5375.46 test_acc:  0.8984375\n",
            "iter:  175 train_cost:  5405.2725 train_acc:  0.8828125 test_cost:  2437.5657 test_acc:  0.90625\n",
            "iter:  176 train_cost:  3003.856 train_acc:  0.953125 test_cost:  5145.9556 test_acc:  0.875\n",
            "iter:  177 train_cost:  6109.1025 train_acc:  0.921875 test_cost:  2202.1135 test_acc:  0.9296875\n",
            "iter:  178 train_cost:  2723.5596 train_acc:  0.8984375 test_cost:  4372.58 test_acc:  0.859375\n",
            "iter:  179 train_cost:  4288.8545 train_acc:  0.890625 test_cost:  1590.2806 test_acc:  0.9296875\n",
            "iter:  180 train_cost:  9068.322 train_acc:  0.859375 test_cost:  3654.4114 test_acc:  0.90625\n",
            "iter:  181 train_cost:  1594.2163 train_acc:  0.90625 test_cost:  3923.2678 test_acc:  0.8984375\n",
            "iter:  182 train_cost:  2552.5083 train_acc:  0.90625 test_cost:  4525.224 test_acc:  0.8828125\n",
            "iter:  183 train_cost:  3193.967 train_acc:  0.9296875 test_cost:  946.9751 test_acc:  0.9609375\n",
            "iter:  184 train_cost:  5903.9062 train_acc:  0.921875 test_cost:  4554.4385 test_acc:  0.8671875\n",
            "iter:  185 train_cost:  2599.4482 train_acc:  0.9140625 test_cost:  4606.326 test_acc:  0.9296875\n",
            "iter:  186 train_cost:  4125.595 train_acc:  0.8984375 test_cost:  4620.8105 test_acc:  0.9453125\n",
            "iter:  187 train_cost:  4876.8174 train_acc:  0.90625 test_cost:  3814.2139 test_acc:  0.921875\n",
            "iter:  188 train_cost:  3970.455 train_acc:  0.921875 test_cost:  2609.6367 test_acc:  0.953125\n",
            "iter:  189 train_cost:  2678.1262 train_acc:  0.9453125 test_cost:  2618.845 test_acc:  0.9453125\n",
            "iter:  190 train_cost:  4723.3955 train_acc:  0.8828125 test_cost:  3085.552 test_acc:  0.8984375\n",
            "iter:  191 train_cost:  3021.903 train_acc:  0.8828125 test_cost:  3316.4666 test_acc:  0.9375\n",
            "iter:  192 train_cost:  1680.9951 train_acc:  0.9375 test_cost:  3506.69 test_acc:  0.890625\n",
            "iter:  193 train_cost:  3865.0447 train_acc:  0.8984375 test_cost:  3809.1663 test_acc:  0.8984375\n",
            "iter:  194 train_cost:  3914.6082 train_acc:  0.8671875 test_cost:  3636.8613 test_acc:  0.9140625\n",
            "iter:  195 train_cost:  3938.9673 train_acc:  0.890625 test_cost:  1450.7598 test_acc:  0.921875\n",
            "iter:  196 train_cost:  2185.7886 train_acc:  0.8984375 test_cost:  3131.084 test_acc:  0.90625\n",
            "iter:  197 train_cost:  4561.285 train_acc:  0.9140625 test_cost:  8440.291 test_acc:  0.859375\n",
            "iter:  198 train_cost:  3405.396 train_acc:  0.9375 test_cost:  1993.4775 test_acc:  0.9375\n",
            "iter:  199 train_cost:  879.1436 train_acc:  0.9609375 test_cost:  3674.518 test_acc:  0.8984375\n",
            "iter:  200 train_cost:  4888.01 train_acc:  0.8984375 test_cost:  3023.5823 test_acc:  0.9296875\n",
            "iter:  201 train_cost:  3450.3867 train_acc:  0.921875 test_cost:  3167.6936 test_acc:  0.9296875\n",
            "iter:  202 train_cost:  4091.8416 train_acc:  0.90625 test_cost:  1789.1437 test_acc:  0.9453125\n",
            "iter:  203 train_cost:  4571.0293 train_acc:  0.9296875 test_cost:  2613.1628 test_acc:  0.921875\n",
            "iter:  204 train_cost:  4715.1436 train_acc:  0.921875 test_cost:  3651.1335 test_acc:  0.9375\n",
            "iter:  205 train_cost:  4289.3193 train_acc:  0.8984375 test_cost:  3894.2854 test_acc:  0.9296875\n",
            "iter:  206 train_cost:  3644.179 train_acc:  0.90625 test_cost:  1955.7393 test_acc:  0.9375\n",
            "iter:  207 train_cost:  2802.59 train_acc:  0.90625 test_cost:  3121.1582 test_acc:  0.9609375\n",
            "iter:  208 train_cost:  1746.0098 train_acc:  0.9453125 test_cost:  5537.6665 test_acc:  0.90625\n",
            "iter:  209 train_cost:  3347.6914 train_acc:  0.9296875 test_cost:  2416.8496 test_acc:  0.9296875\n",
            "iter:  210 train_cost:  2824.174 train_acc:  0.9453125 test_cost:  4765.8076 test_acc:  0.90625\n",
            "iter:  211 train_cost:  3412.225 train_acc:  0.9140625 test_cost:  3617.504 test_acc:  0.890625\n",
            "iter:  212 train_cost:  3261.4463 train_acc:  0.921875 test_cost:  5035.056 test_acc:  0.9140625\n",
            "iter:  213 train_cost:  2094.4324 train_acc:  0.9140625 test_cost:  2241.8245 test_acc:  0.9296875\n",
            "iter:  214 train_cost:  5387.912 train_acc:  0.890625 test_cost:  3085.1538 test_acc:  0.9296875\n",
            "iter:  215 train_cost:  2392.2095 train_acc:  0.9296875 test_cost:  4903.8584 test_acc:  0.8984375\n",
            "iter:  216 train_cost:  2189.0938 train_acc:  0.9296875 test_cost:  2668.9272 test_acc:  0.9296875\n",
            "iter:  217 train_cost:  3082.293 train_acc:  0.9140625 test_cost:  2649.1992 test_acc:  0.9375\n",
            "iter:  218 train_cost:  2634.6968 train_acc:  0.9609375 test_cost:  1010.5201 test_acc:  0.9140625\n",
            "iter:  219 train_cost:  1031.6648 train_acc:  0.9375 test_cost:  1796.4613 test_acc:  0.9296875\n",
            "iter:  220 train_cost:  3503.6938 train_acc:  0.9375 test_cost:  2250.583 test_acc:  0.9609375\n",
            "iter:  221 train_cost:  3305.5635 train_acc:  0.90625 test_cost:  2899.4385 test_acc:  0.9296875\n",
            "iter:  222 train_cost:  4516.7896 train_acc:  0.8984375 test_cost:  2349.5771 test_acc:  0.921875\n",
            "iter:  223 train_cost:  2550.539 train_acc:  0.9140625 test_cost:  2936.428 test_acc:  0.8828125\n",
            "iter:  224 train_cost:  2291.4731 train_acc:  0.921875 test_cost:  2140.4854 test_acc:  0.90625\n",
            "iter:  225 train_cost:  2925.0454 train_acc:  0.890625 test_cost:  1313.5383 test_acc:  0.96875\n",
            "iter:  226 train_cost:  4387.15 train_acc:  0.90625 test_cost:  7486.1426 test_acc:  0.859375\n",
            "iter:  227 train_cost:  3995.7898 train_acc:  0.90625 test_cost:  3449.7773 test_acc:  0.890625\n",
            "iter:  228 train_cost:  2423.3188 train_acc:  0.9453125 test_cost:  3810.4407 test_acc:  0.921875\n",
            "iter:  229 train_cost:  4218.3403 train_acc:  0.921875 test_cost:  4009.8948 test_acc:  0.90625\n",
            "iter:  230 train_cost:  279.5287 train_acc:  0.953125 test_cost:  2521.5344 test_acc:  0.9296875\n",
            "iter:  231 train_cost:  4463.3037 train_acc:  0.890625 test_cost:  3946.8997 test_acc:  0.9140625\n",
            "iter:  232 train_cost:  1229.7852 train_acc:  0.9609375 test_cost:  1580.0225 test_acc:  0.9296875\n",
            "iter:  233 train_cost:  2497.3174 train_acc:  0.9609375 test_cost:  2899.4058 test_acc:  0.9296875\n",
            "iter:  234 train_cost:  1748.2646 train_acc:  0.9296875 test_cost:  4385.759 test_acc:  0.9375\n",
            "iter:  235 train_cost:  3564.3208 train_acc:  0.921875 test_cost:  3179.5718 test_acc:  0.8984375\n",
            "iter:  236 train_cost:  2552.225 train_acc:  0.9296875 test_cost:  2698.0127 test_acc:  0.90625\n",
            "iter:  237 train_cost:  4935.315 train_acc:  0.84375 test_cost:  2791.2817 test_acc:  0.8984375\n",
            "iter:  238 train_cost:  3429.1736 train_acc:  0.9453125 test_cost:  1280.4807 test_acc:  0.921875\n",
            "iter:  239 train_cost:  3355.9985 train_acc:  0.8984375 test_cost:  5085.5356 test_acc:  0.8671875\n",
            "iter:  240 train_cost:  2871.5579 train_acc:  0.9296875 test_cost:  3069.3132 test_acc:  0.890625\n",
            "iter:  241 train_cost:  2608.1753 train_acc:  0.921875 test_cost:  5719.8887 test_acc:  0.8984375\n",
            "iter:  242 train_cost:  2465.223 train_acc:  0.9375 test_cost:  1123.9568 test_acc:  0.953125\n",
            "iter:  243 train_cost:  2132.7202 train_acc:  0.9375 test_cost:  1643.4335 test_acc:  0.9375\n",
            "iter:  244 train_cost:  2251.6836 train_acc:  0.9296875 test_cost:  2258.6377 test_acc:  0.9140625\n",
            "iter:  245 train_cost:  1797.397 train_acc:  0.90625 test_cost:  5888.812 test_acc:  0.9296875\n",
            "iter:  246 train_cost:  3174.523 train_acc:  0.9140625 test_cost:  2541.3757 test_acc:  0.9296875\n",
            "iter:  247 train_cost:  2179.0288 train_acc:  0.921875 test_cost:  3326.0479 test_acc:  0.890625\n",
            "iter:  248 train_cost:  1226.6367 train_acc:  0.9375 test_cost:  1719.2728 test_acc:  0.9375\n",
            "iter:  249 train_cost:  3461.9265 train_acc:  0.875 test_cost:  4548.9565 test_acc:  0.921875\n",
            "iter:  250 train_cost:  2698.0464 train_acc:  0.9375 test_cost:  4621.522 test_acc:  0.9140625\n",
            "iter:  251 train_cost:  591.97974 train_acc:  0.96875 test_cost:  2875.1062 test_acc:  0.8984375\n",
            "iter:  252 train_cost:  1069.684 train_acc:  0.96875 test_cost:  2164.6418 test_acc:  0.953125\n",
            "iter:  253 train_cost:  5717.492 train_acc:  0.859375 test_cost:  1637.7351 test_acc:  0.9375\n",
            "iter:  254 train_cost:  4127.3486 train_acc:  0.90625 test_cost:  3410.5967 test_acc:  0.921875\n",
            "iter:  255 train_cost:  2988.8901 train_acc:  0.9375 test_cost:  1825.1113 test_acc:  0.9453125\n",
            "iter:  256 train_cost:  2725.4053 train_acc:  0.9453125 test_cost:  1185.9077 test_acc:  0.9453125\n",
            "iter:  257 train_cost:  1030.7849 train_acc:  0.953125 test_cost:  4319.185 test_acc:  0.9296875\n",
            "iter:  258 train_cost:  1827.5315 train_acc:  0.9140625 test_cost:  4857.497 test_acc:  0.90625\n",
            "iter:  259 train_cost:  2439.5813 train_acc:  0.9140625 test_cost:  968.392 test_acc:  0.9609375\n",
            "iter:  260 train_cost:  2812.8223 train_acc:  0.9296875 test_cost:  1205.4974 test_acc:  0.9375\n",
            "iter:  261 train_cost:  734.1318 train_acc:  0.9609375 test_cost:  4291.396 test_acc:  0.9296875\n",
            "iter:  262 train_cost:  2747.6702 train_acc:  0.9140625 test_cost:  3356.9922 test_acc:  0.921875\n",
            "iter:  263 train_cost:  2165.3423 train_acc:  0.953125 test_cost:  4278.3413 test_acc:  0.9140625\n",
            "iter:  264 train_cost:  1651.3094 train_acc:  0.9453125 test_cost:  2932.0735 test_acc:  0.9296875\n",
            "iter:  265 train_cost:  1961.3911 train_acc:  0.9296875 test_cost:  1384.3602 test_acc:  0.9375\n",
            "iter:  266 train_cost:  1411.354 train_acc:  0.9609375 test_cost:  2379.2473 test_acc:  0.90625\n",
            "iter:  267 train_cost:  2545.0583 train_acc:  0.9140625 test_cost:  4992.9307 test_acc:  0.90625\n",
            "iter:  268 train_cost:  1110.8098 train_acc:  0.9453125 test_cost:  2167.191 test_acc:  0.9609375\n",
            "iter:  269 train_cost:  1386.6724 train_acc:  0.921875 test_cost:  2164.8237 test_acc:  0.9140625\n",
            "iter:  270 train_cost:  1708.986 train_acc:  0.9453125 test_cost:  2478.0679 test_acc:  0.9296875\n",
            "iter:  271 train_cost:  2152.752 train_acc:  0.90625 test_cost:  4834.467 test_acc:  0.890625\n",
            "iter:  272 train_cost:  2387.7363 train_acc:  0.9375 test_cost:  1495.3312 test_acc:  0.953125\n",
            "iter:  273 train_cost:  1930.3455 train_acc:  0.9375 test_cost:  1150.6123 test_acc:  0.953125\n",
            "iter:  274 train_cost:  3910.361 train_acc:  0.921875 test_cost:  5425.997 test_acc:  0.8828125\n",
            "iter:  275 train_cost:  2838.893 train_acc:  0.9140625 test_cost:  1257.8457 test_acc:  0.9140625\n",
            "iter:  276 train_cost:  4034.657 train_acc:  0.9140625 test_cost:  2688.7837 test_acc:  0.90625\n",
            "iter:  277 train_cost:  1156.3534 train_acc:  0.9375 test_cost:  2124.6519 test_acc:  0.9296875\n",
            "iter:  278 train_cost:  1183.8893 train_acc:  0.953125 test_cost:  188.25067 test_acc:  0.9765625\n",
            "iter:  279 train_cost:  3892.9653 train_acc:  0.921875 test_cost:  2457.128 test_acc:  0.90625\n",
            "iter:  280 train_cost:  290.7666 train_acc:  0.984375 test_cost:  1683.4021 test_acc:  0.953125\n",
            "iter:  281 train_cost:  3670.0735 train_acc:  0.921875 test_cost:  2693.361 test_acc:  0.90625\n",
            "iter:  282 train_cost:  2088.2244 train_acc:  0.9140625 test_cost:  1146.2183 test_acc:  0.9609375\n",
            "iter:  283 train_cost:  1489.1372 train_acc:  0.96875 test_cost:  3836.2437 test_acc:  0.890625\n",
            "iter:  284 train_cost:  2446.9165 train_acc:  0.921875 test_cost:  3360.0723 test_acc:  0.8984375\n",
            "iter:  285 train_cost:  3907.242 train_acc:  0.9375 test_cost:  1207.5671 test_acc:  0.9453125\n",
            "iter:  286 train_cost:  2253.3618 train_acc:  0.8828125 test_cost:  2945.764 test_acc:  0.9375\n",
            "iter:  287 train_cost:  1153.614 train_acc:  0.96875 test_cost:  2306.7002 test_acc:  0.9453125\n",
            "iter:  288 train_cost:  4857.8496 train_acc:  0.90625 test_cost:  3398.6663 test_acc:  0.8984375\n",
            "iter:  289 train_cost:  2052.2747 train_acc:  0.9453125 test_cost:  1375.3274 test_acc:  0.953125\n",
            "iter:  290 train_cost:  3904.5674 train_acc:  0.90625 test_cost:  1674.3123 test_acc:  0.9375\n",
            "iter:  291 train_cost:  2805.903 train_acc:  0.9375 test_cost:  1625.9097 test_acc:  0.9296875\n",
            "iter:  292 train_cost:  609.05505 train_acc:  0.953125 test_cost:  600.532 test_acc:  0.96875\n",
            "iter:  293 train_cost:  1894.1388 train_acc:  0.953125 test_cost:  2942.4124 test_acc:  0.9375\n",
            "iter:  294 train_cost:  1928.859 train_acc:  0.9453125 test_cost:  4778.4443 test_acc:  0.90625\n",
            "iter:  295 train_cost:  1451.0277 train_acc:  0.9453125 test_cost:  3070.2144 test_acc:  0.9453125\n",
            "iter:  296 train_cost:  5086.342 train_acc:  0.90625 test_cost:  3439.0955 test_acc:  0.921875\n",
            "iter:  297 train_cost:  1256.8141 train_acc:  0.9609375 test_cost:  664.11957 test_acc:  0.9609375\n",
            "iter:  298 train_cost:  4848.4434 train_acc:  0.890625 test_cost:  2490.5894 test_acc:  0.9375\n",
            "iter:  299 train_cost:  1589.6948 train_acc:  0.9296875 test_cost:  2996.67 test_acc:  0.921875\n",
            "iter:  300 train_cost:  426.67706 train_acc:  0.9609375 test_cost:  607.14923 test_acc:  0.9609375\n",
            "iter:  301 train_cost:  1256.5796 train_acc:  0.96875 test_cost:  1739.1195 test_acc:  0.953125\n",
            "iter:  302 train_cost:  2339.195 train_acc:  0.9375 test_cost:  2340.2588 test_acc:  0.9296875\n",
            "iter:  303 train_cost:  1840.8864 train_acc:  0.9296875 test_cost:  1286.1604 test_acc:  0.9296875\n",
            "iter:  304 train_cost:  1283.0292 train_acc:  0.921875 test_cost:  2011.3125 test_acc:  0.9296875\n",
            "iter:  305 train_cost:  3136.8784 train_acc:  0.9453125 test_cost:  4128.2646 test_acc:  0.890625\n",
            "iter:  306 train_cost:  3051.6455 train_acc:  0.9375 test_cost:  3649.4038 test_acc:  0.9296875\n",
            "iter:  307 train_cost:  1029.405 train_acc:  0.9453125 test_cost:  1273.7664 test_acc:  0.9375\n",
            "iter:  308 train_cost:  1146.0605 train_acc:  0.9375 test_cost:  1352.0093 test_acc:  0.9453125\n",
            "iter:  309 train_cost:  1275.8333 train_acc:  0.96875 test_cost:  465.90622 test_acc:  0.9609375\n",
            "iter:  310 train_cost:  3489.294 train_acc:  0.9375 test_cost:  816.15753 test_acc:  0.953125\n",
            "iter:  311 train_cost:  1435.4144 train_acc:  0.953125 test_cost:  1275.8987 test_acc:  0.9375\n",
            "iter:  312 train_cost:  1114.487 train_acc:  0.9609375 test_cost:  5710.9873 test_acc:  0.9140625\n",
            "iter:  313 train_cost:  1196.3843 train_acc:  0.953125 test_cost:  2357.1533 test_acc:  0.8984375\n",
            "iter:  314 train_cost:  1535.6865 train_acc:  0.8984375 test_cost:  2268.838 test_acc:  0.9375\n",
            "iter:  315 train_cost:  1477.7239 train_acc:  0.9609375 test_cost:  806.52234 test_acc:  0.9609375\n",
            "iter:  316 train_cost:  2740.809 train_acc:  0.8828125 test_cost:  4888.2334 test_acc:  0.8828125\n",
            "iter:  317 train_cost:  1834.8728 train_acc:  0.9375 test_cost:  982.2175 test_acc:  0.96875\n",
            "iter:  318 train_cost:  760.551 train_acc:  0.9609375 test_cost:  2542.7317 test_acc:  0.9296875\n",
            "iter:  319 train_cost:  2684.4268 train_acc:  0.953125 test_cost:  1712.8553 test_acc:  0.9375\n",
            "iter:  320 train_cost:  1206.6716 train_acc:  0.9609375 test_cost:  2037.9192 test_acc:  0.9296875\n",
            "iter:  321 train_cost:  393.4955 train_acc:  0.984375 test_cost:  2592.6172 test_acc:  0.9296875\n",
            "iter:  322 train_cost:  2637.8127 train_acc:  0.9296875 test_cost:  3378.0273 test_acc:  0.9296875\n",
            "iter:  323 train_cost:  3723.501 train_acc:  0.90625 test_cost:  3372.58 test_acc:  0.890625\n",
            "iter:  324 train_cost:  3537.8032 train_acc:  0.9375 test_cost:  4294.6567 test_acc:  0.9375\n",
            "iter:  325 train_cost:  2647.3574 train_acc:  0.8984375 test_cost:  2629.6792 test_acc:  0.90625\n",
            "iter:  326 train_cost:  748.6272 train_acc:  0.9765625 test_cost:  3096.5664 test_acc:  0.9296875\n",
            "iter:  327 train_cost:  970.4164 train_acc:  0.9765625 test_cost:  2034.6307 test_acc:  0.953125\n",
            "iter:  328 train_cost:  2565.8843 train_acc:  0.875 test_cost:  4698.6016 test_acc:  0.890625\n",
            "iter:  329 train_cost:  3591.55 train_acc:  0.8828125 test_cost:  2799.6167 test_acc:  0.953125\n",
            "iter:  330 train_cost:  2356.0054 train_acc:  0.90625 test_cost:  3209.6191 test_acc:  0.9375\n",
            "iter:  331 train_cost:  5148.2275 train_acc:  0.90625 test_cost:  3477.4453 test_acc:  0.890625\n",
            "iter:  332 train_cost:  4508.5127 train_acc:  0.9140625 test_cost:  2046.6072 test_acc:  0.9453125\n",
            "iter:  333 train_cost:  3207.656 train_acc:  0.9296875 test_cost:  1142.517 test_acc:  0.953125\n",
            "iter:  334 train_cost:  1112.9121 train_acc:  0.953125 test_cost:  3503.114 test_acc:  0.9375\n",
            "iter:  335 train_cost:  2209.7214 train_acc:  0.921875 test_cost:  1210.7986 test_acc:  0.9453125\n",
            "iter:  336 train_cost:  2956.1313 train_acc:  0.9453125 test_cost:  3004.9258 test_acc:  0.9296875\n",
            "iter:  337 train_cost:  1682.5295 train_acc:  0.953125 test_cost:  1621.9197 test_acc:  0.9609375\n",
            "iter:  338 train_cost:  5879.308 train_acc:  0.8828125 test_cost:  1387.37 test_acc:  0.9453125\n",
            "iter:  339 train_cost:  1683.5859 train_acc:  0.9453125 test_cost:  6302.81 test_acc:  0.90625\n",
            "iter:  340 train_cost:  2818.1758 train_acc:  0.8984375 test_cost:  2073.2031 test_acc:  0.9296875\n",
            "iter:  341 train_cost:  1752.7825 train_acc:  0.9375 test_cost:  1086.7245 test_acc:  0.9375\n",
            "iter:  342 train_cost:  2499.5244 train_acc:  0.953125 test_cost:  4059.3093 test_acc:  0.9375\n",
            "iter:  343 train_cost:  2100.9277 train_acc:  0.9296875 test_cost:  2525.316 test_acc:  0.9296875\n",
            "iter:  344 train_cost:  3666.574 train_acc:  0.921875 test_cost:  1571.886 test_acc:  0.9453125\n",
            "iter:  345 train_cost:  1325.6323 train_acc:  0.9375 test_cost:  2321.3743 test_acc:  0.8984375\n",
            "iter:  346 train_cost:  3271.3699 train_acc:  0.9140625 test_cost:  1562.5898 test_acc:  0.9296875\n",
            "iter:  347 train_cost:  1683.8772 train_acc:  0.9375 test_cost:  2369.2144 test_acc:  0.921875\n",
            "iter:  348 train_cost:  1997.478 train_acc:  0.921875 test_cost:  1728.304 test_acc:  0.9140625\n",
            "iter:  349 train_cost:  3156.9407 train_acc:  0.9140625 test_cost:  1577.7192 test_acc:  0.9453125\n",
            "iter:  350 train_cost:  1735.7089 train_acc:  0.9140625 test_cost:  2013.0503 test_acc:  0.921875\n",
            "iter:  351 train_cost:  3037.902 train_acc:  0.9375 test_cost:  2225.7217 test_acc:  0.8984375\n",
            "iter:  352 train_cost:  2599.0054 train_acc:  0.9296875 test_cost:  3436.0972 test_acc:  0.90625\n",
            "iter:  353 train_cost:  2236.9626 train_acc:  0.9296875 test_cost:  2228.2866 test_acc:  0.96875\n",
            "iter:  354 train_cost:  3223.4048 train_acc:  0.9375 test_cost:  2475.7178 test_acc:  0.953125\n",
            "iter:  355 train_cost:  1398.6384 train_acc:  0.9453125 test_cost:  4800.7847 test_acc:  0.9140625\n",
            "iter:  356 train_cost:  2599.2036 train_acc:  0.9296875 test_cost:  311.69244 test_acc:  0.9765625\n",
            "iter:  357 train_cost:  1402.8358 train_acc:  0.9609375 test_cost:  1730.9813 test_acc:  0.953125\n",
            "iter:  358 train_cost:  2335.821 train_acc:  0.953125 test_cost:  3465.1829 test_acc:  0.8984375\n",
            "iter:  359 train_cost:  2606.403 train_acc:  0.9375 test_cost:  2366.6577 test_acc:  0.921875\n",
            "iter:  360 train_cost:  3499.0972 train_acc:  0.9140625 test_cost:  3886.4192 test_acc:  0.921875\n",
            "iter:  361 train_cost:  1938.9308 train_acc:  0.9453125 test_cost:  3207.6567 test_acc:  0.9296875\n",
            "iter:  362 train_cost:  2898.692 train_acc:  0.921875 test_cost:  1594.5251 test_acc:  0.9609375\n",
            "iter:  363 train_cost:  1544.5974 train_acc:  0.9609375 test_cost:  2206.7344 test_acc:  0.953125\n",
            "iter:  364 train_cost:  1014.0644 train_acc:  0.9375 test_cost:  2314.6333 test_acc:  0.9140625\n",
            "iter:  365 train_cost:  1419.0352 train_acc:  0.953125 test_cost:  3041.6172 test_acc:  0.9453125\n",
            "iter:  366 train_cost:  1345.9309 train_acc:  0.953125 test_cost:  3951.3843 test_acc:  0.9375\n",
            "iter:  367 train_cost:  2957.698 train_acc:  0.921875 test_cost:  988.64703 test_acc:  0.9609375\n",
            "iter:  368 train_cost:  760.84357 train_acc:  0.953125 test_cost:  2724.6562 test_acc:  0.9609375\n",
            "iter:  369 train_cost:  458.82968 train_acc:  0.96875 test_cost:  2882.5122 test_acc:  0.921875\n",
            "iter:  370 train_cost:  2059.501 train_acc:  0.9453125 test_cost:  4179.301 test_acc:  0.921875\n",
            "iter:  371 train_cost:  967.00757 train_acc:  0.9609375 test_cost:  2879.807 test_acc:  0.9140625\n",
            "iter:  372 train_cost:  317.71307 train_acc:  0.9765625 test_cost:  1762.4934 test_acc:  0.9453125\n",
            "iter:  373 train_cost:  869.3882 train_acc:  0.9765625 test_cost:  3162.1875 test_acc:  0.921875\n",
            "iter:  374 train_cost:  1816.3911 train_acc:  0.9609375 test_cost:  1341.054 test_acc:  0.9609375\n",
            "iter:  375 train_cost:  3656.1492 train_acc:  0.90625 test_cost:  2256.3186 test_acc:  0.9296875\n",
            "iter:  376 train_cost:  1915.6184 train_acc:  0.9453125 test_cost:  690.32166 test_acc:  0.9453125\n",
            "iter:  377 train_cost:  3292.2236 train_acc:  0.890625 test_cost:  2298.99 test_acc:  0.9453125\n",
            "iter:  378 train_cost:  2738.918 train_acc:  0.9453125 test_cost:  3118.663 test_acc:  0.9296875\n",
            "iter:  379 train_cost:  3985.0078 train_acc:  0.9296875 test_cost:  131.5304 test_acc:  0.984375\n",
            "iter:  380 train_cost:  1960.1215 train_acc:  0.9375 test_cost:  1644.8053 test_acc:  0.953125\n",
            "iter:  381 train_cost:  3429.9114 train_acc:  0.9296875 test_cost:  1537.1626 test_acc:  0.96875\n",
            "iter:  382 train_cost:  2404.523 train_acc:  0.9375 test_cost:  1284.9127 test_acc:  0.953125\n",
            "iter:  383 train_cost:  2572.4307 train_acc:  0.9140625 test_cost:  2214.2476 test_acc:  0.9453125\n",
            "iter:  384 train_cost:  2567.9683 train_acc:  0.9296875 test_cost:  2891.0225 test_acc:  0.96875\n",
            "iter:  385 train_cost:  947.3953 train_acc:  0.9609375 test_cost:  1907.3496 test_acc:  0.9453125\n",
            "iter:  386 train_cost:  1629.0479 train_acc:  0.953125 test_cost:  784.3063 test_acc:  0.9609375\n",
            "iter:  387 train_cost:  2658.448 train_acc:  0.953125 test_cost:  1546.3 test_acc:  0.9296875\n",
            "iter:  388 train_cost:  2415.662 train_acc:  0.921875 test_cost:  2767.0994 test_acc:  0.9453125\n",
            "iter:  389 train_cost:  2270.5093 train_acc:  0.921875 test_cost:  2742.5144 test_acc:  0.9296875\n",
            "iter:  390 train_cost:  4483.507 train_acc:  0.9375 test_cost:  1135.6141 test_acc:  0.9609375\n",
            "iter:  391 train_cost:  3737.019 train_acc:  0.9375 test_cost:  3969.2021 test_acc:  0.9375\n",
            "iter:  392 train_cost:  1935.4928 train_acc:  0.9140625 test_cost:  699.2007 test_acc:  0.9609375\n",
            "iter:  393 train_cost:  2388.7617 train_acc:  0.9375 test_cost:  1229.8823 test_acc:  0.953125\n",
            "iter:  394 train_cost:  1618.9175 train_acc:  0.9140625 test_cost:  1078.8569 test_acc:  0.953125\n",
            "iter:  395 train_cost:  2244.2263 train_acc:  0.953125 test_cost:  1802.6768 test_acc:  0.953125\n",
            "iter:  396 train_cost:  1205.5266 train_acc:  0.96875 test_cost:  2015.7552 test_acc:  0.953125\n",
            "iter:  397 train_cost:  3331.0618 train_acc:  0.9140625 test_cost:  3499.2053 test_acc:  0.921875\n",
            "iter:  398 train_cost:  1179.3468 train_acc:  0.96875 test_cost:  794.1718 test_acc:  0.9765625\n",
            "iter:  399 train_cost:  711.6414 train_acc:  0.9765625 test_cost:  2556.3318 test_acc:  0.9375\n",
            "iter:  400 train_cost:  578.1137 train_acc:  0.9765625 test_cost:  1667.788 test_acc:  0.9609375\n",
            "iter:  401 train_cost:  430.12192 train_acc:  0.96875 test_cost:  3624.8184 test_acc:  0.9296875\n",
            "iter:  402 train_cost:  702.00397 train_acc:  0.9375 test_cost:  1090.8582 test_acc:  0.9296875\n",
            "iter:  403 train_cost:  1024.718 train_acc:  0.953125 test_cost:  1749.9885 test_acc:  0.9375\n",
            "iter:  404 train_cost:  1930.7726 train_acc:  0.953125 test_cost:  2304.0098 test_acc:  0.953125\n",
            "iter:  405 train_cost:  2836.289 train_acc:  0.9140625 test_cost:  1086.6462 test_acc:  0.9765625\n",
            "iter:  406 train_cost:  1682.9968 train_acc:  0.9375 test_cost:  2542.0903 test_acc:  0.90625\n",
            "iter:  407 train_cost:  2342.3657 train_acc:  0.9296875 test_cost:  3078.2979 test_acc:  0.9140625\n",
            "iter:  408 train_cost:  1284.097 train_acc:  0.9609375 test_cost:  2838.1748 test_acc:  0.9375\n",
            "iter:  409 train_cost:  537.7438 train_acc:  0.96875 test_cost:  3963.4104 test_acc:  0.921875\n",
            "iter:  410 train_cost:  1294.0256 train_acc:  0.953125 test_cost:  1595.9841 test_acc:  0.953125\n",
            "iter:  411 train_cost:  1498.2198 train_acc:  0.953125 test_cost:  1407.6785 test_acc:  0.96875\n",
            "iter:  412 train_cost:  1386.4844 train_acc:  0.953125 test_cost:  2280.0066 test_acc:  0.9375\n",
            "iter:  413 train_cost:  905.19055 train_acc:  0.96875 test_cost:  1703.8304 test_acc:  0.9375\n",
            "iter:  414 train_cost:  1667.9998 train_acc:  0.921875 test_cost:  2285.3857 test_acc:  0.9296875\n",
            "iter:  415 train_cost:  1393.6841 train_acc:  0.9140625 test_cost:  3515.3828 test_acc:  0.9140625\n",
            "iter:  416 train_cost:  2223.2578 train_acc:  0.9296875 test_cost:  3133.5515 test_acc:  0.90625\n",
            "iter:  417 train_cost:  1512.3545 train_acc:  0.9375 test_cost:  2675.1973 test_acc:  0.9296875\n",
            "iter:  418 train_cost:  653.04474 train_acc:  0.96875 test_cost:  770.2244 test_acc:  0.96875\n",
            "iter:  419 train_cost:  2133.888 train_acc:  0.9609375 test_cost:  4031.3594 test_acc:  0.9140625\n",
            "iter:  420 train_cost:  2700.7517 train_acc:  0.9296875 test_cost:  3250.0674 test_acc:  0.9453125\n",
            "iter:  421 train_cost:  5091.21 train_acc:  0.921875 test_cost:  1058.8057 test_acc:  0.96875\n",
            "iter:  422 train_cost:  1000.1299 train_acc:  0.9609375 test_cost:  307.9218 test_acc:  0.96875\n",
            "iter:  423 train_cost:  874.7244 train_acc:  0.9453125 test_cost:  2662.2627 test_acc:  0.9375\n",
            "iter:  424 train_cost:  2131.7344 train_acc:  0.9375 test_cost:  992.8901 test_acc:  0.953125\n",
            "iter:  425 train_cost:  1327.3027 train_acc:  0.9375 test_cost:  2489.1316 test_acc:  0.9375\n",
            "iter:  426 train_cost:  407.22076 train_acc:  0.9609375 test_cost:  1880.8525 test_acc:  0.9609375\n",
            "iter:  427 train_cost:  2756.1353 train_acc:  0.9453125 test_cost:  1042.1973 test_acc:  0.9609375\n",
            "iter:  428 train_cost:  2371.7947 train_acc:  0.921875 test_cost:  1616.704 test_acc:  0.9453125\n",
            "iter:  429 train_cost:  1030.3191 train_acc:  0.953125 test_cost:  1884.4034 test_acc:  0.9609375\n",
            "iter:  430 train_cost:  2536.3093 train_acc:  0.9453125 test_cost:  1647.3701 test_acc:  0.96875\n",
            "iter:  431 train_cost:  1210.5144 train_acc:  0.9453125 test_cost:  2753.8838 test_acc:  0.921875\n",
            "iter:  432 train_cost:  1543.2665 train_acc:  0.9375 test_cost:  980.489 test_acc:  0.9765625\n",
            "iter:  433 train_cost:  304.8598 train_acc:  0.9765625 test_cost:  911.29456 test_acc:  0.9765625\n",
            "iter:  434 train_cost:  2293.1658 train_acc:  0.9375 test_cost:  2159.4543 test_acc:  0.9375\n",
            "iter:  435 train_cost:  410.29163 train_acc:  0.953125 test_cost:  1948.6766 test_acc:  0.9140625\n",
            "iter:  436 train_cost:  761.3258 train_acc:  0.9765625 test_cost:  1451.488 test_acc:  0.953125\n",
            "iter:  437 train_cost:  1367.6738 train_acc:  0.9296875 test_cost:  2259.2158 test_acc:  0.9375\n",
            "iter:  438 train_cost:  632.0859 train_acc:  0.9609375 test_cost:  0.0 test_acc:  1.0\n",
            "iter:  439 train_cost:  1417.0803 train_acc:  0.9609375 test_cost:  741.1992 test_acc:  0.9453125\n",
            "iter:  440 train_cost:  1490.8357 train_acc:  0.953125 test_cost:  1428.0098 test_acc:  0.953125\n",
            "iter:  441 train_cost:  3143.0176 train_acc:  0.9453125 test_cost:  1516.2065 test_acc:  0.9140625\n",
            "iter:  442 train_cost:  1596.0217 train_acc:  0.9453125 test_cost:  1997.4164 test_acc:  0.9609375\n",
            "iter:  443 train_cost:  1369.6085 train_acc:  0.9609375 test_cost:  545.6669 test_acc:  0.9765625\n",
            "iter:  444 train_cost:  1083.1996 train_acc:  0.9765625 test_cost:  2606.9019 test_acc:  0.9453125\n",
            "iter:  445 train_cost:  2108.7646 train_acc:  0.921875 test_cost:  3612.931 test_acc:  0.921875\n",
            "iter:  446 train_cost:  1128.46 train_acc:  0.96875 test_cost:  1087.5322 test_acc:  0.96875\n",
            "iter:  447 train_cost:  214.22974 train_acc:  0.9765625 test_cost:  1347.2341 test_acc:  0.9453125\n",
            "iter:  448 train_cost:  710.3751 train_acc:  0.953125 test_cost:  1246.0171 test_acc:  0.953125\n",
            "iter:  449 train_cost:  1276.4991 train_acc:  0.9453125 test_cost:  1454.5195 test_acc:  0.9609375\n",
            "iter:  450 train_cost:  1565.7615 train_acc:  0.9375 test_cost:  1747.2068 test_acc:  0.9453125\n",
            "iter:  451 train_cost:  836.2501 train_acc:  0.96875 test_cost:  1637.8331 test_acc:  0.953125\n",
            "iter:  452 train_cost:  451.5677 train_acc:  0.96875 test_cost:  222.9975 test_acc:  0.984375\n",
            "iter:  453 train_cost:  2493.1846 train_acc:  0.953125 test_cost:  1204.2513 test_acc:  0.9375\n",
            "iter:  454 train_cost:  1102.3584 train_acc:  0.96875 test_cost:  1682.1633 test_acc:  0.9609375\n",
            "iter:  455 train_cost:  1325.6211 train_acc:  0.9453125 test_cost:  1602.3595 test_acc:  0.9296875\n",
            "iter:  456 train_cost:  2299.0579 train_acc:  0.9375 test_cost:  2989.1328 test_acc:  0.9375\n",
            "iter:  457 train_cost:  2217.2734 train_acc:  0.9765625 test_cost:  1940.0476 test_acc:  0.96875\n",
            "iter:  458 train_cost:  739.11224 train_acc:  0.9609375 test_cost:  3167.5474 test_acc:  0.9140625\n",
            "iter:  459 train_cost:  492.4596 train_acc:  0.9765625 test_cost:  1406.0463 test_acc:  0.9453125\n",
            "iter:  460 train_cost:  336.24664 train_acc:  0.9765625 test_cost:  2562.6611 test_acc:  0.9453125\n",
            "iter:  461 train_cost:  1581.5159 train_acc:  0.9609375 test_cost:  192.01147 test_acc:  0.9765625\n",
            "iter:  462 train_cost:  1100.5725 train_acc:  0.953125 test_cost:  3657.2876 test_acc:  0.953125\n",
            "iter:  463 train_cost:  905.9627 train_acc:  0.9609375 test_cost:  3464.0662 test_acc:  0.9375\n",
            "iter:  464 train_cost:  365.61255 train_acc:  0.9609375 test_cost:  2470.6104 test_acc:  0.9453125\n",
            "iter:  465 train_cost:  1819.6584 train_acc:  0.9453125 test_cost:  3077.7993 test_acc:  0.9375\n",
            "iter:  466 train_cost:  2087.1777 train_acc:  0.9296875 test_cost:  2860.9946 test_acc:  0.9375\n",
            "iter:  467 train_cost:  839.16315 train_acc:  0.9609375 test_cost:  2596.7659 test_acc:  0.9453125\n",
            "iter:  468 train_cost:  739.6334 train_acc:  0.9765625 test_cost:  753.0159 test_acc:  0.9609375\n",
            "iter:  469 train_cost:  1041.2926 train_acc:  0.953125 test_cost:  701.905 test_acc:  0.953125\n",
            "iter:  470 train_cost:  2398.65 train_acc:  0.921875 test_cost:  1774.5878 test_acc:  0.9296875\n",
            "iter:  471 train_cost:  1863.1692 train_acc:  0.953125 test_cost:  3073.2268 test_acc:  0.9453125\n",
            "iter:  472 train_cost:  746.60205 train_acc:  0.9609375 test_cost:  1489.6394 test_acc:  0.9453125\n",
            "iter:  473 train_cost:  736.23145 train_acc:  0.9609375 test_cost:  2620.3667 test_acc:  0.9296875\n",
            "iter:  474 train_cost:  1322.2556 train_acc:  0.984375 test_cost:  1210.3606 test_acc:  0.96875\n",
            "iter:  475 train_cost:  1210.273 train_acc:  0.9609375 test_cost:  523.22876 test_acc:  0.9453125\n",
            "iter:  476 train_cost:  820.7772 train_acc:  0.953125 test_cost:  3205.525 test_acc:  0.9453125\n",
            "iter:  477 train_cost:  545.2887 train_acc:  0.96875 test_cost:  1475.3696 test_acc:  0.9453125\n",
            "iter:  478 train_cost:  222.81757 train_acc:  0.984375 test_cost:  936.84564 test_acc:  0.953125\n",
            "iter:  479 train_cost:  1553.0247 train_acc:  0.9453125 test_cost:  882.0738 test_acc:  0.9453125\n",
            "iter:  480 train_cost:  534.0464 train_acc:  0.9609375 test_cost:  3882.9526 test_acc:  0.90625\n",
            "iter:  481 train_cost:  1137.0474 train_acc:  0.9609375 test_cost:  422.97842 test_acc:  0.9765625\n",
            "iter:  482 train_cost:  176.40765 train_acc:  0.9765625 test_cost:  1874.1995 test_acc:  0.953125\n",
            "iter:  483 train_cost:  483.20477 train_acc:  0.9296875 test_cost:  1204.374 test_acc:  0.953125\n",
            "iter:  484 train_cost:  1936.0712 train_acc:  0.9453125 test_cost:  219.48727 test_acc:  0.9765625\n",
            "iter:  485 train_cost:  530.10944 train_acc:  0.96875 test_cost:  1295.755 test_acc:  0.9296875\n",
            "iter:  486 train_cost:  1355.0177 train_acc:  0.9609375 test_cost:  1483.1442 test_acc:  0.9453125\n",
            "iter:  487 train_cost:  2201.6597 train_acc:  0.921875 test_cost:  1017.1013 test_acc:  0.96875\n",
            "iter:  488 train_cost:  1269.5511 train_acc:  0.953125 test_cost:  2186.1033 test_acc:  0.9375\n",
            "iter:  489 train_cost:  1533.9033 train_acc:  0.96875 test_cost:  1631.2875 test_acc:  0.953125\n",
            "iter:  490 train_cost:  12.268799 train_acc:  0.9765625 test_cost:  879.48883 test_acc:  0.9765625\n",
            "iter:  491 train_cost:  629.0778 train_acc:  0.9375 test_cost:  1625.9683 test_acc:  0.9453125\n",
            "iter:  492 train_cost:  1186.5238 train_acc:  0.9453125 test_cost:  2509.4033 test_acc:  0.9375\n",
            "iter:  493 train_cost:  710.56116 train_acc:  0.9609375 test_cost:  1115.3738 test_acc:  0.9453125\n",
            "iter:  494 train_cost:  624.0297 train_acc:  0.984375 test_cost:  1774.6602 test_acc:  0.953125\n",
            "iter:  495 train_cost:  531.80707 train_acc:  0.953125 test_cost:  2430.159 test_acc:  0.921875\n",
            "iter:  496 train_cost:  1519.679 train_acc:  0.953125 test_cost:  2721.6567 test_acc:  0.9375\n",
            "iter:  497 train_cost:  491.6121 train_acc:  0.984375 test_cost:  1396.305 test_acc:  0.9453125\n",
            "iter:  498 train_cost:  1010.9292 train_acc:  0.96875 test_cost:  1979.1266 test_acc:  0.9765625\n",
            "iter:  499 train_cost:  1900.3179 train_acc:  0.953125 test_cost:  1186.7869 test_acc:  0.9609375\n",
            "iter:  500 train_cost:  1047.9497 train_acc:  0.96875 test_cost:  540.97534 test_acc:  0.9609375\n",
            "iter:  501 train_cost:  522.03094 train_acc:  0.9765625 test_cost:  2071.1519 test_acc:  0.953125\n",
            "iter:  502 train_cost:  914.0856 train_acc:  0.953125 test_cost:  1079.6309 test_acc:  0.96875\n",
            "iter:  503 train_cost:  929.8103 train_acc:  0.96875 test_cost:  696.9471 test_acc:  0.9453125\n",
            "iter:  504 train_cost:  389.13696 train_acc:  0.9765625 test_cost:  1116.6742 test_acc:  0.984375\n",
            "iter:  505 train_cost:  629.72046 train_acc:  0.9609375 test_cost:  743.92596 test_acc:  0.96875\n",
            "iter:  506 train_cost:  982.21643 train_acc:  0.984375 test_cost:  493.02832 test_acc:  0.984375\n",
            "iter:  507 train_cost:  201.51941 train_acc:  0.9921875 test_cost:  781.2756 test_acc:  0.9453125\n",
            "iter:  508 train_cost:  1147.2905 train_acc:  0.96875 test_cost:  1781.2285 test_acc:  0.9375\n",
            "iter:  509 train_cost:  493.80872 train_acc:  0.984375 test_cost:  2815.6992 test_acc:  0.921875\n",
            "iter:  510 train_cost:  874.7882 train_acc:  0.9453125 test_cost:  708.9614 test_acc:  0.9609375\n",
            "iter:  511 train_cost:  1372.0312 train_acc:  0.953125 test_cost:  1698.0198 test_acc:  0.9609375\n",
            "iter:  512 train_cost:  508.39795 train_acc:  0.96875 test_cost:  1737.5259 test_acc:  0.9375\n",
            "iter:  513 train_cost:  269.11014 train_acc:  0.96875 test_cost:  1840.0847 test_acc:  0.9453125\n",
            "iter:  514 train_cost:  228.72754 train_acc:  0.9921875 test_cost:  4203.2666 test_acc:  0.921875\n",
            "iter:  515 train_cost:  978.27057 train_acc:  0.9609375 test_cost:  2426.9548 test_acc:  0.9140625\n",
            "iter:  516 train_cost:  1683.8245 train_acc:  0.9296875 test_cost:  628.8823 test_acc:  0.9765625\n",
            "iter:  517 train_cost:  1339.8503 train_acc:  0.9609375 test_cost:  2753.4485 test_acc:  0.9609375\n",
            "iter:  518 train_cost:  1306.4497 train_acc:  0.96875 test_cost:  1487.4963 test_acc:  0.9296875\n",
            "iter:  519 train_cost:  1397.6011 train_acc:  0.953125 test_cost:  1309.9438 test_acc:  0.96875\n",
            "iter:  520 train_cost:  3073.293 train_acc:  0.9453125 test_cost:  1115.9292 test_acc:  0.9375\n",
            "iter:  521 train_cost:  2444.0571 train_acc:  0.9375 test_cost:  3391.179 test_acc:  0.90625\n",
            "iter:  522 train_cost:  960.78864 train_acc:  0.953125 test_cost:  1642.6327 test_acc:  0.96875\n",
            "iter:  523 train_cost:  221.59094 train_acc:  0.9609375 test_cost:  1203.5863 test_acc:  0.984375\n",
            "iter:  524 train_cost:  1658.7423 train_acc:  0.9609375 test_cost:  394.24646 test_acc:  0.984375\n",
            "iter:  525 train_cost:  154.36273 train_acc:  0.984375 test_cost:  2886.5586 test_acc:  0.9296875\n",
            "iter:  526 train_cost:  182.73712 train_acc:  0.984375 test_cost:  258.54666 test_acc:  0.9765625\n",
            "iter:  527 train_cost:  135.05914 train_acc:  0.96875 test_cost:  2334.9856 test_acc:  0.9453125\n",
            "iter:  528 train_cost:  803.942 train_acc:  0.96875 test_cost:  1827.3241 test_acc:  0.9453125\n",
            "iter:  529 train_cost:  1209.389 train_acc:  0.96875 test_cost:  1090.7073 test_acc:  0.953125\n",
            "iter:  530 train_cost:  1629.7106 train_acc:  0.953125 test_cost:  1509.9133 test_acc:  0.9296875\n",
            "iter:  531 train_cost:  1321.2368 train_acc:  0.96875 test_cost:  1810.783 test_acc:  0.953125\n",
            "iter:  532 train_cost:  416.7962 train_acc:  0.984375 test_cost:  1920.0719 test_acc:  0.9453125\n",
            "iter:  533 train_cost:  740.1924 train_acc:  0.96875 test_cost:  1153.7115 test_acc:  0.9453125\n",
            "iter:  534 train_cost:  1942.0986 train_acc:  0.9375 test_cost:  1089.8203 test_acc:  0.953125\n",
            "iter:  535 train_cost:  1051.0332 train_acc:  0.9765625 test_cost:  225.14474 test_acc:  0.984375\n",
            "iter:  536 train_cost:  1402.7808 train_acc:  0.9453125 test_cost:  849.5806 test_acc:  0.9765625\n",
            "iter:  537 train_cost:  1490.0676 train_acc:  0.953125 test_cost:  597.1989 test_acc:  0.96875\n",
            "iter:  538 train_cost:  1146.6702 train_acc:  0.9609375 test_cost:  2251.1565 test_acc:  0.9375\n",
            "iter:  539 train_cost:  366.20886 train_acc:  0.9765625 test_cost:  493.85437 test_acc:  0.9765625\n",
            "iter:  540 train_cost:  211.18005 train_acc:  0.984375 test_cost:  1707.6433 test_acc:  0.953125\n",
            "iter:  541 train_cost:  905.9511 train_acc:  0.984375 test_cost:  2318.942 test_acc:  0.921875\n",
            "iter:  542 train_cost:  695.49994 train_acc:  0.9609375 test_cost:  1446.8499 test_acc:  0.96875\n",
            "iter:  543 train_cost:  1171.4624 train_acc:  0.9375 test_cost:  55.61682 test_acc:  0.984375\n",
            "iter:  544 train_cost:  273.69232 train_acc:  0.984375 test_cost:  2413.1855 test_acc:  0.9375\n",
            "iter:  545 train_cost:  1455.9897 train_acc:  0.9453125 test_cost:  3757.0696 test_acc:  0.953125\n",
            "iter:  546 train_cost:  1742.564 train_acc:  0.9453125 test_cost:  4626.1934 test_acc:  0.921875\n",
            "iter:  547 train_cost:  553.5259 train_acc:  0.96875 test_cost:  1635.3785 test_acc:  0.9453125\n",
            "iter:  548 train_cost:  1481.7588 train_acc:  0.9453125 test_cost:  2031.4606 test_acc:  0.953125\n",
            "iter:  549 train_cost:  1568.2769 train_acc:  0.96875 test_cost:  414.14825 test_acc:  0.984375\n",
            "iter:  550 train_cost:  943.12354 train_acc:  0.9453125 test_cost:  2500.7622 test_acc:  0.96875\n",
            "iter:  551 train_cost:  571.8302 train_acc:  0.9765625 test_cost:  140.057 test_acc:  0.9765625\n",
            "iter:  552 train_cost:  257.428 train_acc:  0.96875 test_cost:  714.98236 test_acc:  0.984375\n",
            "iter:  553 train_cost:  16.204285 train_acc:  0.984375 test_cost:  1218.3298 test_acc:  0.953125\n",
            "iter:  554 train_cost:  694.5011 train_acc:  0.96875 test_cost:  2735.7056 test_acc:  0.9609375\n",
            "iter:  555 train_cost:  1123.6097 train_acc:  0.9375 test_cost:  1465.7861 test_acc:  0.953125\n",
            "iter:  556 train_cost:  606.32764 train_acc:  0.984375 test_cost:  2216.7292 test_acc:  0.9453125\n",
            "iter:  557 train_cost:  1814.793 train_acc:  0.9453125 test_cost:  2241.101 test_acc:  0.953125\n",
            "iter:  558 train_cost:  139.61249 train_acc:  0.984375 test_cost:  2186.2007 test_acc:  0.921875\n",
            "iter:  559 train_cost:  1972.7137 train_acc:  0.9296875 test_cost:  2732.8567 test_acc:  0.953125\n",
            "iter:  560 train_cost:  164.60638 train_acc:  0.984375 test_cost:  946.17004 test_acc:  0.9921875\n",
            "iter:  561 train_cost:  1079.2169 train_acc:  0.9609375 test_cost:  2214.7495 test_acc:  0.9453125\n",
            "iter:  562 train_cost:  2047.437 train_acc:  0.953125 test_cost:  4621.262 test_acc:  0.90625\n",
            "iter:  563 train_cost:  308.34335 train_acc:  0.9921875 test_cost:  1506.4448 test_acc:  0.9453125\n",
            "iter:  564 train_cost:  1567.1995 train_acc:  0.953125 test_cost:  1352.1165 test_acc:  0.9453125\n",
            "iter:  565 train_cost:  454.48102 train_acc:  0.9765625 test_cost:  1904.218 test_acc:  0.9453125\n",
            "iter:  566 train_cost:  1297.7916 train_acc:  0.9609375 test_cost:  1434.94 test_acc:  0.9609375\n",
            "iter:  567 train_cost:  136.52466 train_acc:  0.9765625 test_cost:  1975.806 test_acc:  0.921875\n",
            "iter:  568 train_cost:  1151.4543 train_acc:  0.9453125 test_cost:  404.10736 test_acc:  0.9609375\n",
            "iter:  569 train_cost:  1644.5565 train_acc:  0.96875 test_cost:  2408.0405 test_acc:  0.96875\n",
            "iter:  570 train_cost:  354.65738 train_acc:  0.984375 test_cost:  1329.3756 test_acc:  0.9296875\n",
            "iter:  571 train_cost:  163.13025 train_acc:  0.96875 test_cost:  3293.671 test_acc:  0.921875\n",
            "iter:  572 train_cost:  37.021484 train_acc:  0.984375 test_cost:  1699.3486 test_acc:  0.9453125\n",
            "iter:  573 train_cost:  1390.9404 train_acc:  0.96875 test_cost:  1655.6753 test_acc:  0.9453125\n",
            "iter:  574 train_cost:  1649.4465 train_acc:  0.9609375 test_cost:  1925.2236 test_acc:  0.9609375\n",
            "iter:  575 train_cost:  1041.8849 train_acc:  0.953125 test_cost:  1461.8954 test_acc:  0.9609375\n",
            "iter:  576 train_cost:  644.5373 train_acc:  0.96875 test_cost:  1350.8785 test_acc:  0.953125\n",
            "iter:  577 train_cost:  255.51575 train_acc:  0.96875 test_cost:  470.9102 test_acc:  0.96875\n",
            "iter:  578 train_cost:  68.959656 train_acc:  0.984375 test_cost:  1051.1372 test_acc:  0.9453125\n",
            "iter:  579 train_cost:  1393.79 train_acc:  0.9453125 test_cost:  1477.4705 test_acc:  0.96875\n",
            "iter:  580 train_cost:  839.03107 train_acc:  0.96875 test_cost:  2221.8586 test_acc:  0.9375\n",
            "iter:  581 train_cost:  3978.9072 train_acc:  0.9453125 test_cost:  563.0983 test_acc:  0.953125\n",
            "iter:  582 train_cost:  51.59491 train_acc:  0.984375 test_cost:  1215.4736 test_acc:  0.9296875\n",
            "iter:  583 train_cost:  783.1118 train_acc:  0.96875 test_cost:  957.5791 test_acc:  0.96875\n",
            "iter:  584 train_cost:  37.55432 train_acc:  0.9921875 test_cost:  2040.2965 test_acc:  0.9609375\n",
            "iter:  585 train_cost:  1845.7914 train_acc:  0.96875 test_cost:  397.9839 test_acc:  0.9765625\n",
            "iter:  586 train_cost:  786.9412 train_acc:  0.9765625 test_cost:  1244.162 test_acc:  0.953125\n",
            "iter:  587 train_cost:  270.26715 train_acc:  0.9765625 test_cost:  1548.6973 test_acc:  0.984375\n",
            "iter:  588 train_cost:  496.28534 train_acc:  0.984375 test_cost:  1332.2064 test_acc:  0.9765625\n",
            "iter:  589 train_cost:  573.5591 train_acc:  0.9765625 test_cost:  1757.8281 test_acc:  0.96875\n",
            "iter:  590 train_cost:  952.6253 train_acc:  0.9765625 test_cost:  2240.9185 test_acc:  0.953125\n",
            "iter:  591 train_cost:  1264.2683 train_acc:  0.9453125 test_cost:  832.9268 test_acc:  0.953125\n",
            "iter:  592 train_cost:  603.68225 train_acc:  0.984375 test_cost:  536.11035 test_acc:  0.984375\n",
            "iter:  593 train_cost:  382.57965 train_acc:  0.9609375 test_cost:  1044.2327 test_acc:  0.9375\n",
            "iter:  594 train_cost:  739.44653 train_acc:  0.9765625 test_cost:  1731.9956 test_acc:  0.953125\n",
            "iter:  595 train_cost:  1960.513 train_acc:  0.9609375 test_cost:  2089.4456 test_acc:  0.953125\n",
            "iter:  596 train_cost:  1044.8119 train_acc:  0.96875 test_cost:  1603.0845 test_acc:  0.9609375\n",
            "iter:  597 train_cost:  19.47821 train_acc:  0.984375 test_cost:  358.2096 test_acc:  0.9921875\n",
            "iter:  598 train_cost:  964.37836 train_acc:  0.9609375 test_cost:  867.67664 test_acc:  0.9609375\n",
            "iter:  599 train_cost:  1515.3579 train_acc:  0.9453125 test_cost:  1374.1892 test_acc:  0.9296875\n",
            "iter:  600 train_cost:  1325.0828 train_acc:  0.96875 test_cost:  3890.4453 test_acc:  0.9453125\n",
            "iter:  601 train_cost:  686.4944 train_acc:  0.9765625 test_cost:  714.60315 test_acc:  0.953125\n",
            "iter:  602 train_cost:  444.57346 train_acc:  0.984375 test_cost:  460.47574 test_acc:  0.9765625\n",
            "iter:  603 train_cost:  542.1483 train_acc:  0.96875 test_cost:  4135.787 test_acc:  0.921875\n",
            "iter:  604 train_cost:  1446.1904 train_acc:  0.953125 test_cost:  1199.2549 test_acc:  0.9765625\n",
            "iter:  605 train_cost:  237.91211 train_acc:  0.984375 test_cost:  2266.4897 test_acc:  0.9453125\n",
            "iter:  606 train_cost:  117.10535 train_acc:  0.9921875 test_cost:  0.0 test_acc:  1.0\n",
            "iter:  607 train_cost:  923.3845 train_acc:  0.953125 test_cost:  1213.1581 test_acc:  0.9609375\n",
            "iter:  608 train_cost:  1674.5789 train_acc:  0.9765625 test_cost:  1726.0197 test_acc:  0.953125\n",
            "iter:  609 train_cost:  1821.4215 train_acc:  0.953125 test_cost:  2171.8242 test_acc:  0.9453125\n",
            "iter:  610 train_cost:  570.51746 train_acc:  0.9765625 test_cost:  944.3075 test_acc:  0.96875\n",
            "iter:  611 train_cost:  1912.3362 train_acc:  0.953125 test_cost:  652.314 test_acc:  0.9609375\n",
            "iter:  612 train_cost:  479.0247 train_acc:  0.9765625 test_cost:  2004.7058 test_acc:  0.9453125\n",
            "iter:  613 train_cost:  705.8584 train_acc:  0.9609375 test_cost:  707.7799 test_acc:  0.96875\n",
            "iter:  614 train_cost:  567.88763 train_acc:  0.953125 test_cost:  1110.6741 test_acc:  0.9296875\n",
            "iter:  615 train_cost:  586.20197 train_acc:  0.9453125 test_cost:  1489.964 test_acc:  0.9609375\n",
            "iter:  616 train_cost:  1489.5833 train_acc:  0.9453125 test_cost:  2205.8396 test_acc:  0.9609375\n",
            "iter:  617 train_cost:  1073.7361 train_acc:  0.984375 test_cost:  526.9978 test_acc:  0.984375\n",
            "iter:  618 train_cost:  1351.7753 train_acc:  0.9453125 test_cost:  2010.9098 test_acc:  0.9609375\n",
            "iter:  619 train_cost:  552.6502 train_acc:  0.9765625 test_cost:  1884.8994 test_acc:  0.9296875\n",
            "iter:  620 train_cost:  1492.6698 train_acc:  0.921875 test_cost:  1238.7747 test_acc:  0.953125\n",
            "iter:  621 train_cost:  264.22202 train_acc:  0.96875 test_cost:  1091.2252 test_acc:  0.9375\n",
            "iter:  622 train_cost:  702.85895 train_acc:  0.9453125 test_cost:  903.526 test_acc:  0.96875\n",
            "iter:  623 train_cost:  911.81995 train_acc:  0.96875 test_cost:  2416.9558 test_acc:  0.921875\n",
            "iter:  624 train_cost:  424.65903 train_acc:  0.96875 test_cost:  1228.7065 test_acc:  0.953125\n",
            "iter:  625 train_cost:  1998.3081 train_acc:  0.9296875 test_cost:  3298.1584 test_acc:  0.9296875\n",
            "iter:  626 train_cost:  1121.9746 train_acc:  0.9609375 test_cost:  957.68414 test_acc:  0.9609375\n",
            "iter:  627 train_cost:  505.1547 train_acc:  0.96875 test_cost:  1935.8237 test_acc:  0.9453125\n",
            "iter:  628 train_cost:  874.54175 train_acc:  0.96875 test_cost:  809.84125 test_acc:  0.953125\n",
            "iter:  629 train_cost:  836.8097 train_acc:  0.9765625 test_cost:  2058.6375 test_acc:  0.9375\n",
            "iter:  630 train_cost:  1294.6393 train_acc:  0.9765625 test_cost:  1193.053 test_acc:  0.9375\n",
            "iter:  631 train_cost:  821.64703 train_acc:  0.9765625 test_cost:  1043.139 test_acc:  0.96875\n",
            "iter:  632 train_cost:  308.46667 train_acc:  0.9765625 test_cost:  747.8231 test_acc:  0.96875\n",
            "iter:  633 train_cost:  429.32056 train_acc:  0.9765625 test_cost:  344.34308 test_acc:  0.96875\n",
            "iter:  634 train_cost:  2043.4741 train_acc:  0.9453125 test_cost:  1682.7568 test_acc:  0.9453125\n",
            "iter:  635 train_cost:  1681.2698 train_acc:  0.953125 test_cost:  2152.4224 test_acc:  0.9609375\n",
            "iter:  636 train_cost:  338.42413 train_acc:  0.984375 test_cost:  737.48816 test_acc:  0.9609375\n",
            "iter:  637 train_cost:  433.1042 train_acc:  0.9765625 test_cost:  2022.7491 test_acc:  0.9296875\n",
            "iter:  638 train_cost:  385.70392 train_acc:  0.9765625 test_cost:  535.694 test_acc:  0.9453125\n",
            "iter:  639 train_cost:  1080.9407 train_acc:  0.9609375 test_cost:  947.9613 test_acc:  0.9765625\n",
            "iter:  640 train_cost:  9.570129 train_acc:  0.9921875 test_cost:  1002.59644 test_acc:  0.9453125\n",
            "iter:  641 train_cost:  573.78986 train_acc:  0.984375 test_cost:  431.2125 test_acc:  0.96875\n",
            "iter:  642 train_cost:  711.6263 train_acc:  0.9609375 test_cost:  3226.286 test_acc:  0.9296875\n",
            "iter:  643 train_cost:  238.1101 train_acc:  0.9765625 test_cost:  1818.6598 test_acc:  0.9375\n",
            "iter:  644 train_cost:  423.98215 train_acc:  0.9765625 test_cost:  393.92307 test_acc:  0.96875\n",
            "iter:  645 train_cost:  993.4376 train_acc:  0.9609375 test_cost:  1514.1653 test_acc:  0.9453125\n",
            "iter:  646 train_cost:  297.4851 train_acc:  0.9765625 test_cost:  1145.3306 test_acc:  0.9609375\n",
            "iter:  647 train_cost:  272.90475 train_acc:  0.96875 test_cost:  913.3579 test_acc:  0.96875\n",
            "iter:  648 train_cost:  717.73083 train_acc:  0.96875 test_cost:  1832.9294 test_acc:  0.9453125\n",
            "iter:  649 train_cost:  756.97375 train_acc:  0.953125 test_cost:  1125.8004 test_acc:  0.9453125\n",
            "iter:  650 train_cost:  564.4654 train_acc:  0.9609375 test_cost:  94.85016 test_acc:  0.984375\n",
            "iter:  651 train_cost:  996.59375 train_acc:  0.9765625 test_cost:  1009.4944 test_acc:  0.9609375\n",
            "iter:  652 train_cost:  997.341 train_acc:  0.96875 test_cost:  427.9885 test_acc:  0.9765625\n",
            "iter:  653 train_cost:  1702.7853 train_acc:  0.9296875 test_cost:  2235.0996 test_acc:  0.9453125\n",
            "iter:  654 train_cost:  602.1463 train_acc:  0.9765625 test_cost:  384.05267 test_acc:  0.953125\n",
            "iter:  655 train_cost:  1991.9647 train_acc:  0.9609375 test_cost:  261.9777 test_acc:  0.984375\n",
            "iter:  656 train_cost:  466.1667 train_acc:  0.96875 test_cost:  1257.2518 test_acc:  0.9765625\n",
            "iter:  657 train_cost:  933.457 train_acc:  0.9765625 test_cost:  2017.1635 test_acc:  0.9140625\n",
            "iter:  658 train_cost:  646.34143 train_acc:  0.953125 test_cost:  2528.8088 test_acc:  0.9453125\n",
            "iter:  659 train_cost:  482.10626 train_acc:  0.9609375 test_cost:  1260.6346 test_acc:  0.9609375\n",
            "iter:  660 train_cost:  169.09589 train_acc:  0.984375 test_cost:  2766.3704 test_acc:  0.953125\n",
            "iter:  661 train_cost:  354.17032 train_acc:  0.9765625 test_cost:  561.8841 test_acc:  0.953125\n",
            "iter:  662 train_cost:  1126.4021 train_acc:  0.9765625 test_cost:  251.24585 test_acc:  0.9765625\n",
            "iter:  663 train_cost:  726.4663 train_acc:  0.9609375 test_cost:  410.0353 test_acc:  0.953125\n",
            "iter:  664 train_cost:  242.46631 train_acc:  0.984375 test_cost:  834.83203 test_acc:  0.96875\n",
            "iter:  665 train_cost:  902.9973 train_acc:  0.9765625 test_cost:  570.0316 test_acc:  0.96875\n",
            "iter:  666 train_cost:  740.7562 train_acc:  0.984375 test_cost:  1293.7236 test_acc:  0.96875\n",
            "iter:  667 train_cost:  1510.0167 train_acc:  0.984375 test_cost:  881.65796 test_acc:  0.984375\n",
            "iter:  668 train_cost:  74.29431 train_acc:  0.9921875 test_cost:  85.85132 test_acc:  0.9765625\n",
            "iter:  669 train_cost:  1535.0585 train_acc:  0.96875 test_cost:  1486.9653 test_acc:  0.9453125\n",
            "iter:  670 train_cost:  914.17566 train_acc:  0.953125 test_cost:  3892.503 test_acc:  0.921875\n",
            "iter:  671 train_cost:  523.352 train_acc:  0.953125 test_cost:  2443.4377 test_acc:  0.9296875\n",
            "iter:  672 train_cost:  219.47107 train_acc:  0.984375 test_cost:  2105.3374 test_acc:  0.953125\n",
            "iter:  673 train_cost:  737.4532 train_acc:  0.984375 test_cost:  2323.6313 test_acc:  0.9609375\n",
            "iter:  674 train_cost:  1918.9429 train_acc:  0.9453125 test_cost:  721.0236 test_acc:  0.953125\n",
            "iter:  675 train_cost:  432.8945 train_acc:  0.96875 test_cost:  580.0436 test_acc:  0.9609375\n",
            "iter:  676 train_cost:  309.9422 train_acc:  0.9765625 test_cost:  181.20123 test_acc:  0.9921875\n",
            "iter:  677 train_cost:  1599.1208 train_acc:  0.9609375 test_cost:  1821.2561 test_acc:  0.9296875\n",
            "iter:  678 train_cost:  1713.6035 train_acc:  0.953125 test_cost:  1800.0361 test_acc:  0.953125\n",
            "iter:  679 train_cost:  2156.4666 train_acc:  0.9375 test_cost:  497.23383 test_acc:  0.9765625\n",
            "iter:  680 train_cost:  924.13 train_acc:  0.9609375 test_cost:  1241.3105 test_acc:  0.953125\n",
            "iter:  681 train_cost:  483.91895 train_acc:  0.984375 test_cost:  473.093 test_acc:  0.9609375\n",
            "iter:  682 train_cost:  864.5392 train_acc:  0.96875 test_cost:  1229.6909 test_acc:  0.953125\n",
            "iter:  683 train_cost:  1561.7605 train_acc:  0.9609375 test_cost:  1341.2449 test_acc:  0.9609375\n",
            "iter:  684 train_cost:  1604.3522 train_acc:  0.953125 test_cost:  1477.8774 test_acc:  0.953125\n",
            "iter:  685 train_cost:  1383.6155 train_acc:  0.9609375 test_cost:  1654.5054 test_acc:  0.96875\n",
            "iter:  686 train_cost:  587.978 train_acc:  0.984375 test_cost:  184.9472 test_acc:  0.984375\n",
            "iter:  687 train_cost:  1149.3599 train_acc:  0.9453125 test_cost:  3085.9512 test_acc:  0.921875\n",
            "iter:  688 train_cost:  1145.9177 train_acc:  0.96875 test_cost:  1717.7728 test_acc:  0.9609375\n",
            "iter:  689 train_cost:  209.98572 train_acc:  0.9921875 test_cost:  1175.7356 test_acc:  0.9765625\n",
            "iter:  690 train_cost:  437.21478 train_acc:  0.9609375 test_cost:  5279.9463 test_acc:  0.9140625\n",
            "iter:  691 train_cost:  540.6035 train_acc:  0.9765625 test_cost:  428.0918 test_acc:  0.9765625\n",
            "iter:  692 train_cost:  254.47836 train_acc:  0.96875 test_cost:  1785.0925 test_acc:  0.9453125\n",
            "iter:  693 train_cost:  4.684326 train_acc:  0.9921875 test_cost:  520.41595 test_acc:  0.9609375\n",
            "iter:  694 train_cost:  189.64374 train_acc:  0.9921875 test_cost:  1612.2307 test_acc:  0.953125\n",
            "iter:  695 train_cost:  1653.3508 train_acc:  0.9609375 test_cost:  337.00494 test_acc:  0.984375\n",
            "iter:  696 train_cost:  603.5448 train_acc:  0.9765625 test_cost:  459.93082 test_acc:  0.9609375\n",
            "iter:  697 train_cost:  1164.6958 train_acc:  0.953125 test_cost:  535.8675 test_acc:  0.9765625\n",
            "iter:  698 train_cost:  817.79736 train_acc:  0.9609375 test_cost:  770.8168 test_acc:  0.9765625\n",
            "iter:  699 train_cost:  249.19476 train_acc:  0.984375 test_cost:  1075.411 test_acc:  0.953125\n",
            "iter:  700 train_cost:  1171.9185 train_acc:  0.96875 test_cost:  744.3728 test_acc:  0.9609375\n",
            "iter:  701 train_cost:  729.35986 train_acc:  0.9453125 test_cost:  1517.1187 test_acc:  0.96875\n",
            "iter:  702 train_cost:  1516.5996 train_acc:  0.96875 test_cost:  594.5782 test_acc:  0.96875\n",
            "iter:  703 train_cost:  1995.7405 train_acc:  0.9375 test_cost:  754.95605 test_acc:  0.96875\n",
            "iter:  704 train_cost:  626.12885 train_acc:  0.9765625 test_cost:  1380.9978 test_acc:  0.953125\n",
            "iter:  705 train_cost:  885.8627 train_acc:  0.96875 test_cost:  2455.2537 test_acc:  0.9609375\n",
            "iter:  706 train_cost:  656.9845 train_acc:  0.984375 test_cost:  924.89264 test_acc:  0.953125\n",
            "iter:  707 train_cost:  667.85504 train_acc:  0.9765625 test_cost:  1659.9056 test_acc:  0.96875\n",
            "iter:  708 train_cost:  798.1179 train_acc:  0.9765625 test_cost:  2486.8848 test_acc:  0.9453125\n",
            "iter:  709 train_cost:  507.66916 train_acc:  0.9609375 test_cost:  916.3303 test_acc:  0.984375\n",
            "iter:  710 train_cost:  51.227356 train_acc:  0.9921875 test_cost:  987.824 test_acc:  0.90625\n",
            "iter:  711 train_cost:  981.2356 train_acc:  0.9765625 test_cost:  1996.3872 test_acc:  0.9609375\n",
            "iter:  712 train_cost:  857.9573 train_acc:  0.953125 test_cost:  1721.2201 test_acc:  0.921875\n",
            "iter:  713 train_cost:  603.6022 train_acc:  0.96875 test_cost:  1187.1594 test_acc:  0.9609375\n",
            "iter:  714 train_cost:  819.8065 train_acc:  0.9765625 test_cost:  1979.5623 test_acc:  0.96875\n",
            "iter:  715 train_cost:  150.53326 train_acc:  0.96875 test_cost:  1976.9478 test_acc:  0.9375\n",
            "iter:  716 train_cost:  1341.0781 train_acc:  0.9609375 test_cost:  453.28033 test_acc:  0.9765625\n",
            "iter:  717 train_cost:  193.24536 train_acc:  0.984375 test_cost:  430.7157 test_acc:  0.953125\n",
            "iter:  718 train_cost:  1411.1447 train_acc:  0.9453125 test_cost:  3313.8064 test_acc:  0.9375\n",
            "iter:  719 train_cost:  367.2651 train_acc:  0.984375 test_cost:  842.84973 test_acc:  0.953125\n",
            "iter:  720 train_cost:  1001.7719 train_acc:  0.96875 test_cost:  1613.727 test_acc:  0.9609375\n",
            "iter:  721 train_cost:  855.65906 train_acc:  0.96875 test_cost:  2522.19 test_acc:  0.9375\n",
            "iter:  722 train_cost:  877.1509 train_acc:  0.96875 test_cost:  1276.628 test_acc:  0.9296875\n",
            "iter:  723 train_cost:  837.5832 train_acc:  0.9375 test_cost:  2189.1316 test_acc:  0.9375\n",
            "iter:  724 train_cost:  278.26 train_acc:  0.9765625 test_cost:  2928.4658 test_acc:  0.9375\n",
            "iter:  725 train_cost:  2066.5967 train_acc:  0.96875 test_cost:  1489.2595 test_acc:  0.9453125\n",
            "iter:  726 train_cost:  1615.3594 train_acc:  0.9453125 test_cost:  1277.5676 test_acc:  0.9453125\n",
            "iter:  727 train_cost:  709.70935 train_acc:  0.9765625 test_cost:  959.7035 test_acc:  0.9609375\n",
            "iter:  728 train_cost:  382.6632 train_acc:  0.9609375 test_cost:  1538.3337 test_acc:  0.9375\n",
            "iter:  729 train_cost:  1871.7922 train_acc:  0.9375 test_cost:  2357.3936 test_acc:  0.9375\n",
            "iter:  730 train_cost:  896.04126 train_acc:  0.953125 test_cost:  1231.2747 test_acc:  0.9296875\n",
            "iter:  731 train_cost:  626.2307 train_acc:  0.9765625 test_cost:  673.503 test_acc:  0.984375\n",
            "iter:  732 train_cost:  359.11954 train_acc:  0.96875 test_cost:  1011.0305 test_acc:  0.953125\n",
            "iter:  733 train_cost:  735.6406 train_acc:  0.9609375 test_cost:  913.5531 test_acc:  0.953125\n",
            "iter:  734 train_cost:  2401.874 train_acc:  0.953125 test_cost:  3813.0308 test_acc:  0.8984375\n",
            "iter:  735 train_cost:  552.16614 train_acc:  0.96875 test_cost:  1195.6567 test_acc:  0.96875\n",
            "iter:  736 train_cost:  685.6669 train_acc:  0.9453125 test_cost:  534.97375 test_acc:  0.9765625\n",
            "iter:  737 train_cost:  876.2532 train_acc:  0.96875 test_cost:  1357.3949 test_acc:  0.953125\n",
            "iter:  738 train_cost:  1570.8898 train_acc:  0.9765625 test_cost:  1224.1382 test_acc:  0.96875\n",
            "iter:  739 train_cost:  2148.4692 train_acc:  0.9453125 test_cost:  564.6807 test_acc:  0.9609375\n",
            "iter:  740 train_cost:  1176.7886 train_acc:  0.9375 test_cost:  1508.4832 test_acc:  0.9296875\n",
            "iter:  741 train_cost:  1140.571 train_acc:  0.953125 test_cost:  1496.8398 test_acc:  0.9296875\n",
            "iter:  742 train_cost:  1733.0759 train_acc:  0.9609375 test_cost:  882.8955 test_acc:  0.96875\n",
            "iter:  743 train_cost:  767.4149 train_acc:  0.9609375 test_cost:  2397.956 test_acc:  0.953125\n",
            "iter:  744 train_cost:  692.26575 train_acc:  0.9765625 test_cost:  1167.3229 test_acc:  0.953125\n",
            "iter:  745 train_cost:  191.38953 train_acc:  0.96875 test_cost:  503.8063 test_acc:  0.9765625\n",
            "iter:  746 train_cost:  228.60315 train_acc:  0.9921875 test_cost:  1452.3613 test_acc:  0.9765625\n",
            "iter:  747 train_cost:  1390.857 train_acc:  0.96875 test_cost:  1348.5586 test_acc:  0.9765625\n",
            "iter:  748 train_cost:  1087.5471 train_acc:  0.953125 test_cost:  984.38116 test_acc:  0.9609375\n",
            "iter:  749 train_cost:  548.38556 train_acc:  0.96875 test_cost:  1556.8473 test_acc:  0.9375\n",
            "iter:  750 train_cost:  1800.6665 train_acc:  0.9375 test_cost:  1161.5984 test_acc:  0.9375\n",
            "iter:  751 train_cost:  1221.5667 train_acc:  0.9609375 test_cost:  2168.649 test_acc:  0.9375\n",
            "iter:  752 train_cost:  1312.8103 train_acc:  0.953125 test_cost:  925.7457 test_acc:  0.9609375\n",
            "iter:  753 train_cost:  1550.4163 train_acc:  0.9765625 test_cost:  935.702 test_acc:  0.9609375\n",
            "iter:  754 train_cost:  237.23889 train_acc:  0.9765625 test_cost:  1699.2761 test_acc:  0.9296875\n",
            "iter:  755 train_cost:  86.90741 train_acc:  0.984375 test_cost:  1641.3918 test_acc:  0.953125\n",
            "iter:  756 train_cost:  2669.4875 train_acc:  0.9765625 test_cost:  757.2251 test_acc:  0.9609375\n",
            "iter:  757 train_cost:  918.7 train_acc:  0.9453125 test_cost:  944.11 test_acc:  0.9765625\n",
            "iter:  758 train_cost:  433.8296 train_acc:  0.9765625 test_cost:  1396.2871 test_acc:  0.9453125\n",
            "iter:  759 train_cost:  52.99353 train_acc:  0.984375 test_cost:  517.8262 test_acc:  0.96875\n",
            "iter:  760 train_cost:  601.09717 train_acc:  0.96875 test_cost:  485.04984 test_acc:  0.984375\n",
            "iter:  761 train_cost:  285.2237 train_acc:  0.96875 test_cost:  1461.385 test_acc:  0.9453125\n",
            "iter:  762 train_cost:  1296.9895 train_acc:  0.9375 test_cost:  862.9835 test_acc:  0.953125\n",
            "iter:  763 train_cost:  494.44403 train_acc:  0.96875 test_cost:  192.35516 test_acc:  0.9921875\n",
            "iter:  764 train_cost:  556.92834 train_acc:  0.96875 test_cost:  2715.2927 test_acc:  0.9609375\n",
            "iter:  765 train_cost:  560.23676 train_acc:  0.96875 test_cost:  2175.1016 test_acc:  0.9765625\n",
            "iter:  766 train_cost:  826.4722 train_acc:  0.9609375 test_cost:  873.91907 test_acc:  0.96875\n",
            "iter:  767 train_cost:  0.0 train_acc:  1.0 test_cost:  285.87543 test_acc:  0.9765625\n",
            "iter:  768 train_cost:  741.34045 train_acc:  0.96875 test_cost:  2452.6106 test_acc:  0.9453125\n",
            "iter:  769 train_cost:  120.70508 train_acc:  0.9921875 test_cost:  643.2785 test_acc:  0.984375\n",
            "iter:  770 train_cost:  369.8979 train_acc:  0.984375 test_cost:  460.24158 test_acc:  0.9609375\n",
            "iter:  771 train_cost:  143.13245 train_acc:  0.9921875 test_cost:  579.0227 test_acc:  0.96875\n",
            "iter:  772 train_cost:  1200.5381 train_acc:  0.96875 test_cost:  1203.1477 test_acc:  0.9609375\n",
            "iter:  773 train_cost:  127.402405 train_acc:  0.984375 test_cost:  720.5814 test_acc:  0.9609375\n",
            "iter:  774 train_cost:  394.89508 train_acc:  0.96875 test_cost:  73.08807 test_acc:  0.984375\n",
            "iter:  775 train_cost:  658.179 train_acc:  0.9609375 test_cost:  1712.6957 test_acc:  0.953125\n",
            "iter:  776 train_cost:  736.60034 train_acc:  0.9765625 test_cost:  588.2138 test_acc:  0.9609375\n",
            "iter:  777 train_cost:  428.78906 train_acc:  0.984375 test_cost:  1226.1707 test_acc:  0.953125\n",
            "iter:  778 train_cost:  475.39874 train_acc:  0.984375 test_cost:  965.59973 test_acc:  0.953125\n",
            "iter:  779 train_cost:  129.64856 train_acc:  0.984375 test_cost:  2091.0862 test_acc:  0.9453125\n",
            "iter:  780 train_cost:  976.9881 train_acc:  0.9609375 test_cost:  1644.7769 test_acc:  0.953125\n",
            "iter:  781 train_cost:  708.844 train_acc:  0.9609375 test_cost:  2226.3833 test_acc:  0.9453125\n",
            "iter:  782 train_cost:  717.76953 train_acc:  0.9609375 test_cost:  841.8883 test_acc:  0.96875\n",
            "iter:  783 train_cost:  777.9709 train_acc:  0.9609375 test_cost:  2160.0317 test_acc:  0.9453125\n",
            "iter:  784 train_cost:  699.66565 train_acc:  0.9765625 test_cost:  726.6273 test_acc:  0.9453125\n",
            "iter:  785 train_cost:  366.50296 train_acc:  0.9765625 test_cost:  1254.9568 test_acc:  0.9609375\n",
            "iter:  786 train_cost:  724.3249 train_acc:  0.984375 test_cost:  1196.2664 test_acc:  0.953125\n",
            "iter:  787 train_cost:  1038.322 train_acc:  0.9765625 test_cost:  1295.257 test_acc:  0.96875\n",
            "iter:  788 train_cost:  786.6594 train_acc:  0.96875 test_cost:  1078.9595 test_acc:  0.96875\n",
            "iter:  789 train_cost:  77.60867 train_acc:  0.9765625 test_cost:  0.0 test_acc:  1.0\n",
            "iter:  790 train_cost:  267.98846 train_acc:  0.984375 test_cost:  1043.6487 test_acc:  0.9765625\n",
            "iter:  791 train_cost:  873.07886 train_acc:  0.96875 test_cost:  82.96002 test_acc:  0.984375\n",
            "iter:  792 train_cost:  423.59076 train_acc:  0.96875 test_cost:  1856.8008 test_acc:  0.9375\n",
            "iter:  793 train_cost:  303.7655 train_acc:  0.984375 test_cost:  3979.626 test_acc:  0.921875\n",
            "iter:  794 train_cost:  506.54803 train_acc:  0.9609375 test_cost:  1415.7916 test_acc:  0.953125\n",
            "iter:  795 train_cost:  365.49982 train_acc:  0.984375 test_cost:  1978.6852 test_acc:  0.953125\n",
            "iter:  796 train_cost:  356.3274 train_acc:  0.9765625 test_cost:  2209.651 test_acc:  0.9296875\n",
            "iter:  797 train_cost:  1187.523 train_acc:  0.96875 test_cost:  397.6731 test_acc:  0.9765625\n",
            "iter:  798 train_cost:  844.1427 train_acc:  0.9765625 test_cost:  514.47003 test_acc:  0.9609375\n",
            "iter:  799 train_cost:  186.49896 train_acc:  0.984375 test_cost:  1355.5117 test_acc:  0.9609375\n",
            "iter:  800 train_cost:  280.83807 train_acc:  0.9921875 test_cost:  1589.7919 test_acc:  0.9609375\n",
            "iter:  801 train_cost:  31.290009 train_acc:  0.9921875 test_cost:  1927.4076 test_acc:  0.9453125\n",
            "iter:  802 train_cost:  1808.6691 train_acc:  0.9609375 test_cost:  2443.0537 test_acc:  0.9375\n",
            "iter:  803 train_cost:  1076.9009 train_acc:  0.9609375 test_cost:  1547.133 test_acc:  0.9296875\n",
            "iter:  804 train_cost:  294.83994 train_acc:  0.96875 test_cost:  1135.0443 test_acc:  0.9609375\n",
            "iter:  805 train_cost:  756.5633 train_acc:  0.953125 test_cost:  1717.148 test_acc:  0.9375\n",
            "iter:  806 train_cost:  994.16986 train_acc:  0.9453125 test_cost:  787.5461 test_acc:  0.9453125\n",
            "iter:  807 train_cost:  1399.664 train_acc:  0.9765625 test_cost:  565.187 test_acc:  0.9765625\n",
            "iter:  808 train_cost:  1687.9836 train_acc:  0.9375 test_cost:  1900.0908 test_acc:  0.9375\n",
            "iter:  809 train_cost:  296.71112 train_acc:  0.9765625 test_cost:  764.458 test_acc:  0.9765625\n",
            "iter:  810 train_cost:  92.721924 train_acc:  0.984375 test_cost:  1558.2102 test_acc:  0.9296875\n",
            "iter:  811 train_cost:  551.5232 train_acc:  0.984375 test_cost:  682.8766 test_acc:  0.9453125\n",
            "iter:  812 train_cost:  1383.0452 train_acc:  0.90625 test_cost:  1288.1238 test_acc:  0.9375\n",
            "iter:  813 train_cost:  607.75507 train_acc:  0.96875 test_cost:  389.97766 test_acc:  0.9609375\n",
            "iter:  814 train_cost:  1660.0173 train_acc:  0.9609375 test_cost:  2543.5396 test_acc:  0.9453125\n",
            "iter:  815 train_cost:  1149.7797 train_acc:  0.953125 test_cost:  2805.0986 test_acc:  0.9453125\n",
            "iter:  816 train_cost:  1988.0278 train_acc:  0.9609375 test_cost:  313.8401 test_acc:  0.9921875\n",
            "iter:  817 train_cost:  1382.8613 train_acc:  0.9609375 test_cost:  1380.2009 test_acc:  0.9375\n",
            "iter:  818 train_cost:  427.61578 train_acc:  0.9765625 test_cost:  627.8679 test_acc:  0.96875\n",
            "iter:  819 train_cost:  973.74207 train_acc:  0.96875 test_cost:  2258.36 test_acc:  0.9296875\n",
            "iter:  820 train_cost:  81.85376 train_acc:  0.9921875 test_cost:  690.4645 test_acc:  0.9609375\n",
            "iter:  821 train_cost:  849.90826 train_acc:  0.9453125 test_cost:  2041.1449 test_acc:  0.9296875\n",
            "iter:  822 train_cost:  544.41675 train_acc:  0.9453125 test_cost:  1274.025 test_acc:  0.953125\n",
            "iter:  823 train_cost:  352.52472 train_acc:  0.984375 test_cost:  853.74 test_acc:  0.9609375\n",
            "iter:  824 train_cost:  1166.7979 train_acc:  0.984375 test_cost:  81.99463 test_acc:  0.984375\n",
            "iter:  825 train_cost:  1398.7562 train_acc:  0.9609375 test_cost:  214.08911 test_acc:  0.984375\n",
            "iter:  826 train_cost:  1193.4869 train_acc:  0.9609375 test_cost:  0.7695923 test_acc:  0.984375\n",
            "iter:  827 train_cost:  96.4718 train_acc:  0.9921875 test_cost:  1143.7162 test_acc:  0.9609375\n",
            "iter:  828 train_cost:  241.23685 train_acc:  0.96875 test_cost:  950.36 test_acc:  0.9453125\n",
            "iter:  829 train_cost:  1222.6493 train_acc:  0.9375 test_cost:  2206.452 test_acc:  0.953125\n",
            "iter:  830 train_cost:  1929.9286 train_acc:  0.9453125 test_cost:  3231.728 test_acc:  0.9609375\n",
            "iter:  831 train_cost:  397.811 train_acc:  0.9609375 test_cost:  1303.6593 test_acc:  0.9375\n",
            "iter:  832 train_cost:  632.2454 train_acc:  0.96875 test_cost:  1793.6586 test_acc:  0.96875\n",
            "iter:  833 train_cost:  1066.1599 train_acc:  0.96875 test_cost:  1053.49 test_acc:  0.9765625\n",
            "iter:  834 train_cost:  49.85501 train_acc:  0.984375 test_cost:  1240.95 test_acc:  0.9375\n",
            "iter:  835 train_cost:  422.7251 train_acc:  0.96875 test_cost:  703.7296 test_acc:  0.9453125\n",
            "iter:  836 train_cost:  347.5264 train_acc:  0.984375 test_cost:  1589.44 test_acc:  0.9375\n",
            "iter:  837 train_cost:  211.4989 train_acc:  0.984375 test_cost:  643.17065 test_acc:  0.9765625\n",
            "iter:  838 train_cost:  824.7919 train_acc:  0.9609375 test_cost:  598.4532 test_acc:  0.9609375\n",
            "iter:  839 train_cost:  1870.4846 train_acc:  0.921875 test_cost:  1351.9607 test_acc:  0.9765625\n",
            "iter:  840 train_cost:  804.1106 train_acc:  0.9765625 test_cost:  639.2484 test_acc:  0.9609375\n",
            "iter:  841 train_cost:  559.5028 train_acc:  0.9765625 test_cost:  596.39685 test_acc:  0.96875\n",
            "iter:  842 train_cost:  1128.3997 train_acc:  0.9375 test_cost:  994.6906 test_acc:  0.9765625\n",
            "iter:  843 train_cost:  570.7295 train_acc:  0.9609375 test_cost:  1916.2925 test_acc:  0.9453125\n",
            "iter:  844 train_cost:  401.34006 train_acc:  0.9765625 test_cost:  2285.8232 test_acc:  0.953125\n",
            "iter:  845 train_cost:  976.37415 train_acc:  0.9765625 test_cost:  1250.3794 test_acc:  0.953125\n",
            "iter:  846 train_cost:  166.26276 train_acc:  0.9921875 test_cost:  464.10312 test_acc:  0.9765625\n",
            "iter:  847 train_cost:  887.091 train_acc:  0.9609375 test_cost:  1350.6313 test_acc:  0.96875\n",
            "iter:  848 train_cost:  333.06168 train_acc:  0.9765625 test_cost:  807.8487 test_acc:  0.96875\n",
            "iter:  849 train_cost:  1302.8202 train_acc:  0.9296875 test_cost:  1092.3474 test_acc:  0.9609375\n",
            "iter:  850 train_cost:  379.1373 train_acc:  0.984375 test_cost:  376.34607 test_acc:  0.984375\n",
            "iter:  851 train_cost:  1751.0635 train_acc:  0.96875 test_cost:  269.2002 test_acc:  0.953125\n",
            "iter:  852 train_cost:  802.28754 train_acc:  0.9765625 test_cost:  458.3932 test_acc:  0.9765625\n",
            "iter:  853 train_cost:  619.9824 train_acc:  0.96875 test_cost:  2097.4019 test_acc:  0.953125\n",
            "iter:  854 train_cost:  1235.4955 train_acc:  0.96875 test_cost:  1318.5994 test_acc:  0.9765625\n",
            "iter:  855 train_cost:  712.3292 train_acc:  0.9609375 test_cost:  1197.9167 test_acc:  0.953125\n",
            "iter:  856 train_cost:  428.7618 train_acc:  0.984375 test_cost:  595.15356 test_acc:  0.984375\n",
            "iter:  857 train_cost:  251.31616 train_acc:  0.984375 test_cost:  235.09387 test_acc:  0.984375\n",
            "iter:  858 train_cost:  508.27484 train_acc:  0.9609375 test_cost:  576.5623 test_acc:  0.984375\n",
            "iter:  859 train_cost:  710.60004 train_acc:  0.9609375 test_cost:  1000.9702 test_acc:  0.96875\n",
            "iter:  860 train_cost:  1470.9956 train_acc:  0.9609375 test_cost:  1956.0497 test_acc:  0.953125\n",
            "iter:  861 train_cost:  469.10565 train_acc:  0.9765625 test_cost:  1370.1736 test_acc:  0.9765625\n",
            "iter:  862 train_cost:  462.06342 train_acc:  0.9765625 test_cost:  943.25226 test_acc:  0.953125\n",
            "iter:  863 train_cost:  955.0901 train_acc:  0.9609375 test_cost:  1271.8804 test_acc:  0.9453125\n",
            "iter:  864 train_cost:  706.0824 train_acc:  0.96875 test_cost:  1974.0813 test_acc:  0.9453125\n",
            "iter:  865 train_cost:  1144.0151 train_acc:  0.9765625 test_cost:  799.6653 test_acc:  0.9765625\n",
            "iter:  866 train_cost:  41.8208 train_acc:  0.984375 test_cost:  496.95856 test_acc:  0.9453125\n",
            "iter:  867 train_cost:  657.70703 train_acc:  0.96875 test_cost:  697.93884 test_acc:  0.9453125\n",
            "iter:  868 train_cost:  849.16724 train_acc:  0.9375 test_cost:  1212.356 test_acc:  0.9453125\n",
            "iter:  869 train_cost:  747.46796 train_acc:  0.984375 test_cost:  1725.5652 test_acc:  0.9609375\n",
            "iter:  870 train_cost:  748.06555 train_acc:  0.9765625 test_cost:  1392.4539 test_acc:  0.953125\n",
            "iter:  871 train_cost:  203.76025 train_acc:  0.9921875 test_cost:  2400.5886 test_acc:  0.96875\n",
            "iter:  872 train_cost:  183.51917 train_acc:  0.984375 test_cost:  572.88025 test_acc:  0.96875\n",
            "iter:  873 train_cost:  42.182556 train_acc:  0.9921875 test_cost:  987.38556 test_acc:  0.953125\n",
            "iter:  874 train_cost:  620.25903 train_acc:  0.96875 test_cost:  1876.8516 test_acc:  0.9296875\n",
            "iter:  875 train_cost:  269.1786 train_acc:  0.984375 test_cost:  913.0082 test_acc:  0.953125\n",
            "iter:  876 train_cost:  185.03607 train_acc:  0.9765625 test_cost:  408.16275 test_acc:  0.9765625\n",
            "iter:  877 train_cost:  1458.979 train_acc:  0.9453125 test_cost:  1095.7087 test_acc:  0.96875\n",
            "iter:  878 train_cost:  588.3243 train_acc:  0.96875 test_cost:  552.2372 test_acc:  0.9765625\n",
            "iter:  879 train_cost:  1631.6201 train_acc:  0.984375 test_cost:  813.0924 test_acc:  0.9609375\n",
            "iter:  880 train_cost:  227.66156 train_acc:  0.9765625 test_cost:  1227.2804 test_acc:  0.953125\n",
            "iter:  881 train_cost:  189.18344 train_acc:  0.96875 test_cost:  1069.9492 test_acc:  0.96875\n",
            "iter:  882 train_cost:  285.86157 train_acc:  0.9765625 test_cost:  2522.7458 test_acc:  0.9375\n",
            "iter:  883 train_cost:  0.0 train_acc:  1.0 test_cost:  894.04626 test_acc:  0.9765625\n",
            "iter:  884 train_cost:  258.87732 train_acc:  0.9765625 test_cost:  555.71655 test_acc:  0.9609375\n",
            "iter:  885 train_cost:  920.28314 train_acc:  0.9765625 test_cost:  2153.4995 test_acc:  0.9453125\n",
            "iter:  886 train_cost:  1442.5758 train_acc:  0.96875 test_cost:  817.389 test_acc:  0.9453125\n",
            "iter:  887 train_cost:  0.0 train_acc:  1.0 test_cost:  1751.3213 test_acc:  0.96875\n",
            "iter:  888 train_cost:  802.0902 train_acc:  0.984375 test_cost:  434.4885 test_acc:  0.9765625\n",
            "iter:  889 train_cost:  871.42914 train_acc:  0.96875 test_cost:  1053.8804 test_acc:  0.953125\n",
            "iter:  890 train_cost:  561.74963 train_acc:  0.9765625 test_cost:  721.49536 test_acc:  0.9765625\n",
            "iter:  891 train_cost:  404.313 train_acc:  0.984375 test_cost:  1784.4946 test_acc:  0.953125\n",
            "iter:  892 train_cost:  77.02252 train_acc:  0.9921875 test_cost:  438.27466 test_acc:  0.96875\n",
            "iter:  893 train_cost:  630.4541 train_acc:  0.9609375 test_cost:  1845.666 test_acc:  0.953125\n",
            "iter:  894 train_cost:  0.0 train_acc:  1.0 test_cost:  1177.1564 test_acc:  0.9375\n",
            "iter:  895 train_cost:  332.04535 train_acc:  0.9765625 test_cost:  477.74924 test_acc:  0.9765625\n",
            "iter:  896 train_cost:  0.0 train_acc:  1.0 test_cost:  1109.7639 test_acc:  0.9609375\n",
            "iter:  897 train_cost:  43.523804 train_acc:  0.9921875 test_cost:  139.60144 test_acc:  0.9765625\n",
            "iter:  898 train_cost:  12.179565 train_acc:  0.9921875 test_cost:  2119.3086 test_acc:  0.9765625\n",
            "iter:  899 train_cost:  552.4926 train_acc:  0.984375 test_cost:  716.92633 test_acc:  0.9609375\n",
            "iter:  900 train_cost:  375.3934 train_acc:  0.9765625 test_cost:  191.98004 test_acc:  0.984375\n",
            "iter:  901 train_cost:  194.54034 train_acc:  0.9921875 test_cost:  2473.011 test_acc:  0.96875\n",
            "iter:  902 train_cost:  64.83297 train_acc:  0.9765625 test_cost:  226.1018 test_acc:  0.9765625\n",
            "iter:  903 train_cost:  118.98471 train_acc:  0.9921875 test_cost:  1957.0419 test_acc:  0.9609375\n",
            "iter:  904 train_cost:  5.5319824 train_acc:  0.984375 test_cost:  2498.9795 test_acc:  0.9609375\n",
            "iter:  905 train_cost:  285.83112 train_acc:  0.984375 test_cost:  833.93567 test_acc:  0.9609375\n",
            "iter:  906 train_cost:  0.0 train_acc:  1.0 test_cost:  303.51773 test_acc:  0.9765625\n",
            "iter:  907 train_cost:  724.74414 train_acc:  0.9765625 test_cost:  838.2017 test_acc:  0.96875\n",
            "iter:  908 train_cost:  1190.1566 train_acc:  0.9765625 test_cost:  2840.964 test_acc:  0.9296875\n",
            "iter:  909 train_cost:  443.9595 train_acc:  0.9609375 test_cost:  1305.8809 test_acc:  0.96875\n",
            "iter:  910 train_cost:  462.52197 train_acc:  0.9765625 test_cost:  1505.4121 test_acc:  0.953125\n",
            "iter:  911 train_cost:  190.03052 train_acc:  0.984375 test_cost:  531.8784 test_acc:  0.96875\n",
            "iter:  912 train_cost:  491.0158 train_acc:  0.96875 test_cost:  1556.476 test_acc:  0.9453125\n",
            "iter:  913 train_cost:  97.99182 train_acc:  0.984375 test_cost:  1800.3623 test_acc:  0.9609375\n",
            "iter:  914 train_cost:  769.52905 train_acc:  0.9609375 test_cost:  924.4787 test_acc:  0.984375\n",
            "iter:  915 train_cost:  911.4547 train_acc:  0.9609375 test_cost:  953.6957 test_acc:  0.96875\n",
            "iter:  916 train_cost:  1290.9333 train_acc:  0.953125 test_cost:  967.39935 test_acc:  0.9609375\n",
            "iter:  917 train_cost:  193.18176 train_acc:  0.984375 test_cost:  744.9547 test_acc:  0.9765625\n",
            "iter:  918 train_cost:  159.39948 train_acc:  0.984375 test_cost:  381.68945 test_acc:  0.9765625\n",
            "iter:  919 train_cost:  754.60925 train_acc:  0.9609375 test_cost:  1508.5715 test_acc:  0.9609375\n",
            "iter:  920 train_cost:  168.23346 train_acc:  0.9921875 test_cost:  244.39777 test_acc:  0.984375\n",
            "iter:  921 train_cost:  0.0 train_acc:  1.0 test_cost:  118.879944 test_acc:  0.9921875\n",
            "iter:  922 train_cost:  732.87463 train_acc:  0.9765625 test_cost:  837.93195 test_acc:  0.9609375\n",
            "iter:  923 train_cost:  489.67828 train_acc:  0.984375 test_cost:  1339.2102 test_acc:  0.9609375\n",
            "iter:  924 train_cost:  769.8995 train_acc:  0.984375 test_cost:  1152.6401 test_acc:  0.9453125\n",
            "iter:  925 train_cost:  499.62946 train_acc:  0.984375 test_cost:  2040.6951 test_acc:  0.9453125\n",
            "iter:  926 train_cost:  629.9168 train_acc:  0.984375 test_cost:  1366.9385 test_acc:  0.953125\n",
            "iter:  927 train_cost:  0.0 train_acc:  1.0 test_cost:  1049.1562 test_acc:  0.9375\n",
            "iter:  928 train_cost:  1066.1892 train_acc:  0.96875 test_cost:  452.78824 test_acc:  0.9765625\n",
            "iter:  929 train_cost:  63.712402 train_acc:  0.9765625 test_cost:  1007.3797 test_acc:  0.9609375\n",
            "iter:  930 train_cost:  481.19568 train_acc:  0.9765625 test_cost:  981.63696 test_acc:  0.9765625\n",
            "iter:  931 train_cost:  0.0 train_acc:  1.0 test_cost:  261.20514 test_acc:  0.96875\n",
            "iter:  932 train_cost:  353.8855 train_acc:  0.9609375 test_cost:  0.0 test_acc:  1.0\n",
            "iter:  933 train_cost:  677.0813 train_acc:  0.96875 test_cost:  410.6466 test_acc:  0.96875\n",
            "iter:  934 train_cost:  674.13654 train_acc:  0.96875 test_cost:  1047.0236 test_acc:  0.96875\n",
            "iter:  935 train_cost:  488.40363 train_acc:  0.984375 test_cost:  431.2174 test_acc:  0.9765625\n",
            "iter:  936 train_cost:  231.47253 train_acc:  0.9765625 test_cost:  2852.0845 test_acc:  0.9453125\n",
            "iter:  937 train_cost:  525.2135 train_acc:  0.9765625 test_cost:  652.83044 test_acc:  0.96875\n",
            "iter:  938 train_cost:  785.09106 train_acc:  0.953125 test_cost:  966.5925 test_acc:  0.953125\n",
            "iter:  939 train_cost:  65.246216 train_acc:  0.9921875 test_cost:  198.54346 test_acc:  0.984375\n",
            "iter:  940 train_cost:  344.39496 train_acc:  0.984375 test_cost:  1207.159 test_acc:  0.953125\n",
            "iter:  941 train_cost:  112.21823 train_acc:  0.9921875 test_cost:  545.7622 test_acc:  0.984375\n",
            "iter:  942 train_cost:  449.47388 train_acc:  0.984375 test_cost:  1291.0015 test_acc:  0.96875\n",
            "iter:  943 train_cost:  168.33563 train_acc:  0.984375 test_cost:  1233.5565 test_acc:  0.9609375\n",
            "iter:  944 train_cost:  357.8444 train_acc:  0.9921875 test_cost:  1092.2639 test_acc:  0.9765625\n",
            "iter:  945 train_cost:  311.48193 train_acc:  0.9921875 test_cost:  958.81604 test_acc:  0.984375\n",
            "iter:  946 train_cost:  168.87128 train_acc:  0.9765625 test_cost:  1838.4783 test_acc:  0.9375\n",
            "iter:  947 train_cost:  915.4132 train_acc:  0.96875 test_cost:  856.1784 test_acc:  0.9609375\n",
            "iter:  948 train_cost:  309.65436 train_acc:  0.9765625 test_cost:  413.47498 test_acc:  0.984375\n",
            "iter:  949 train_cost:  348.2594 train_acc:  0.984375 test_cost:  471.66064 test_acc:  0.984375\n",
            "iter:  950 train_cost:  217.65912 train_acc:  0.984375 test_cost:  448.09335 test_acc:  0.9765625\n",
            "iter:  951 train_cost:  458.79483 train_acc:  0.984375 test_cost:  1486.281 test_acc:  0.9453125\n",
            "iter:  952 train_cost:  773.7249 train_acc:  0.96875 test_cost:  976.2186 test_acc:  0.96875\n",
            "iter:  953 train_cost:  0.0 train_acc:  1.0 test_cost:  138.74405 test_acc:  0.984375\n",
            "iter:  954 train_cost:  95.06549 train_acc:  0.984375 test_cost:  990.4319 test_acc:  0.9609375\n",
            "iter:  955 train_cost:  34.451416 train_acc:  0.9921875 test_cost:  1039.8499 test_acc:  0.984375\n",
            "iter:  956 train_cost:  126.89966 train_acc:  0.984375 test_cost:  847.8906 test_acc:  0.9453125\n",
            "iter:  957 train_cost:  371.6405 train_acc:  0.96875 test_cost:  2441.0215 test_acc:  0.9453125\n",
            "iter:  958 train_cost:  150.30017 train_acc:  0.9765625 test_cost:  841.34924 test_acc:  0.9765625\n",
            "iter:  959 train_cost:  23.171204 train_acc:  0.9921875 test_cost:  512.5099 test_acc:  0.9609375\n",
            "iter:  960 train_cost:  551.7396 train_acc:  0.984375 test_cost:  569.40515 test_acc:  0.984375\n",
            "iter:  961 train_cost:  974.5665 train_acc:  0.9609375 test_cost:  637.2327 test_acc:  0.953125\n",
            "iter:  962 train_cost:  378.2356 train_acc:  0.9609375 test_cost:  443.0605 test_acc:  0.984375\n",
            "iter:  963 train_cost:  453.70074 train_acc:  0.984375 test_cost:  288.3188 test_acc:  0.984375\n",
            "iter:  964 train_cost:  540.5848 train_acc:  0.96875 test_cost:  592.3456 test_acc:  0.9765625\n",
            "iter:  965 train_cost:  0.0 train_acc:  1.0 test_cost:  745.1167 test_acc:  0.9453125\n",
            "iter:  966 train_cost:  363.29938 train_acc:  0.9921875 test_cost:  403.77618 test_acc:  0.9765625\n",
            "iter:  967 train_cost:  802.9219 train_acc:  0.9609375 test_cost:  1808.0194 test_acc:  0.9375\n",
            "iter:  968 train_cost:  143.34125 train_acc:  0.984375 test_cost:  81.80228 test_acc:  0.984375\n",
            "iter:  969 train_cost:  0.0 train_acc:  1.0 test_cost:  1383.2441 test_acc:  0.9453125\n",
            "iter:  970 train_cost:  261.99042 train_acc:  0.9765625 test_cost:  857.7627 test_acc:  0.9453125\n",
            "iter:  971 train_cost:  201.29478 train_acc:  0.9765625 test_cost:  3428.7183 test_acc:  0.9140625\n",
            "iter:  972 train_cost:  0.0 train_acc:  1.0 test_cost:  2861.8206 test_acc:  0.9375\n",
            "iter:  973 train_cost:  85.89664 train_acc:  0.984375 test_cost:  359.71582 test_acc:  0.96875\n",
            "iter:  974 train_cost:  166.21704 train_acc:  0.984375 test_cost:  1373.6907 test_acc:  0.9296875\n",
            "iter:  975 train_cost:  69.467514 train_acc:  0.96875 test_cost:  1315.368 test_acc:  0.9375\n",
            "iter:  976 train_cost:  384.42505 train_acc:  0.9921875 test_cost:  1369.2117 test_acc:  0.9609375\n",
            "iter:  977 train_cost:  531.40796 train_acc:  0.9765625 test_cost:  915.7776 test_acc:  0.96875\n",
            "iter:  978 train_cost:  465.41824 train_acc:  0.984375 test_cost:  1378.8169 test_acc:  0.9609375\n",
            "iter:  979 train_cost:  677.6792 train_acc:  0.953125 test_cost:  377.81 test_acc:  0.9765625\n",
            "iter:  980 train_cost:  118.9801 train_acc:  0.9921875 test_cost:  1102.5563 test_acc:  0.96875\n",
            "iter:  981 train_cost:  109.96362 train_acc:  0.984375 test_cost:  1145.6047 test_acc:  0.9609375\n",
            "iter:  982 train_cost:  418.11237 train_acc:  0.9765625 test_cost:  864.13574 test_acc:  0.953125\n",
            "iter:  983 train_cost:  453.4613 train_acc:  0.96875 test_cost:  672.61914 test_acc:  0.96875\n",
            "iter:  984 train_cost:  1521.3315 train_acc:  0.953125 test_cost:  1100.9109 test_acc:  0.96875\n",
            "iter:  985 train_cost:  731.22314 train_acc:  0.96875 test_cost:  1362.3612 test_acc:  0.953125\n",
            "iter:  986 train_cost:  501.24622 train_acc:  0.96875 test_cost:  3983.625 test_acc:  0.9296875\n",
            "iter:  987 train_cost:  368.64026 train_acc:  0.9921875 test_cost:  1054.4158 test_acc:  0.9296875\n",
            "iter:  988 train_cost:  170.52478 train_acc:  0.984375 test_cost:  3972.0674 test_acc:  0.9296875\n",
            "iter:  989 train_cost:  65.613525 train_acc:  0.984375 test_cost:  1076.9844 test_acc:  0.953125\n",
            "iter:  990 train_cost:  515.8429 train_acc:  0.984375 test_cost:  1139.5198 test_acc:  0.9453125\n",
            "iter:  991 train_cost:  42.703552 train_acc:  0.984375 test_cost:  1355.4476 test_acc:  0.9453125\n",
            "iter:  992 train_cost:  154.44788 train_acc:  0.9921875 test_cost:  475.86694 test_acc:  0.984375\n",
            "iter:  993 train_cost:  545.6791 train_acc:  0.96875 test_cost:  536.3009 test_acc:  0.9609375\n",
            "iter:  994 train_cost:  211.272 train_acc:  0.984375 test_cost:  546.44525 test_acc:  0.9609375\n",
            "iter:  995 train_cost:  145.32507 train_acc:  0.9921875 test_cost:  686.9326 test_acc:  0.96875\n",
            "iter:  996 train_cost:  0.0 train_acc:  1.0 test_cost:  500.77673 test_acc:  0.9765625\n",
            "iter:  997 train_cost:  90.14313 train_acc:  0.9765625 test_cost:  627.84595 test_acc:  0.96875\n",
            "iter:  998 train_cost:  128.67331 train_acc:  0.9765625 test_cost:  395.79523 test_acc:  0.9765625\n",
            "iter:  999 train_cost:  200.99738 train_acc:  0.9765625 test_cost:  545.8708 test_acc:  0.9765625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2997.9052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OKmhIq17Ien",
        "colab_type": "text"
      },
      "source": [
        "**First trial**: time with GPU and padding = same is 83.78841700000001 \n",
        "iter:  999 train_cost:  254.80815 train_acc:  0.96875 test_cost:  579.3871 test_acc:  0.96875\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Second trial**: time with GPU and padding = valid is 53.809466999999984 \n",
        "iter:  999 train_cost:  803.3296 train_acc:  0.96875 test_cost:  944.3785 test_acc:  0.96875\n",
        "\n",
        "\n",
        "**Third trial**: time with TPU and padding = valid is 2997.9052\n",
        "iter:  999 train_cost:  200.99738 train_acc:  0.9765625 test_cost:  545.8708 test_acc:  0.9765625\n"
      ]
    }
  ]
}